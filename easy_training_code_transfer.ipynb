{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import argparse\n",
    "from utils import dotdict\n",
    "from activation_dataset import setup_token_data\n",
    "import wandb\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "# from standard_metrics import run_with_model_intervention, perplexity_under_reconstruction, mean_nonzero_activations\n",
    "# Create \n",
    "# # make an argument parser directly below\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--model_name\", type=str, default=\"EleutherAI/pythia-70m-deduped\")\n",
    "# parser.add_argument(\"--layer\", type=int, default=4)\n",
    "# parser.add_argument(\"--setting\", type=str, default=\"residual\")\n",
    "# parser.add_argument(\"--l1_alpha\", type=float, default=3e-3)\n",
    "# parser.add_argument(\"--num_epochs\", type=int, default=10)\n",
    "# parser.add_argument(\"--model_batch_size\", type=int, default=4)\n",
    "# parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "# parser.add_argument(\"--kl\", type=bool, default=False)\n",
    "# parser.add_argument(\"--reconstruction\", type=bool, default=False)\n",
    "# parser.add_argument(\"--dataset_name\", type=str, default=\"NeelNanda/pile-10k\")\n",
    "# parser.add_argument(\"--device\", type=str, default=\"cuda:4\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "cfg = dotdict()\n",
    "# cfg.model_name=\"EleutherAI/pythia-70m-deduped\", \"usvsnsp/pythia-6.9b-sft\"\n",
    "cfg.model_name=\"EleutherAI/pythia-70m-deduped\"\n",
    "cfg.target_name=\"EleutherAI/pythia-70m-deduped\"\n",
    "cfg.layers=[4]\n",
    "cfg.setting=\"residual\"\n",
    "cfg.tensor_name=\"gpt_neox.layers.{layer}\"\n",
    "original_l1_alpha = 1e-3\n",
    "cfg.l1_alpha=original_l1_alpha\n",
    "cfg.sparsity=None\n",
    "cfg.num_epochs=10\n",
    "cfg.model_batch_size=4\n",
    "cfg.lr=1e-3\n",
    "cfg.kl=False\n",
    "cfg.reconstruction=False\n",
    "# cfg.dataset_name=\"NeelNanda/pile-10k\"\n",
    "cfg.dataset_name=\"Elriggs/openwebtext-100k\"\n",
    "cfg.device=\"cuda:0\"\n",
    "cfg.ratio = 4\n",
    "cfg.seed = 0\n",
    "# cfg.device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_names = [cfg.tensor_name.format(layer=layer) for layer in cfg.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(cfg.model_name)\n",
    "model = model.to(cfg.device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 112749568\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "# TODO iteratively grab dataset?\n",
    "cfg.max_length = 256\n",
    "cfg.model_batch_size = 4\n",
    "token_loader = setup_token_data(cfg, tokenizer, model, seed=cfg.seed)\n",
    "num_tokens = cfg.max_length*cfg.model_batch_size*len(token_loader)\n",
    "print(f\"Number of tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation size: 512\n"
     ]
    }
   ],
   "source": [
    "# Run 1 datapoint on model to get the activation size\n",
    "from baukit import Trace\n",
    "\n",
    "text = \"1\"\n",
    "tokens = tokenizer(text, return_tensors=\"pt\").input_ids.to(cfg.device)\n",
    "# Your activation name will be different. In the next cells, we will show you how to find it.\n",
    "with torch.no_grad():\n",
    "    with Trace(model, tensor_names[0]) as ret:\n",
    "        _ = model(tokens)\n",
    "        representation = ret.output\n",
    "        # check if instance tuple\n",
    "        if(isinstance(representation, tuple)):\n",
    "            representation = representation[0]\n",
    "        activation_size = representation.shape[-1]\n",
    "print(f\"Activation size: {activation_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize New autoencoder\n",
    "from autoencoders.learned_dict import TiedSAE, UntiedSAE, AnthropicSAE\n",
    "from torch import nn\n",
    "params = dict()\n",
    "n_dict_components = activation_size*cfg.ratio\n",
    "params[\"encoder\"] = torch.empty((n_dict_components, activation_size), device=cfg.device)\n",
    "nn.init.xavier_uniform_(params[\"encoder\"])\n",
    "\n",
    "params[\"decoder\"] = torch.empty((n_dict_components, activation_size), device=cfg.device)\n",
    "nn.init.xavier_uniform_(params[\"decoder\"])\n",
    "\n",
    "params[\"encoder_bias\"] = torch.empty((n_dict_components,), device=cfg.device)\n",
    "nn.init.zeros_(params[\"encoder_bias\"])\n",
    "\n",
    "params[\"shift_bias\"] = torch.empty((activation_size,), device=cfg.device)\n",
    "nn.init.zeros_(params[\"shift_bias\"])\n",
    "\n",
    "autoencoder = AnthropicSAE(  # TiedSAE, UntiedSAE, AnthropicSAE\n",
    "    # n_feats = n_dict_components, \n",
    "    # activation_size=activation_size,\n",
    "    encoder=params[\"encoder\"],\n",
    "    encoder_bias=params[\"encoder_bias\"],\n",
    "    decoder=params[\"decoder\"],\n",
    "    shift_bias=params[\"shift_bias\"],\n",
    ")\n",
    "autoencoder.to_device(cfg.device)\n",
    "autoencoder.set_grad()\n",
    "# autoencoder.encoder.requires_grad = True\n",
    "# autoencoder.encoder_bias.requires_grad = True\n",
    "# autoencoder.decoder.requires_grad = True\n",
    "# autoencoder.shift_bias.requires_grad = True\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        autoencoder.encoder, \n",
    "        autoencoder.encoder_bias,\n",
    "        autoencoder.decoder,\n",
    "        autoencoder.shift_bias,\n",
    "    ], lr=cfg.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target sparsity: 51\n"
     ]
    }
   ],
   "source": [
    "# Set target sparsity to 10% of activation_size if not set\n",
    "if cfg.sparsity is None:\n",
    "    cfg.sparsity = int(activation_size*0.1)\n",
    "    print(f\"Target sparsity: {cfg.sparsity}\")\n",
    "\n",
    "target_lower_sparsity = cfg.sparsity - 5.0\n",
    "target_upper_sparsity = cfg.sparsity + 5.0\n",
    "adjustment_factor = 0.1  # You can set this to whatever you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbenw8888\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb_run_name: EleutherAI/pythia-70m-deduped_1011-032433_51\n"
     ]
    }
   ],
   "source": [
    "original_bias = autoencoder.encoder_bias.clone().detach()\n",
    "# Wandb setup\n",
    "secrets = json.load(open(\"secrets.json\"))\n",
    "wandb.login(key=secrets[\"wandb_key\"])\n",
    "start_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "wandb_run_name = f\"{cfg.model_name}_{start_time[4:]}_{cfg.sparsity}\"  # trim year\n",
    "print(f\"wandb_run_name: {wandb_run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:75zj1ler) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">EleutherAI/pythia-70m-deduped_1011-014428_51</strong> at: <a href='https://wandb.ai/benw8888/sparse%20coding/runs/75zj1ler' target=\"_blank\">https://wandb.ai/benw8888/sparse%20coding/runs/75zj1ler</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231011_014524-75zj1ler/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:75zj1ler). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/sparse_coding/wandb/run-20231011_014746-jwjmogoe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/benw8888/sparse%20coding/runs/jwjmogoe' target=\"_blank\">EleutherAI/pythia-70m-deduped_1011-014428_51</a></strong> to <a href='https://wandb.ai/benw8888/sparse%20coding' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/benw8888/sparse%20coding' target=\"_blank\">https://wandb.ai/benw8888/sparse%20coding</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/benw8888/sparse%20coding/runs/jwjmogoe' target=\"_blank\">https://wandb.ai/benw8888/sparse%20coding/runs/jwjmogoe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/benw8888/sparse%20coding/runs/jwjmogoe?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f7424282dd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"sparse coding\", config=dict(cfg), name=wandb_run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# class ActivationSaver():    \n",
    "#     def __init__(self, batches_per_file=5_000, folder_path=\"saved_activations\"):\n",
    "#         self.total_batches = 0\n",
    "#         self.batches_per_file = batches_per_file\n",
    "#         self.folder_path = folder_path\n",
    "        \n",
    "#         self.files = []\n",
    "#         self.batch_buffer = []\n",
    "#         if not os.path.exists(folder_path):\n",
    "#             os.makedirs(folder_path)\n",
    "            \n",
    "#     def save_batch(self, batch):\n",
    "#         if len(self.batch_buffer) >= self.batches_per_file:\n",
    "#             new_file = f\"{self.folder_path}/activations_{len(self.files)+1}.pkl\"\n",
    "#             torch.save(self.batch_buffer, new_file)\n",
    "#             self.batch_buffer = []\n",
    "#             self.files.append(new_file)\n",
    "            \n",
    "#         self.batch_buffer.append(batch)\n",
    "#         self.total_batches +=1\n",
    "    \n",
    "#     def save_buffer(self):\n",
    "#         new_file = f\"{self.folder_path}/activations_{len(self.files)+1}.pkl\"\n",
    "#         torch.save(self.batch_buffer, new_file)\n",
    "#         self.batch_buffer = []\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return self.total_batches\n",
    "        \n",
    "#     def load_file(self, i):\n",
    "#         return torch.load(self.files[i])\n",
    "    \n",
    "#     def generator(self):\n",
    "#         cur_file = 0\n",
    "#         while cur_file < len(self.files):\n",
    "#             for batch in self.load_file(cur_file):\n",
    "#                 yield batch\n",
    "#             cur_file += 1\n",
    "#         for batch in self.batch_buffer:\n",
    "#             yield batch\n",
    "# activation_saver = ActivationSaver(batches_per_file=5_000, folder_path=\"saved_activations/base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/110107 [00:00<1:02:59, 29.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/110107 [00:00<47:14, 38.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 1016.3 | Dead Features: 0 | Total Loss: 1.56 | Reconstruction Loss: 1.19 | L1 Loss: 0.37 | l1_alpha: 1.00e-03 | Tokens: 0 | Self Similarity: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 508/110107 [00:11<40:26, 45.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 145.7 | Dead Features: 0 | Total Loss: 0.14 | Reconstruction Loss: 0.09 | L1 Loss: 0.05 | l1_alpha: 1.00e-03 | Tokens: 512000 | Self Similarity: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1008/110107 [00:22<40:22, 45.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 151.5 | Dead Features: 0 | Total Loss: 0.13 | Reconstruction Loss: 0.07 | L1 Loss: 0.05 | l1_alpha: 1.00e-03 | Tokens: 1024000 | Self Similarity: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1498/110107 [00:32<39:58, 45.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 143.8 | Dead Features: 1 | Total Loss: 0.12 | Reconstruction Loss: 0.07 | L1 Loss: 0.05 | l1_alpha: 1.00e-03 | Tokens: 1536000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      "  2%|▏         | 2008/110107 [00:46<40:00, 45.02it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 144.5 | Dead Features: 0 | Total Loss: 0.11 | Reconstruction Loss: 0.06 | L1 Loss: 0.05 | l1_alpha: 1.00e-03 | Tokens: 2048000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2508/110107 [00:57<39:50, 45.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 145.2 | Dead Features: 0 | Total Loss: 0.11 | Reconstruction Loss: 0.06 | L1 Loss: 0.05 | l1_alpha: 1.00e-03 | Tokens: 2560000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3008/110107 [01:08<39:39, 45.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 147.7 | Dead Features: 0 | Total Loss: 0.10 | Reconstruction Loss: 0.05 | L1 Loss: 0.05 | l1_alpha: 1.00e-03 | Tokens: 3072000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3508/110107 [01:19<39:31, 44.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 151.3 | Dead Features: 0 | Total Loss: 0.10 | Reconstruction Loss: 0.05 | L1 Loss: 0.05 | l1_alpha: 1.00e-03 | Tokens: 3584000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 4008/110107 [01:30<39:23, 44.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 146.1 | Dead Features: 0 | Total Loss: 0.10 | Reconstruction Loss: 0.05 | L1 Loss: 0.05 | l1_alpha: 1.00e-03 | Tokens: 4096000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4498/110107 [01:41<38:51, 45.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 137.3 | Dead Features: 1 | Total Loss: 0.10 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 4608000 | Self Similarity: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      "  5%|▍         | 5008/110107 [01:59<6:50:31,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 140.5 | Dead Features: 0 | Total Loss: 0.10 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 5120000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 5498/110107 [02:10<37:42, 46.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 146.2 | Dead Features: 1 | Total Loss: 0.10 | Reconstruction Loss: 0.05 | L1 Loss: 0.05 | l1_alpha: 1.00e-03 | Tokens: 5632000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      "  5%|▌         | 5998/110107 [02:23<37:34, 46.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 140.2 | Dead Features: 5 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 6144000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      "  6%|▌         | 6498/110107 [02:36<37:25, 46.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 144.2 | Dead Features: 2 | Total Loss: 0.10 | Reconstruction Loss: 0.06 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 6656000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      "  6%|▋         | 6998/110107 [02:48<37:12, 46.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 143.0 | Dead Features: 4 | Total Loss: 0.10 | Reconstruction Loss: 0.05 | L1 Loss: 0.05 | l1_alpha: 1.00e-03 | Tokens: 7168000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      "  7%|▋         | 7498/110107 [03:01<36:56, 46.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 141.5 | Dead Features: 12 | Total Loss: 0.10 | Reconstruction Loss: 0.05 | L1 Loss: 0.05 | l1_alpha: 1.00e-03 | Tokens: 7680000 | Self Similarity: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      "  7%|▋         | 7998/110107 [03:14<36:53, 46.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 142.6 | Dead Features: 5 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 8192000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      "  8%|▊         | 8498/110107 [03:27<36:39, 46.19it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 143.2 | Dead Features: 5 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 8704000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      "  8%|▊         | 8998/110107 [03:40<36:30, 46.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 144.4 | Dead Features: 14 | Total Loss: 0.10 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 9216000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      "  9%|▊         | 9498/110107 [03:52<36:20, 46.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 134.0 | Dead Features: 53 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 9728000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      "  9%|▉         | 9998/110107 [04:05<36:45, 45.39it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 130.9 | Dead Features: 48 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 10240000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 10%|▉         | 10498/110107 [04:24<35:55, 46.21it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 140.0 | Dead Features: 22 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 10752000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 10%|▉         | 10998/110107 [04:36<35:44, 46.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 141.9 | Dead Features: 25 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 11264000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 10%|█         | 11498/110107 [04:49<35:32, 46.24it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 139.7 | Dead Features: 8 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 11776000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 11%|█         | 11998/110107 [05:02<35:22, 46.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 145.3 | Dead Features: 17 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 12288000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 11%|█▏        | 12498/110107 [05:15<35:15, 46.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 145.4 | Dead Features: 12 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 12800000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 12%|█▏        | 12998/110107 [05:28<35:00, 46.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 141.3 | Dead Features: 9 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 13312000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 12%|█▏        | 13498/110107 [05:40<34:51, 46.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 136.2 | Dead Features: 2 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 13824000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 13%|█▎        | 13998/110107 [05:53<34:39, 46.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 148.0 | Dead Features: 3 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 14336000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 13%|█▎        | 14498/110107 [06:06<34:29, 46.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 139.4 | Dead Features: 3 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 14848000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 14%|█▎        | 14998/110107 [06:30<34:20, 46.15it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 144.7 | Dead Features: 3 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 15360000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 14%|█▍        | 15496/110107 [06:43<34:10, 46.14it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 144.7 | Dead Features: 8 | Total Loss: 0.11 | Reconstruction Loss: 0.06 | L1 Loss: 0.05 | l1_alpha: 1.00e-03 | Tokens: 15872000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 15%|█▍        | 15996/110107 [06:56<33:51, 46.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 147.0 | Dead Features: 5 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 16384000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 15%|█▍        | 16506/110107 [07:09<33:57, 45.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 141.7 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 16896000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 16996/110107 [07:20<33:36, 46.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 135.7 | Dead Features: 3 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 17408000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 16%|█▌        | 17496/110107 [07:33<33:30, 46.07it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 147.5 | Dead Features: 1 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 17920000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 16%|█▋        | 17996/110107 [07:45<33:16, 46.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 128.0 | Dead Features: 11 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 18432000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 17%|█▋        | 18496/110107 [07:58<33:04, 46.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 130.1 | Dead Features: 1 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 18944000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 17%|█▋        | 19006/110107 [08:11<33:19, 45.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 135.6 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 19456000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 19506/110107 [08:21<33:09, 45.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 139.3 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 19968000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 19996/110107 [08:32<32:26, 46.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 141.2 | Dead Features: 1 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 20480000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 19%|█▊        | 20506/110107 [08:50<32:25, 46.07it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 138.8 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 20992000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 20996/110107 [09:01<31:58, 46.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 141.6 | Dead Features: 5 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 21504000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 20%|█▉        | 21496/110107 [09:14<31:53, 46.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 139.1 | Dead Features: 3 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 22016000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 20%|█▉        | 21996/110107 [09:27<31:35, 46.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 138.9 | Dead Features: 1 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 22528000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 20%|██        | 22506/110107 [09:39<31:52, 45.80it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 133.2 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 23040000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 22996/110107 [09:50<31:24, 46.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 133.6 | Dead Features: 33 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 23552000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 21%|██▏       | 23496/110107 [10:03<31:10, 46.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 133.6 | Dead Features: 18 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 24064000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 22%|██▏       | 23996/110107 [10:15<30:59, 46.32it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 140.8 | Dead Features: 9 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 24576000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 22%|██▏       | 24496/110107 [10:28<30:47, 46.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 137.0 | Dead Features: 3 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 25088000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 23%|██▎       | 24996/110107 [10:41<30:41, 46.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 137.0 | Dead Features: 2 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 25600000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 23%|██▎       | 25496/110107 [10:59<30:24, 46.38it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 140.8 | Dead Features: 1 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 26112000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 24%|██▎       | 26006/110107 [11:12<30:28, 46.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 133.4 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 26624000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 26506/110107 [11:23<30:25, 45.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 137.3 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 27136000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 27006/110107 [11:34<30:09, 45.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 147.1 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 27648000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 27506/110107 [11:45<30:00, 45.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 139.5 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 28160000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 28006/110107 [11:56<29:49, 45.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 143.6 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 28672000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 28506/110107 [12:06<29:43, 45.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 141.4 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 29184000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 28996/110107 [12:17<29:24, 45.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 137.7 | Dead Features: 1 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 29696000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 27%|██▋       | 29506/110107 [12:30<29:15, 45.91it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 133.1 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 30208000 | Self Similarity: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 29996/110107 [12:41<28:48, 46.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 136.2 | Dead Features: 2 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 30720000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 28%|██▊       | 30506/110107 [13:00<28:53, 45.92it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 143.8 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 31232000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 31006/110107 [13:11<28:56, 45.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 136.4 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 31744000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 31506/110107 [13:21<28:34, 45.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 140.3 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 32256000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 32006/110107 [13:32<28:20, 45.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 141.4 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 32768000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 32496/110107 [13:43<27:53, 46.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 141.6 | Dead Features: 1 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 33280000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 30%|██▉       | 32996/110107 [13:55<27:46, 46.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 132.6 | Dead Features: 1 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 33792000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 30%|███       | 33506/110107 [14:08<28:04, 45.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 137.0 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 34304000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 34006/110107 [14:19<27:45, 45.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 136.6 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 34816000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 34506/110107 [14:30<27:33, 45.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 139.4 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 35328000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 34996/110107 [14:41<27:03, 46.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 139.1 | Dead Features: 1 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 35840000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 32%|███▏      | 35506/110107 [14:59<27:16, 45.60it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 146.2 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 36352000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 36006/110107 [15:10<26:55, 45.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 142.7 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 36864000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 36496/110107 [15:20<26:27, 46.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 133.6 | Dead Features: 1 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 37376000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 34%|███▎      | 36996/110107 [15:33<26:16, 46.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 132.6 | Dead Features: 1 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 37888000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 34%|███▍      | 37506/110107 [15:46<26:22, 45.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 142.4 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 38400000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 38006/110107 [15:57<26:12, 45.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 134.4 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 38912000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 38496/110107 [16:07<25:50, 46.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 131.8 | Dead Features: 1 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 39424000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 35%|███▌      | 39006/110107 [16:20<25:49, 45.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 137.0 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 39936000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 39506/110107 [16:31<26:10, 44.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 138.7 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 40448000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 40006/110107 [16:47<4:33:17,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 139.6 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 40960000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 40506/110107 [16:58<25:11, 46.04it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 136.0 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 41472000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 41006/110107 [17:08<25:08, 45.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 138.6 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 41984000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 41506/110107 [17:19<24:51, 45.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 136.8 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 42496000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 42006/110107 [17:30<24:40, 46.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 136.0 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 43008000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 42506/110107 [17:41<24:31, 45.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 139.6 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 43520000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 42996/110107 [17:51<24:18, 46.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 149.1 | Dead Features: 1 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 44032000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n",
      " 40%|███▉      | 43506/110107 [18:05<24:24, 45.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 143.7 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 44544000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 44006/110107 [18:16<24:10, 45.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 141.5 | Dead Features: 0 | Total Loss: 0.10 | Reconstruction Loss: 0.06 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 45056000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 44506/110107 [18:26<23:56, 45.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 134.4 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 45568000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 45006/110107 [18:43<4:22:17,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 138.0 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 46080000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 45506/110107 [18:53<23:30, 45.79it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 135.5 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 46592000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 46006/110107 [19:04<23:52, 44.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 137.4 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 47104000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 46506/110107 [19:15<23:05, 45.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 137.8 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 47616000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 47006/110107 [19:26<22:53, 45.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 134.4 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 48128000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 47506/110107 [19:37<22:50, 45.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 130.4 | Dead Features: 0 | Total Loss: 0.08 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 48640000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 48006/110107 [19:48<22:44, 45.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 142.4 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 49152000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 48506/110107 [19:58<22:29, 45.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 137.7 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.04 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 49664000 | Self Similarity: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 49006/110107 [20:09<22:20, 45.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 133.1 | Dead Features: 0 | Total Loss: 0.10 | Reconstruction Loss: 0.06 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 50176000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 49506/110107 [20:20<22:00, 45.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 140.0 | Dead Features: 0 | Total Loss: 0.09 | Reconstruction Loss: 0.05 | L1 Loss: 0.04 | l1_alpha: 1.00e-03 | Tokens: 50688000 | Self Similarity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 50000/110107 [20:37<24:47, 40.42it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:337] . unexpected pos 1151820160 vs 1151820048",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 441\u001b[0m     _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:668\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    667\u001b[0m num_bytes \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39mnbytes()\n\u001b[0;32m--> 668\u001b[0m zip_file\u001b[39m.\u001b[39;49mwrite_record(name, storage\u001b[39m.\u001b[39;49mdata_ptr(), num_bytes)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:471] . PytorchStreamWriter failed writing file data/1492: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m             representation \u001b[39m=\u001b[39m representation[\u001b[39m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m layer_activations \u001b[39m=\u001b[39m rearrange(representation, \u001b[39m\"\u001b[39m\u001b[39mb seq d_model -> (b seq) d_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m activation_saver\u001b[39m.\u001b[39;49msave_batch(layer_activations\u001b[39m.\u001b[39;49mclone()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mdetach())\n\u001b[1;32m     20\u001b[0m c \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mencode(layer_activations)\n\u001b[1;32m     21\u001b[0m x_hat \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mdecode(c)\n",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m, in \u001b[0;36mActivationSaver.save_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_buffer) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatches_per_file:\n\u001b[1;32m     12\u001b[0m     new_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfolder_path\u001b[39m}\u001b[39;00m\u001b[39m/activations_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m     torch\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_buffer, new_file)\n\u001b[1;32m     14\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_buffer \u001b[39m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles\u001b[39m.\u001b[39mappend(new_file)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 440\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:291\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_like\u001b[39m.\u001b[39;49mwrite_end_of_file()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:337] . unexpected pos 1151820160 vs 1151820048"
     ]
    }
   ],
   "source": [
    "dead_features = torch.zeros(autoencoder.encoder.shape[0])\n",
    "total_activations = torch.zeros(autoencoder.encoder.shape[0])\n",
    "max_num_tokens = 100_000_000\n",
    "# Freeze model parameters \n",
    "model.eval()\n",
    "model.requires_grad_(False)\n",
    "model.to(cfg.device)\n",
    "last_encoder = autoencoder.encoder.clone().detach()\n",
    "for i, batch in enumerate(tqdm(token_loader)):\n",
    "    tokens = batch[\"input_ids\"].to(cfg.device)\n",
    "    with torch.no_grad(): # As long as not doing KL divergence, don't need gradients for model\n",
    "        with Trace(model, tensor_names[0]) as ret:\n",
    "            _ = model(tokens)\n",
    "            representation = ret.output\n",
    "            if(isinstance(representation, tuple)):\n",
    "                representation = representation[0]\n",
    "    layer_activations = rearrange(representation, \"b seq d_model -> (b seq) d_model\")\n",
    "    # activation_saver.save_batch(layer_activations.clone().cpu().detach())\n",
    "\n",
    "    c = autoencoder.encode(layer_activations)\n",
    "    x_hat = autoencoder.decode(c)\n",
    "    \n",
    "    reconstruction_loss = (x_hat - layer_activations).pow(2).mean()\n",
    "    l1_loss = torch.norm(c, 1, dim=-1).mean()\n",
    "    total_loss = reconstruction_loss + cfg.l1_alpha*l1_loss\n",
    "\n",
    "    dead_features += c.sum(dim=0).cpu()\n",
    "    total_activations += c.sum(dim=0).cpu()\n",
    "    if (i % 500 == 0): # Check here so first check is model w/o change\n",
    "        # self_similarity = torch.cosine_similarity(c, last_encoder, dim=-1).mean().cpu().item()\n",
    "        # Above is wrong, should be similarity between encoder and last encoder\n",
    "        self_similarity = torch.cosine_similarity(autoencoder.encoder, last_encoder, dim=-1).mean().cpu().item()\n",
    "        last_encoder = autoencoder.encoder.clone().detach()\n",
    "        num_tokens_so_far = i*cfg.max_length*cfg.model_batch_size\n",
    "        with torch.no_grad():\n",
    "            sparsity = (c != 0).float().mean(dim=0).sum().cpu().item()\n",
    "            # Count number of dead_features are zero\n",
    "            num_dead_features = (dead_features == 0).sum().item()\n",
    "        print(f\"Sparsity: {sparsity:.1f} | Dead Features: {num_dead_features} | Total Loss: {total_loss:.2f} | Reconstruction Loss: {reconstruction_loss:.2f} | L1 Loss: {cfg.l1_alpha*l1_loss:.2f} | l1_alpha: {cfg.l1_alpha:.2e} | Tokens: {num_tokens_so_far} | Self Similarity: {self_similarity:.2f}\")\n",
    "        wandb.log({\n",
    "            'Sparsity': sparsity,\n",
    "            'Dead Features': num_dead_features,\n",
    "            'Total Loss': total_loss.item(),\n",
    "            'Reconstruction Loss': reconstruction_loss.item(),\n",
    "            'L1 Loss': (cfg.l1_alpha*l1_loss).item(),\n",
    "            'l1_alpha': cfg.l1_alpha,\n",
    "            'Tokens': num_tokens_so_far,\n",
    "            'Self Similarity': self_similarity\n",
    "        })\n",
    "        \n",
    "        dead_features = torch.zeros(autoencoder.encoder.shape[0])\n",
    "        \n",
    "        if(num_tokens_so_far > max_num_tokens):\n",
    "            print(f\"Reached max number of tokens: {max_num_tokens}\")\n",
    "            break\n",
    "    \n",
    "    resample_period = 500\n",
    "    if (i % resample_period == 0):\n",
    "        # RESAMPLING\n",
    "        with torch.no_grad():\n",
    "            # Count number of dead_features are zero\n",
    "            num_dead_features = (total_activations == 0).sum().item()\n",
    "            \n",
    "        if num_dead_features > 0:\n",
    "            # hyperparams:\n",
    "            max_resample_tokens = 1000 # the number of token activations that we consider for inserting into the dictionary\n",
    "            # compute loss of model on random subset of inputs\n",
    "            resample_loader = setup_token_data(cfg, tokenizer, model, seed=i)\n",
    "            num_resample_data = 0\n",
    "\n",
    "            resample_activations = torch.empty(0, activation_size)\n",
    "            resample_losses = torch.empty(0)\n",
    "\n",
    "            for resample_batch in resample_loader:\n",
    "                resample_tokens = resample_batch[\"input_ids\"].to(cfg.device)\n",
    "                with torch.no_grad(): # As long as not doing KL divergence, don't need gradients for model\n",
    "                    with Trace(model, tensor_names[0]) as ret:\n",
    "                        _ = model(resample_tokens)\n",
    "                        representation = ret.output\n",
    "                        if(isinstance(representation, tuple)):\n",
    "                            representation = representation[0]\n",
    "                layer_activations = rearrange(representation, \"b seq d_model -> (b seq) d_model\")\n",
    "                resample_activations = torch.cat((resample_activations, layer_activations.detach().cpu()), dim=0)\n",
    "\n",
    "                c = autoencoder.encode(layer_activations)\n",
    "                x_hat = autoencoder.decode(c)\n",
    "                \n",
    "                reconstruction_loss = (x_hat - layer_activations).pow(2).mean(dim=-1)\n",
    "                l1_loss = torch.norm(c, 1, dim=-1)\n",
    "                temp_loss = reconstruction_loss + cfg.l1_alpha*l1_loss\n",
    "                \n",
    "                resample_losses = torch.cat((resample_losses, temp_loss.detach().cpu()), dim=0)\n",
    "                \n",
    "                num_resample_data +=layer_activations.shape[0]\n",
    "                if num_resample_data > max_resample_tokens:\n",
    "                    break\n",
    "\n",
    "                \n",
    "            # sample num_dead_features vectors of input activations\n",
    "            probabilities = resample_losses**2\n",
    "            sampled_indices = torch.multinomial(probabilities, num_dead_features)\n",
    "            new_vectors = resample_activations[sampled_indices]\n",
    "\n",
    "            # calculate average encoder norm of alive neurons\n",
    "            alive_neurons = list((total_activations!=0))\n",
    "            modified_columns = total_activations==0\n",
    "            avg_norm = autoencoder.encoder.data[alive_neurons].norm(dim=-1).mean()\n",
    "\n",
    "            # replace dictionary and encoder weights with vectors\n",
    "            new_vectors = new_vectors / new_vectors.norm(dim=1, keepdim=True)\n",
    "            \n",
    "            params_to_modify = [autoencoder.encoder, autoencoder.encoder_bias]\n",
    "\n",
    "            current_weights = autoencoder.encoder.data\n",
    "            current_weights[modified_columns] = (new_vectors.to(cfg.device) * avg_norm * 0.2)\n",
    "            autoencoder.encoder.data = current_weights\n",
    "\n",
    "            current_weights = autoencoder.encoder_bias.data\n",
    "            current_weights[modified_columns] = 0\n",
    "            autoencoder.encoder_bias.data = current_weights\n",
    "            \n",
    "            if hasattr(autoencoder, 'decoder'):\n",
    "                current_weights = autoencoder.decoder.data\n",
    "                current_weights[modified_columns] = new_vectors.to(cfg.device)\n",
    "                autoencoder.decoder.data = current_weights\n",
    "                params_to_modify += [autoencoder.decoder]\n",
    "\n",
    "            for param_group in optimizer.param_groups:\n",
    "                for param in param_group['params']:\n",
    "                    if any(param is d_ for d_ in params_to_modify):\n",
    "                        # Extract the corresponding rows from m and v\n",
    "                        m = optimizer.state[param]['exp_avg']\n",
    "                        v = optimizer.state[param]['exp_avg_sq']\n",
    "                        \n",
    "                        # Update the m and v values for the modified columns\n",
    "                        m[modified_columns] = 0  # Reset moving average for modified columns\n",
    "                        v[modified_columns] = 0  # Reset squared moving average for modified columns\n",
    "        \n",
    "        total_activations = torch.zeros(autoencoder.encoder.shape[0])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # # Running sparsity check\n",
    "    # if(num_tokens_so_far > 500000):\n",
    "    #     if(i % 200 == 0):\n",
    "    #         with torch.no_grad():\n",
    "    #             sparsity = (c != 0).float().mean(dim=0).sum().cpu().item()\n",
    "    #         if sparsity > target_upper_sparsity:\n",
    "    #             cfg.l1_alpha *= (1 + adjustment_factor)\n",
    "    #         elif sparsity < target_lower_sparsity:\n",
    "    #             cfg.l1_alpha *= (1 - adjustment_factor)\n",
    "    #         # print(f\"Sparsity: {sparsity:.1f} | l1_alpha: {cfg.l1_alpha:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_name = cfg.model_name.split(\"/\")[-1]\n",
    "save_name = f\"{model_save_name}_sp{cfg.sparsity}_r{cfg.ratio}_{tensor_names[0]}\"  # trim year\n",
    "\n",
    "# Make directory traiend_models if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(\"trained_models\"):\n",
    "    os.makedirs(\"trained_models\")\n",
    "# Save model\n",
    "torch.save(autoencoder, f\"trained_models/{save_name}.pt\")\n",
    "\n",
    "# if not os.path.exists(\"activations\"):\n",
    "#     os.makedirs(\"activations\")\n",
    "# # Save model\n",
    "# torch.save(saved_activations[:-1], f\"activations/{save_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Dead Features</td><td>▁▁▁▁▁▂▃▂█▅▃▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>L1 Loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Reconstruction Loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Self Similarity</td><td>█▁▃▃▃▃▂▄▂▄▅▄▄▅▅▅▅▄▂▅▅▅▅▄▄▅▄▅▅▅▄▅▅▅▅▄▅▅▄▅</td></tr><tr><td>Sparsity</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Tokens</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Total Loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>l1_alpha</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Dead Features</td><td>0</td></tr><tr><td>L1 Loss</td><td>0.04268</td></tr><tr><td>Reconstruction Loss</td><td>0.04672</td></tr><tr><td>Self Similarity</td><td>0.97426</td></tr><tr><td>Sparsity</td><td>139.97461</td></tr><tr><td>Tokens</td><td>50688000</td></tr><tr><td>Total Loss</td><td>0.08939</td></tr><tr><td>l1_alpha</td><td>0.001</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">EleutherAI/pythia-70m-deduped_1011-014428_51</strong> at: <a href='https://wandb.ai/benw8888/sparse%20coding/runs/jwjmogoe' target=\"_blank\">https://wandb.ai/benw8888/sparse%20coding/runs/jwjmogoe</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231011_014746-jwjmogoe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = AutoModelForCausalLM.from_pretrained(cfg.target_name).cpu()\n",
    "\n",
    "model_save_name = cfg.model_name.split(\"/\")[-1]\n",
    "save_name = f\"{model_save_name}_sp{cfg.sparsity}_r{cfg.ratio}_{tensor_names[0]}\"  # trim year\n",
    "autoencoder = torch.load(f\"trained_models/{save_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize New autoencoder\n",
    "from autoencoders.learned_dict import TiedSAE, UntiedSAE, AnthropicSAE, TransferSAE\n",
    "from torch import nn\n",
    "\n",
    "# params[\"decoder\"] = torch.empty((n_dict_components, activation_size), device=cfg.device)\n",
    "# nn.init.xavier_uniform_(params[\"decoder\"])\n",
    "\n",
    "params[\"decoder_bias\"] = torch.empty((activation_size,), device=cfg.device)\n",
    "nn.init.zeros_(params[\"decoder_bias\"])\n",
    "\n",
    "transfer_autoencoder = TransferSAE(\n",
    "    # n_feats = n_dict_components, \n",
    "    # activation_size=activation_size,\n",
    "    autoencoder,\n",
    "    decoder=autoencoder.encoder.detach().clone(),\n",
    "    decoder_bias=params[\"decoder_bias\"],\n",
    ")\n",
    "transfer_autoencoder.to_device(cfg.device)\n",
    "\n",
    "# Set gradient to true for decoder only- only training decoder on transfer\n",
    "transfer_autoencoder.set_grad()\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        transfer_autoencoder.decoder,\n",
    "        transfer_autoencoder.decoder_bias,\n",
    "    ], lr=cfg.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb_run_name: EleutherAI/pythia-70m-deduped_transfer_1011-040220_51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/sparse_coding/wandb/run-20231011_040220-jllu8mvw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/benw8888/sparse%20coding/runs/jllu8mvw' target=\"_blank\">EleutherAI/pythia-70m-deduped_transfer_1011-040220_51</a></strong> to <a href='https://wandb.ai/benw8888/sparse%20coding' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/benw8888/sparse%20coding' target=\"_blank\">https://wandb.ai/benw8888/sparse%20coding</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/benw8888/sparse%20coding/runs/jllu8mvw' target=\"_blank\">https://wandb.ai/benw8888/sparse%20coding/runs/jllu8mvw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/benw8888/sparse%20coding/runs/jllu8mvw?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f6b7c4a1870>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wandb setup\n",
    "secrets = json.load(open(\"secrets.json\"))\n",
    "wandb.login(key=secrets[\"wandb_key\"])\n",
    "start_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "wandb_run_name = f\"{cfg.target_name}_transfer_{start_time[4:]}_{cfg.sparsity}\"  # trim year\n",
    "print(f\"wandb_run_name: {wandb_run_name}\")\n",
    "wandb.init(project=\"sparse coding\", config=dict(cfg), name=wandb_run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(model, inputs):\n",
    "    acts = []\n",
    "    for tokens in inputs:\n",
    "        with torch.no_grad(): # As long as not doing KL divergence, don't need gradients for model\n",
    "            with Trace(model, tensor_names[0]) as ret:\n",
    "                _ = model(tokens)\n",
    "                representation = ret.output\n",
    "                if(isinstance(representation, tuple)):\n",
    "                    representation = representation[0]\n",
    "        layer_activations = rearrange(representation, \"b seq d_model -> (b seq) d_model\")\n",
    "        acts.append(layer_activations.cpu())\n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8401ec7d4dbd84d2_*_of_00008.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 143.0 | Dead Features: 1 | Reconstruction Loss: 0.86 | Tokens: 0 | Self Similarity: 1.00\n",
      "Sparsity: 145.0 | Dead Features: 0 | Reconstruction Loss: 0.06 | Tokens: 512000 | Self Similarity: 0.84\n",
      "Sparsity: 143.0 | Dead Features: 0 | Reconstruction Loss: 0.05 | Tokens: 1024000 | Self Similarity: 0.98\n",
      "Sparsity: 139.8 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 1536000 | Self Similarity: 0.99\n",
      "Sparsity: 138.9 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 2048000 | Self Similarity: 0.99\n",
      "Sparsity: 140.2 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 2560000 | Self Similarity: 0.99\n",
      "Sparsity: 136.2 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 3072000 | Self Similarity: 0.99\n",
      "Sparsity: 140.2 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 3584000 | Self Similarity: 0.99\n",
      "Sparsity: 138.6 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 4096000 | Self Similarity: 0.99\n",
      "Sparsity: 137.1 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 4608000 | Self Similarity: 0.99\n",
      "Sparsity: 138.9 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 5120000 | Self Similarity: 0.99\n",
      "Sparsity: 143.5 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 5632000 | Self Similarity: 0.99\n",
      "Sparsity: 137.8 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 6144000 | Self Similarity: 0.99\n",
      "Sparsity: 140.6 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 6656000 | Self Similarity: 0.99\n",
      "Sparsity: 145.1 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 7168000 | Self Similarity: 0.99\n",
      "Sparsity: 145.4 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 7680000 | Self Similarity: 0.99\n",
      "Sparsity: 139.6 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 8192000 | Self Similarity: 0.99\n",
      "Sparsity: 139.4 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 8704000 | Self Similarity: 0.99\n",
      "Sparsity: 140.9 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 9216000 | Self Similarity: 0.99\n",
      "Sparsity: 135.2 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 9728000 | Self Similarity: 0.99\n",
      "Sparsity: 132.3 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 10240000 | Self Similarity: 0.99\n",
      "Sparsity: 141.4 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 10752000 | Self Similarity: 0.99\n",
      "Sparsity: 140.2 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 11264000 | Self Similarity: 0.99\n",
      "Sparsity: 136.8 | Dead Features: 0 | Reconstruction Loss: 0.04 | Tokens: 11776000 | Self Similarity: 0.99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m (k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m%\u001b[39m\u001b[39m500\u001b[39m\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m     20\u001b[0m     \u001b[39m# compute base and target model activations\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39mif\u001b[39;00m model_on_gpu:\n\u001b[0;32m---> 22\u001b[0m         base_activations \u001b[39m=\u001b[39m get_activations(model, saved_inputs)\n\u001b[1;32m     23\u001b[0m         model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     24\u001b[0m         target_model \u001b[39m=\u001b[39m target_model\u001b[39m.\u001b[39mto(cfg\u001b[39m.\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[38], line 11\u001b[0m, in \u001b[0;36mget_activations\u001b[0;34m(model, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 representation \u001b[39m=\u001b[39m representation[\u001b[39m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m     layer_activations \u001b[39m=\u001b[39m rearrange(representation, \u001b[39m\"\u001b[39m\u001b[39mb seq d_model -> (b seq) d_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     acts\u001b[39m.\u001b[39mappend(layer_activations\u001b[39m.\u001b[39;49mcpu())\n\u001b[1;32m     12\u001b[0m \u001b[39mreturn\u001b[39;00m acts\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training transfer autoencoder\n",
    "token_loader = setup_token_data(cfg, tokenizer, model, seed=cfg.seed)\n",
    "dead_features = torch.zeros(transfer_autoencoder.encoder.shape[0])\n",
    "max_num_tokens = 100_000_000\n",
    "# Freeze model parameters \n",
    "model = model.to(cfg.device)\n",
    "target_model = target_model.cpu()\n",
    "target_model.eval()\n",
    "target_model.requires_grad_(False)\n",
    "\n",
    "last_decoder = transfer_autoencoder.decoder.clone().detach()\n",
    "model_on_gpu = True\n",
    "\n",
    "saved_inputs = []\n",
    "i = 0 # counts all optimization steps\n",
    "for k, (batch) in enumerate(token_loader):\n",
    "    saved_inputs.append(batch[\"input_ids\"].to(cfg.device))\n",
    "    \n",
    "    if (k+1)%500==0:\n",
    "        # compute base and target model activations\n",
    "        if model_on_gpu:\n",
    "            base_activations = get_activations(model, saved_inputs)\n",
    "            model = model.cpu()\n",
    "            target_model = target_model.to(cfg.device)\n",
    "        target_activations = get_activations(target_model, saved_inputs)\n",
    "        if not model_on_gpu:\n",
    "            target_model = target_model.cpu()\n",
    "            model = model.to(cfg.device)\n",
    "            base_activations = get_activations(model, saved_inputs)\n",
    "        model_on_gpu = not model_on_gpu\n",
    "\n",
    "        # wipe saved inputs\n",
    "        saved_inputs = []\n",
    "        \n",
    "        # train autoencoder on activations:\n",
    "        for (base_activation, target_activation) in (zip(base_activations, target_activations)):\n",
    "            c = transfer_autoencoder.encode(base_activation.to(cfg.device))\n",
    "            x_hat = transfer_autoencoder.decode(c)\n",
    "            \n",
    "            reconstruction_loss = (x_hat - target_activation.to(cfg.device)).pow(2).mean()\n",
    "            total_loss = reconstruction_loss # NO L1 LOSS\n",
    "\n",
    "            dead_features += c.sum(dim=0).cpu()\n",
    "            if (i % 500 == 0): # Check here so first check is model w/o change\n",
    "                self_similarity = torch.cosine_similarity(transfer_autoencoder.decoder, last_decoder, dim=-1).mean().cpu().item()\n",
    "                last_decoder = transfer_autoencoder.decoder.clone().detach()\n",
    "                num_tokens_so_far = i*cfg.max_length*cfg.model_batch_size\n",
    "                with torch.no_grad():\n",
    "                    sparsity = (c != 0).float().mean(dim=0).sum().cpu().item()\n",
    "                    # Count number of dead_features are zero\n",
    "                    num_dead_features = (dead_features == 0).sum().item()\n",
    "                print(f\"Sparsity: {sparsity:.1f} | Dead Features: {num_dead_features} | Reconstruction Loss: {reconstruction_loss:.2f} | Tokens: {num_tokens_so_far} | Self Similarity: {self_similarity:.2f}\")\n",
    "                wandb.log({\n",
    "                    'Sparsity': sparsity,\n",
    "                    'Dead Features': num_dead_features,\n",
    "                    'Reconstruction Loss': reconstruction_loss.item(),\n",
    "                    'Tokens': num_tokens_so_far,\n",
    "                    'Self Similarity': self_similarity\n",
    "                })\n",
    "                dead_features = torch.zeros(transfer_autoencoder.encoder.shape[0])\n",
    "                \n",
    "                if(num_tokens_so_far > max_num_tokens):\n",
    "                    print(f\"Reached max number of tokens: {max_num_tokens}\")\n",
    "                    break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            i+=1\n",
    "\n",
    "            # # Running sparsity check\n",
    "            # if(num_tokens_so_far > 500000):\n",
    "            #     if(i % 200 == 0):\n",
    "            #         with torch.no_grad():\n",
    "            #             sparsity = (c != 0).float().mean(dim=0).sum().cpu().item()\n",
    "            #         if sparsity > target_upper_sparsity:\n",
    "            #             cfg.l1_alpha *= (1 + adjustment_factor)\n",
    "            #         elif sparsity < target_lower_sparsity:\n",
    "            #             cfg.l1_alpha *= (1 - adjustment_factor)\n",
    "            #         # print(f\"Sparsity: {sparsity:.1f} | l1_alpha: {cfg.l1_alpha:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_name = cfg.target_name.split(\"/\")[-1]\n",
    "save_name = f\"{model_save_name}_transfer_sp{cfg.sparsity}_r{cfg.ratio}_{tensor_names[0]}\"  # trim year\n",
    "\n",
    "# Make directory traiend_models if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(\"trained_models\"):\n",
    "    os.makedirs(\"trained_models\")\n",
    "# Save model\n",
    "torch.save(transfer_autoencoder, f\"trained_models/{save_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">EleutherAI/pythia-70m-deduped_transfer_1011-034431_51</strong> at: <a href='https://wandb.ai/benw8888/sparse%20coding/runs/p1dz89o1' target=\"_blank\">https://wandb.ai/benw8888/sparse%20coding/runs/p1dz89o1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231011_034431-p1dz89o1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'EleutherAI/pythia-70m-deduped',\n",
       " 'layers': [4],\n",
       " 'setting': 'residual',\n",
       " 'tensor_name': 'gpt_neox.layers.{layer}',\n",
       " 'l1_alpha': 0.0020591228579666505,\n",
       " 'sparsity': 51,\n",
       " 'num_epochs': 10,\n",
       " 'model_batch_size': 4,\n",
       " 'lr': 0.001,\n",
       " 'kl': False,\n",
       " 'reconstruction': False,\n",
       " 'dataset_name': 'NeelNanda/pile-10k',\n",
       " 'device': 'cuda:0',\n",
       " 'ratio': 4,\n",
       " 'max_length': 256}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting autoawq\n",
      "  Obtaining dependency information for autoawq from https://files.pythonhosted.org/packages/b7/2e/3da6bd6314e68ce6a6951c69a9be3c55e5038cb4f05f1838eabb7003945a/autoawq-0.1.6-cp39-cp39-manylinux2014_x86_64.whl.metadata\n",
      "  Using cached autoawq-0.1.6-cp39-cp39-manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting torch>=2.1.0 (from autoawq)\n",
      "  Obtaining dependency information for torch>=2.1.0 from https://files.pythonhosted.org/packages/d3/fa/93f3ef65dee8947d8f54eb876ab57a8b019845a45dc07546e2ac214da97b/torch-2.1.0-cp39-cp39-manylinux1_x86_64.whl.metadata\n",
      "  Using cached torch-2.1.0-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: transformers>=4.35.0 in /home/lev/.local/lib/python3.9/site-packages (from autoawq) (4.35.0)\n",
      "Requirement already satisfied: tokenizers>=0.12.1 in /home/lev/.local/lib/python3.9/site-packages (from autoawq) (0.14.1)\n",
      "Requirement already satisfied: accelerate in /home/lev/.local/lib/python3.9/site-packages (from autoawq) (0.24.1)\n",
      "Requirement already satisfied: sentencepiece in /home/lev/.local/lib/python3.9/site-packages (from autoawq) (0.1.99)\n",
      "Collecting lm-eval (from autoawq)\n",
      "  Using cached lm_eval-0.3.0-py3-none-any.whl (178 kB)\n",
      "Collecting texttable (from autoawq)\n",
      "  Obtaining dependency information for texttable from https://files.pythonhosted.org/packages/24/99/4772b8e00a136f3e01236de33b0efda31ee7077203ba5967fcc76da94d65/texttable-1.7.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: toml in /home/lev/.local/lib/python3.9/site-packages (from autoawq) (0.10.2)\n",
      "Collecting attributedict (from autoawq)\n",
      "  Using cached attributedict-0.3.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: protobuf in /home/lev/.local/lib/python3.9/site-packages (from autoawq) (3.20.3)\n",
      "Requirement already satisfied: torchvision in /home/lev/.local/lib/python3.9/site-packages (from autoawq) (0.15.2)\n",
      "Collecting tabulate (from autoawq)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: huggingface_hub<0.18,>=0.16.4 in /home/lev/.local/lib/python3.9/site-packages (from tokenizers>=0.12.1->autoawq) (0.17.3)\n",
      "Requirement already satisfied: filelock in /home/lev/.local/lib/python3.9/site-packages (from torch>=2.1.0->autoawq) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /home/lev/.local/lib/python3.9/site-packages (from torch>=2.1.0->autoawq) (4.6.2)\n",
      "Requirement already satisfied: sympy in /home/lev/.local/lib/python3.9/site-packages (from torch>=2.1.0->autoawq) (1.12)\n",
      "Requirement already satisfied: networkx in /home/lev/.local/lib/python3.9/site-packages (from torch>=2.1.0->autoawq) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/lev/.local/lib/python3.9/site-packages (from torch>=2.1.0->autoawq) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/lev/.local/lib/python3.9/site-packages (from torch>=2.1.0->autoawq) (2023.5.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.0->autoawq)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.0->autoawq)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.0->autoawq)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1.0->autoawq)\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==8.9.2.26 from https://files.pythonhosted.org/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.0->autoawq)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.0->autoawq)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.0->autoawq)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.0->autoawq)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.0->autoawq)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch>=2.1.0->autoawq)\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.0->autoawq)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch>=2.1.0->autoawq)\n",
      "  Obtaining dependency information for triton==2.1.0 from https://files.pythonhosted.org/packages/d1/5a/e5811fcc8fc6703be39eb157af6224eaa3b628a42008df93b87e23eb9731/triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Using cached triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->autoawq)\n",
      "  Obtaining dependency information for nvidia-nvjitlink-cu12 from https://files.pythonhosted.org/packages/45/de/885b6d3e1fa07bf19124076b348d3cf30f68051f813cba99e103f53d2f75/nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Using cached nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/lev/.local/lib/python3.9/site-packages (from transformers>=4.35.0->autoawq) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lev/.local/lib/python3.9/site-packages (from transformers>=4.35.0->autoawq) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/lev/.local/lib/python3.9/site-packages (from transformers>=4.35.0->autoawq) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/lev/.local/lib/python3.9/site-packages (from transformers>=4.35.0->autoawq) (2023.5.5)\n",
      "Requirement already satisfied: requests in /home/lev/.local/lib/python3.9/site-packages (from transformers>=4.35.0->autoawq) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/lev/.local/lib/python3.9/site-packages (from transformers>=4.35.0->autoawq) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/lev/.local/lib/python3.9/site-packages (from transformers>=4.35.0->autoawq) (4.65.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->autoawq) (5.9.5)\n",
      "Collecting rootpath>=0.1.0 (from attributedict->autoawq)\n",
      "  Using cached rootpath-0.1.1-py3-none-any.whl (15 kB)\n",
      "Collecting inspecta>=0.1.0 (from attributedict->autoawq)\n",
      "  Using cached inspecta-0.1.3-py3-none-any.whl (9.2 kB)\n",
      "Collecting colour-runner>=0.0.5 (from attributedict->autoawq)\n",
      "  Using cached colour_runner-0.1.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: deepdiff>=3.3.0 in /home/lev/.local/lib/python3.9/site-packages (from attributedict->autoawq) (6.4.1)\n",
      "Collecting tox>=3.0.0 (from attributedict->autoawq)\n",
      "  Obtaining dependency information for tox>=3.0.0 from https://files.pythonhosted.org/packages/f5/f9/963052e8b825645c54262dce7b7c88691505e3b9ee10a3e3667711eaaf21/tox-4.11.3-py3-none-any.whl.metadata\n",
      "  Using cached tox-4.11.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting coverage>=4.5.2 (from attributedict->autoawq)\n",
      "  Obtaining dependency information for coverage>=4.5.2 from https://files.pythonhosted.org/packages/f1/e7/6d778d717d178c8c73103e2c467f3c8d8ebc9cacb825ebe3f3cf05e7c6df/coverage-7.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached coverage-7.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting codecov>=2.0.15 (from attributedict->autoawq)\n",
      "  Using cached codecov-2.1.13-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/lev/.local/lib/python3.9/site-packages (from lm-eval->autoawq) (2.12.0)\n",
      "Requirement already satisfied: jsonlines in /home/lev/.local/lib/python3.9/site-packages (from lm-eval->autoawq) (4.0.0)\n",
      "Requirement already satisfied: numexpr in /home/lev/.local/lib/python3.9/site-packages (from lm-eval->autoawq) (2.8.5)\n",
      "Requirement already satisfied: openai>=0.6.4 in /home/lev/.local/lib/python3.9/site-packages (from lm-eval->autoawq) (0.27.9)\n",
      "Collecting pybind11>=2.6.2 (from lm-eval->autoawq)\n",
      "  Obtaining dependency information for pybind11>=2.6.2 from https://files.pythonhosted.org/packages/06/55/9f73c32dda93fa4f539fafa268f9504e83c489f460c380371d94296126cd/pybind11-2.11.1-py3-none-any.whl.metadata\n",
      "  Using cached pybind11-2.11.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting pycountry (from lm-eval->autoawq)\n",
      "  Using cached pycountry-22.3.5.tar.gz (10.1 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytablewriter (from lm-eval->autoawq)\n",
      "  Obtaining dependency information for pytablewriter from https://files.pythonhosted.org/packages/06/74/b39b823ee7dba155b117634e62733a0dfdfe5aa100a553b435062cee2062/pytablewriter-1.2.0-py3-none-any.whl.metadata\n",
      "  Using cached pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting rouge-score>=0.0.4 (from lm-eval->autoawq)\n",
      "  Using cached rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacrebleu==1.5.0 (from lm-eval->autoawq)\n",
      "  Using cached sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /home/lev/.local/lib/python3.9/site-packages (from lm-eval->autoawq) (1.2.2)\n",
      "Collecting sqlitedict (from lm-eval->autoawq)\n",
      "  Using cached sqlitedict-2.1.0-py3-none-any.whl\n",
      "Collecting tqdm-multiprocess (from lm-eval->autoawq)\n",
      "  Using cached tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
      "Collecting zstandard (from lm-eval->autoawq)\n",
      "  Obtaining dependency information for zstandard from https://files.pythonhosted.org/packages/85/96/61a79e9e9c9e14e5e1baf84fd71115944320bac525fcd754695ba84e2084/zstandard-0.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached zstandard-0.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
      "Collecting portalocker (from sacrebleu==1.5.0->lm-eval->autoawq)\n",
      "  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from autoawq)\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/8b/64/00e53316beb2f19edcaa0eb283b6087cb4d5275112f24b8ea0d8b49c1d5f/torchvision-0.16.0-cp39-cp39-manylinux1_x86_64.whl.metadata\n",
      "  Using cached torchvision-0.16.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/lev/.local/lib/python3.9/site-packages (from torchvision->autoawq) (10.0.0)\n",
      "Collecting blessings (from colour-runner>=0.0.5->attributedict->autoawq)\n",
      "  Using cached blessings-1.7-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pygments in /home/lev/.local/lib/python3.9/site-packages (from colour-runner>=0.0.5->attributedict->autoawq) (2.15.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/lev/.local/lib/python3.9/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/lev/.local/lib/python3.9/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/lev/.local/lib/python3.9/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (2.0.2)\n",
      "Requirement already satisfied: xxhash in /home/lev/.local/lib/python3.9/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /home/lev/.local/lib/python3.9/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /home/lev/.local/lib/python3.9/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in /home/lev/.local/lib/python3.9/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (0.18.0)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /home/lev/.local/lib/python3.9/site-packages (from deepdiff>=3.3.0->attributedict->autoawq) (4.1.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/lev/.local/lib/python3.9/site-packages (from inspecta>=0.1.0->attributedict->autoawq) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/lev/.local/lib/python3.9/site-packages (from inspecta>=0.1.0->attributedict->autoawq) (2.3.0)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/lev/.local/lib/python3.9/site-packages/Pillow-10.0.0.dist-info/METADATA'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install autoawq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/lev/code/research/ai/play_around/sparse_coding', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '', '/home/lev/.local/lib/python3.9/site-packages', '/usr/local/lib/python3.9/dist-packages', '/usr/lib/python3/dist-packages', 'AutoAWQ', '/tmp/tmpsa3nr0c_', 'AutoAWQ']\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'awq_inference_engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/lev/code/research/ai/play_around/sparse_coding/quantized.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdebian-desktop/home/lev/code/research/ai/play_around/sparse_coding/quantized.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39mAutoAWQ\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdebian-desktop/home/lev/code/research/ai/play_around/sparse_coding/quantized.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(sys\u001b[39m.\u001b[39mpath)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdebian-desktop/home/lev/code/research/ai/play_around/sparse_coding/quantized.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mAutoAWQ\u001b[39;00m \u001b[39mimport\u001b[39;00m awq\n",
      "File \u001b[0;32m~/code/research/ai/play_around/sparse_coding/AutoAWQ/awq/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.1.6\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoAWQForCausalLM\n",
      "File \u001b[0;32m~/code/research/ai/play_around/sparse_coding/AutoAWQ/awq/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.1.6\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoAWQForCausalLM\n",
      "File \u001b[0;32m~/code/research/ai/play_around/sparse_coding/AutoAWQ/awq/models/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmpt\u001b[39;00m \u001b[39mimport\u001b[39;00m MptAWQForCausalLM\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mllama\u001b[39;00m \u001b[39mimport\u001b[39;00m LlamaAWQForCausalLM\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mopt\u001b[39;00m \u001b[39mimport\u001b[39;00m OptAWQForCausalLM\n",
      "File \u001b[0;32m~/code/research/ai/play_around/sparse_coding/AutoAWQ/awq/models/mpt.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseAWQForCausalLM\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmpt\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_mpt\u001b[39;00m \u001b[39mimport\u001b[39;00m MptBlock \u001b[39mas\u001b[39;00m OldMptBlock, MptForCausalLM\n\u001b[1;32m      4\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMptAWQForCausalLM\u001b[39;00m(BaseAWQForCausalLM):\n",
      "File \u001b[0;32m~/code/research/ai/play_around/sparse_coding/AutoAWQ/awq/models/base.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mact\u001b[39;00m \u001b[39mimport\u001b[39;00m ScaledActivation\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m \u001b[39mimport\u001b[39;00m snapshot_download\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantize\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantizer\u001b[39;00m \u001b[39mimport\u001b[39;00m AwqQuantizer\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m shard_checkpoint\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear\u001b[39;00m \u001b[39mimport\u001b[39;00m WQLinear_GEMM, WQLinear_GEMV\n",
      "File \u001b[0;32m~/code/research/ai/play_around/sparse_coding/AutoAWQ/awq/quantize/quantizer.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcalib_data\u001b[39;00m \u001b[39mimport\u001b[39;00m get_calib_dataset\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantize\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscale\u001b[39;00m \u001b[39mimport\u001b[39;00m apply_scale, apply_clip\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear\u001b[39;00m \u001b[39mimport\u001b[39;00m WQLinear_GEMM, WQLinear_GEMV\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodule\u001b[39;00m \u001b[39mimport\u001b[39;00m append_str_prefix, get_op_name, get_named_linears, set_op_by_name\n\u001b[1;32m     15\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mAwqQuantizer\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/research/ai/play_around/sparse_coding/AutoAWQ/awq/modules/linear.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mawq_inference_engine\u001b[39;00m  \u001b[39m# with CUDA kernels\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_divisible\u001b[39m(c, divisor):\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m (c \u001b[39m+\u001b[39m divisor \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m divisor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'awq_inference_engine'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append('AutoAWQ')\n",
    "print(sys.path)\n",
    "\n",
    "from AutoAWQ import awq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoAWQForCausalLM' from 'AutoAWQ' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/lev/code/research/ai/play_around/sparse_coding/quantized.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdebian-desktop/home/lev/code/research/ai/play_around/sparse_coding/quantized.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdebian-desktop/home/lev/code/research/ai/play_around/sparse_coding/quantized.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdebian-desktop/home/lev/code/research/ai/play_around/sparse_coding/quantized.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mAutoAWQ\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoAWQForCausalLM\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdebian-desktop/home/lev/code/research/ai/play_around/sparse_coding/quantized.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mybelkada/opt-125m-awq\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdebian-desktop/home/lev/code/research/ai/play_around/sparse_coding/quantized.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m AutoAWQForCausalLM\u001b[39m.\u001b[39mfrom_quantized(model, fuse_layers\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdebian-desktop/home/lev/code/research/ai/play_around/sparse_coding/quantized.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m                                           trust_remote_code\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, safetensors\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AutoAWQForCausalLM' from 'AutoAWQ' (unknown location)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers \n",
    "import torch\n",
    "from AutoAWQ import AutoAWQForCausalLM\n",
    "model = \"ybelkada/opt-125m-awq\"\n",
    "\n",
    "model = AutoAWQForCausalLM.from_quantized(model, fuse_layers=True,\n",
    "                                          trust_remote_code=False, safetensors=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "\t\tdevice=device\n",
    ")\n",
    "\n",
    "prompt = \"How to get in a good university?\"\n",
    "formatted_prompt = (\n",
    "    f\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "sequences = pipeline(\n",
    "    formatted_prompt,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p = 0.9,\n",
    "    num_return_sequences=1,\n",
    "    repetition_penalty=1.1,\n",
    "    max_new_tokens=1024,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, activation_size, n_dict_components, t_type=torch.float16):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        #Â create decoder using float16 to save memory\n",
    "        self.decoder = nn.Linear(n_dict_components, activation_size, bias=False)\n",
    "        # Initialize the decoder weights orthogonally\n",
    "        nn.init.orthogonal_(self.decoder.weight)\n",
    "        self.decoder = self.decoder.to(t_type)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(activation_size, n_dict_components).to(t_type),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        c = self.encoder(x)\n",
    "        # Apply unit norm constraint to the decoder weights\n",
    "        self.decoder.weight.data = nn.functional.normalize(self.decoder.weight.data, dim=0)\n",
    "    \n",
    "        x_hat = self.decoder(c)\n",
    "        return x_hat, c\n",
    "    \n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "    \n",
    "\n",
    "import pickle\n",
    "\n",
    "filename = r'/root/sparse_coding/auto_encoders.pkl'\n",
    "\n",
    "# Load the pickle file\n",
    "with open(filename, 'rb') as file:\n",
    "    autoencoders = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries = [autoencoder.decoder.weight.data.T for autoencoder in autoencoders[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dictionaries:\n",
    "    print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_dict, larger_dict = dictionaries[0], dictionaries[1]\n",
    "smaller_auto_encoder, larger_auto_encoder = autoencoders[0][0], autoencoders[0][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary Comparison\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "smaller_dict_features, _ = smaller_dict.shape\n",
    "larger_dict_features, _ = larger_dict.shape\n",
    "larger_dict = larger_dict.to(device)\n",
    "# Hungary algorithm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "# Calculate all cosine similarities and store in a 2D array\n",
    "cos_sims = np.zeros((smaller_dict_features, larger_dict_features))\n",
    "for idx, vector in enumerate(smaller_dict):\n",
    "    cos_sims[idx] = torch.nn.functional.cosine_similarity(vector.to(device), larger_dict, dim=1).cpu().numpy()\n",
    "# Convert to a minimization problem\n",
    "cos_sims = 1 - cos_sims\n",
    "# Use the Hungarian algorithm to solve the assignment problem\n",
    "row_ind, col_ind = linear_sum_assignment(cos_sims)\n",
    "# Retrieve the max cosine similarities and corresponding indices\n",
    "max_cosine_similarities = 1 - cos_sims[row_ind, col_ind]\n",
    "\n",
    "print(max_cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the max cosine similarities in descending order\n",
    "max_indices = np.argsort(max_cosine_similarities)[::-1]\n",
    "max_cosine_similarities[max_indices][:20]\n",
    "(max_cosine_similarities > .9).sum()\n",
    "# Plot histogram of max_cosine_similarities\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(max_cosine_similarities, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model activations & Dictionary Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the Pythia model w/ transformer lens\n",
    "model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downnload dataset\n",
    "from datasets import Dataset, load_dataset\n",
    "dataset_name = \"NeelNanda/pile-10k\"\n",
    "token_amount=25\n",
    "dataset = load_dataset(dataset_name, split=\"train\").map(\n",
    "    lambda x: model.tokenizer(x['text']),\n",
    "    batched=True,\n",
    ").filter(\n",
    "    lambda x: len(x['input_ids']) > token_amount\n",
    ").map(\n",
    "    lambda x: {'input_ids': x['input_ids'][:token_amount]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the model to get the activations\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "neurons = model.W_in.shape[-1]\n",
    "datapoints = dataset.num_rows\n",
    "batch_size = 64\n",
    "layer = 2\n",
    "neuron_activations = torch.zeros((datapoints*token_amount, neurons))\n",
    "dictionary_activations = torch.zeros((datapoints*token_amount, smaller_dict_features))\n",
    "smaller_auto_encoder = smaller_auto_encoder.to(device)\n",
    "\n",
    "with torch.no_grad(), dataset.formatted_as(\"pt\"):\n",
    "    dl = DataLoader(dataset[\"input_ids\"], batch_size=batch_size)\n",
    "    for i, batch in enumerate(tqdm(dl)):\n",
    "        _, cache = model.run_with_cache(batch.to(device))\n",
    "        batched_neuron_activations = rearrange(cache[f\"blocks.{layer}.mlp.hook_post\"], \"b s n -> (b s) n\" )\n",
    "        neuron_activations[i*batch_size*token_amount:(i+1)*batch_size*token_amount,:] = batched_neuron_activations\n",
    "        reconstruction, batched_dictionary_activations = smaller_auto_encoder(batched_neuron_activations)\n",
    "        dictionary_activations[i*batch_size*token_amount:(i+1)*batch_size*token_amount,:] = batched_dictionary_activations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron Sparsity per Feature by Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find corresponding neurons activations between pythia & autoencoder\n",
    "# Get the activations for the best dict features\n",
    "thresholds = [round(0.1*x,1) for x in range(11)]\n",
    "all_activated_neurons = []\n",
    "for threshold in thresholds:\n",
    "    current_activated_neurons = []\n",
    "    for x in range(10):\n",
    "        best_feature = max_indices[x]\n",
    "        best_feature_activations = dictionary_activations[:, best_feature]\n",
    "        # Sort the features by activation, get the indices\n",
    "        nonzero_indices = torch.argsort(best_feature_activations, descending=True)\n",
    "        sorted_indices = nonzero_indices[:10]\n",
    "        t = (neuron_activations[sorted_indices, :] > threshold)\n",
    "        # ( And across the first dim)\n",
    "        t = t.all(dim=0)\n",
    "        neurons_activated = t.sum()\n",
    "        current_activated_neurons.append(neurons_activated)\n",
    "        # print(f\"Feature {x} is active for {t.sum()} neurons\")\n",
    "    all_activated_neurons.append(current_activated_neurons)\n",
    "# Plot boxplot w/ plotly\n",
    "\n",
    "plt.boxplot(all_activated_neurons, labels=thresholds)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Number of neurons activated\")\n",
    "plt.title(\"Features/Neurons activated\")\n",
    "# plt.ylim(0, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of non-zero activations for each feature in the dictionary\n",
    "nonzero_activations = dictionary_activations.count_nonzero(dim=0)\n",
    "# clip to 1\n",
    "nonzero_activations = nonzero_activations.clamp(max=1)\n",
    "# plot against the max cosine similarities\n",
    "# plt.hist(nonzero_activations.cpu().numpy(), bins=100)\n",
    "plt.scatter(max_cosine_similarities, nonzero_activations.cpu().numpy())\n",
    "# x-axis is the max cosine similarity\n",
    "# y-axis is the number of non-zero activations\n",
    "# now setting x-axis\n",
    "plt.xlabel(\"Max Cosine Similarity\")\n",
    "plt.ylabel(\"Number of Non-Zero Activations\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Activation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuitsvis.activations import text_neuron_activations\n",
    "# Get the activations for the best dict features\n",
    "def get_feature_datapoints(feature_index, dictionary_activations, dataset, k=10, setting=\"max\"):\n",
    "    best_feature_activations = dictionary_activations[:, feature_index]\n",
    "    # Sort the features by activation, get the indices\n",
    "    if setting==\"max\":\n",
    "        found_indices = torch.argsort(best_feature_activations, descending=True)[:k]\n",
    "    elif setting==\"uniform\":\n",
    "        sorted_values, sorted_indices = torch.sort(best_feature_activations, descending=True)\n",
    "        nonzero_indices = torch.nonzero(sorted_values)[:, 0]\n",
    "        uniform_indices = torch.linspace(0, nonzero_indices.shape[0]-1, k).round().long()\n",
    "        found_indices = sorted_indices[nonzero_indices][uniform_indices]\n",
    "        # Append the last indice of sorted_indices to found_indices\n",
    "        found_indices = torch.cat((found_indices, torch.tensor([sorted_indices[-1]])))\n",
    "    else: # random\n",
    "        # get nonzero indices\n",
    "        nonzero_indices = torch.nonzero(best_feature_activations)[:, 0]\n",
    "        # shuffle\n",
    "        shuffled_indices = nonzero_indices[torch.randperm(nonzero_indices.shape[0])]\n",
    "        found_indices = shuffled_indices[:k]\n",
    "    datapoint_indices =[np.unravel_index(i, (datapoints, token_amount)) for i in found_indices]\n",
    "    text_list = []\n",
    "    full_text = []\n",
    "    token_list = []\n",
    "    full_token_list = []\n",
    "    for md, s_ind in datapoint_indices:\n",
    "        md = int(md)\n",
    "        s_ind = int(s_ind)\n",
    "        full_tok = torch.tensor(dataset[md][\"input_ids\"])\n",
    "        full_text.append(model.tokenizer.decode(full_tok))\n",
    "        tok = dataset[md][\"input_ids\"][:s_ind+1]\n",
    "        text = model.tokenizer.decode(tok)\n",
    "        text_list.append(text)\n",
    "        token_list.append(tok)\n",
    "        full_token_list.append(full_tok)\n",
    "    return text_list, full_text, token_list, full_token_list\n",
    "\n",
    "def get_neuron_activation(token, feature, model):\n",
    "    with torch.no_grad():\n",
    "        _, cache = model.run_with_cache(token.to(model.cfg.device))\n",
    "        neuron_act_batch = cache[f\"blocks.{layer}.mlp.hook_post\"]\n",
    "        _, act = smaller_auto_encoder(neuron_act_batch)\n",
    "    return act[0, :, feature].tolist()\n",
    "\n",
    "def ablate_text(text, feature, model, setting=\"plot\"):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    display_text_list = []\n",
    "    activation_list = []\n",
    "    for t in text:\n",
    "        # Convert text into tokens\n",
    "        if isinstance(t, str): # If the text is a list of tokens\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            tokens = model.to_tokens(t, prepend_bos=False)\n",
    "        else: # t equals tokens\n",
    "            tokens = t\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "        seq_size = tokens.shape[1]\n",
    "        if(seq_size == 1): # If the text is a single token, we can't ablate it\n",
    "            continue\n",
    "        original = get_neuron_activation(tokens, feature, model)[-1]\n",
    "        changed_activations = torch.zeros(seq_size, device=device).cpu()\n",
    "        for i in range(seq_size):\n",
    "            # Remove the i'th token from the input\n",
    "            ablated_tokens = torch.cat((tokens[:,:i], tokens[:,i+1:]), dim=1)\n",
    "            changed_activations[i] += get_neuron_activation(ablated_tokens, feature, model)[-1]\n",
    "        changed_activations -= original\n",
    "        display_text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "        activation_list += changed_activations.tolist() + [0.0]\n",
    "    activation_list = torch.tensor(activation_list).reshape(-1,1,1)\n",
    "    if setting == \"plot\":\n",
    "        return text_neuron_activations(tokens=display_text_list, activations=activation_list)\n",
    "    else:\n",
    "        return display_text_list, activation_list\n",
    "def visualize_text(text, feature, model, setting=\"plot\"):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    display_text_list = []\n",
    "    act_list = []\n",
    "    for t in text:\n",
    "        if isinstance(t, str): # If the text is a list of tokens\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            token = model.to_tokens(t, prepend_bos=False)\n",
    "        else: # t are tokens\n",
    "            token = t\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "        display_text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "        act_list += get_neuron_activation(token, feature, model) + [0.0]\n",
    "    act_list = torch.tensor(act_list).reshape(-1,1,1)\n",
    "    return text_neuron_activations(tokens=display_text_list, activations=act_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=10\n",
    "# best_feature_activations = get_feature_datapoints(best_feature, dictionary_activations, dataset, setting=\"uniform\")\n",
    "# sorted_values, sorted_indices = torch.sort(best_feature_activations, descending=True)\n",
    "# nonzero_indices = torch.nonzero(sorted_values)[:, 0]\n",
    "\n",
    "# uniform_indices = torch.linspace(0, nonzero_indices.shape[0]-1, k).round().long()\n",
    "# found_indices = sorted_indices[nonzero_indices][uniform_indices]\n",
    "# # Append the last indice of sorted_indices to found_indices\n",
    "# found_indices = torch.cat((found_indices, torch.tensor([sorted_indices[-1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_indices, found_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablate the feature direction of the tokens\n",
    "# token_list is a list of tokens, convert to tensor of shape (batch_size, seq_len)\n",
    "from einops import rearrange\n",
    "def ablate_feature_direction(tokens, feature, model, autoencoder):\n",
    "    def mlp_ablation_hook(value, hook):\n",
    "        # Rearrange to fit autoencoder\n",
    "        int_val = rearrange(value, 'b s h -> (b s) h')\n",
    "\n",
    "        # Run through the autoencoder\n",
    "        _, act = autoencoder(int_val)\n",
    "        feature_to_ablate = feature # TODO: bring this out of the function\n",
    "\n",
    "        # Subtract value with feature direction*act_of_feature\n",
    "        feature_direction = torch.outer(act[:, feature_to_ablate], autoencoder.decoder.weight[:, feature_to_ablate])\n",
    "        batch, seq_len, hidden_size = value.shape\n",
    "        feature_direction = rearrange(feature_direction, '(b s) h -> b s h', b=batch, s=seq_len)\n",
    "        value -= feature_direction\n",
    "        return value\n",
    "    # def mlp_ablation_hook(value, hook):\n",
    "    #     # Rearrange to fit autoencoder\n",
    "    #     int_val = rearrange(value, 'b s h -> (b s) h')\n",
    "\n",
    "    #     # Run through the autoencoder\n",
    "    #     _, act = autoencoder(int_val)\n",
    "    #     feature_to_ablate = feature # TODO: bring this out of the function\n",
    "\n",
    "    #     # Subtract value with feature direction*act_of_feature\n",
    "    #     feature_direction = torch.outer(act[:, feature_to_ablate], autoencoder.decoder.weight[:, feature_to_ablate])\n",
    "    #     batch, seq_len, hidden_size = value.shape\n",
    "    #     feature_direction = rearrange(feature_direction, '(b s) h -> b s h', b=batch, s=seq_len)\n",
    "    #     value -= feature_direction\n",
    "    #     return value\n",
    "\n",
    "    return model.run_with_hooks(tokens, \n",
    "        fwd_hooks=[(\n",
    "            f\"blocks.{layer}.mlp.hook_post\", \n",
    "            mlp_ablation_hook\n",
    "            )]\n",
    "        )\n",
    "def visualize_logit_diff(text, features=None, setting=\"true_tokens\", verbose=False):\n",
    "    text = full_text\n",
    "    features = best_feature\n",
    "\n",
    "    if features==None:\n",
    "        features = torch.tensor([best_feature])\n",
    "    if isinstance(features, int):\n",
    "        features = torch.tensor([features])\n",
    "    if isinstance(features, list):\n",
    "        features = torch.tensor(features)\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    text_list = []\n",
    "    logit_list = []\n",
    "    for t in text:\n",
    "        tokens = model.to_tokens(t, prepend_bos=False)\n",
    "        with torch.no_grad():\n",
    "            original_logits = model(tokens).log_softmax(-1).cpu()\n",
    "            ablated_logits = ablate_feature_direction(tokens, features, model, smaller_auto_encoder).log_softmax(-1).cpu()\n",
    "        diff_logits = ablated_logits  - original_logits# ablated > original -> negative diff\n",
    "        tokens = tokens.cpu()\n",
    "        if setting == \"true_tokens\":\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            gather_tokens = rearrange(tokens[:,1:], \"b s -> b s 1\") # TODO: verify this is correct\n",
    "            # Gather the logits for the true tokens\n",
    "            diff = rearrange(diff_logits[:, :-1].gather(-1,gather_tokens), \"b s n -> (b s n)\")\n",
    "        elif setting == \"max\":\n",
    "            # Negate the diff_logits to see which tokens have the largest effect on the neuron\n",
    "            val, ind = (-1*diff_logits).max(-1)\n",
    "            diff = rearrange(val[:, :-1], \"b s -> (b s)\")\n",
    "            diff*= -1 # Negate the values gathered\n",
    "            split_text = model.to_str_tokens(ind, prepend_bos=False)\n",
    "            gather_tokens = rearrange(ind[:,1:], \"1 s -> 1 s 1\")\n",
    "        split_text = split_text[1:] # Remove the first token since we're not predicting it\n",
    "        if(verbose):\n",
    "            text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            orig = rearrange(original_logits[:, :-1].gather(-1, gather_tokens), \"b s n -> (b s n)\")\n",
    "            ablated = rearrange(ablated_logits[:, :-1].gather(-1, gather_tokens), \"b s n -> (b s n)\")\n",
    "            logit_list += orig.tolist() + [0.0]\n",
    "            logit_list += ablated.tolist() + [0.0]\n",
    "        text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "        logit_list += diff.tolist() + [0.0]\n",
    "    logit_list = torch.tensor(logit_list).reshape(-1,1,1)\n",
    "    if verbose:\n",
    "        print(f\"Max & Min logit-diff: {logit_list.max().item():.2f} & {logit_list.min().item():.2f}\")\n",
    "    return text_neuron_activations(tokens=text_list, activations=logit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mcs= True\n",
    "if max_mcs:\n",
    "    N = 6\n",
    "    best_feature = max_indices[N]\n",
    "else: # by threshold\n",
    "    threshold = 0.3\n",
    "    error = 0.01\n",
    "    max_cosine_similarities[max_indices]\n",
    "    threshold_indices = np.nonzero((max_cosine_similarities[max_indices] > threshold-error) & (max_cosine_similarities[max_indices] < threshold+error))\n",
    "    N = threshold_indices[0][0]\n",
    "    best_feature = max_indices[N]\n",
    "\n",
    "print(f\"Max feature index: {N}\")\n",
    "print(f\"MCS: {max_cosine_similarities[best_feature]}\")\n",
    "text_list, full_text, token_list, full_token_list = get_feature_datapoints(best_feature, dictionary_activations, dataset, setting=\"max\")\n",
    "visualize_text(text_list, best_feature, model, setting=\"plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablate_text(text_list, best_feature, model, setting=\"plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_logit_diff(full_text, best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of top-k examples, just random samples from non-zero values\n",
    "text_list, full_text, _, _ = get_feature_datapoints(best_feature, dictionary_activations, dataset, setting=\"uniform\", k=10)\n",
    "visualize_text(text_list, best_feature, model, setting=\"plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific examples\n",
    "\n",
    "#f5\n",
    "text_list = [\n",
    "    ' I do.\"\"',\n",
    "    'I do\"\"',\n",
    "    'I do?\"\"',\n",
    "    \"I do''\"\n",
    "\n",
    "]\n",
    "#f52\n",
    "text_list = [\n",
    "    \" $\",\n",
    "    \" for $\",\n",
    "    \" integral $\",\n",
    "    \" for integral $\",\n",
    "    \" sold $\",\n",
    "    \" hey $\",\n",
    "    \" 1 $\",\n",
    "    \" sold for $\",\n",
    "    \" for all $\",\n",
    "    \" sold for all $\",\n",
    "    \" profit for all $\",\n",
    "    \" \\nfor all $\",\n",
    "    \" {] for all $\",\n",
    "]\n",
    "#f3?\n",
    "text_list = [\n",
    "    \"www\",\n",
    "    \" www.\",\n",
    "    \" vol. www.\",\n",
    "    # \" go to the www.\",\n",
    "    \" vol www.\",\n",
    "    \"://aaa\"\n",
    "    \" http://aaa\",\n",
    "]\n",
    "#f4\n",
    "text_list = [\n",
    "    \"' '\",\n",
    "    '\" \"',\n",
    "    '?\" \"',\n",
    "    '.\" \"',\n",
    "    '.\" \\'',\n",
    "    '.\" d',\n",
    "    '.\" }',\n",
    "    '.\" 1',\n",
    "    ' \"',\n",
    "]\n",
    "#f5\n",
    "text_list = [\n",
    "    \"-type\",\n",
    "    \" silica nanoparticles multidrug resistance\",\n",
    "    \" type-type-type\",\n",
    "]\n",
    "#f6\n",
    "text_list = [\n",
    "    \"*n\",\n",
    "    \"*j\",\n",
    "    \"*5\",\n",
    "    \"xn\",\n",
    "    \"4n\",\n",
    "    \"*]\",\n",
    "]\n",
    "\n",
    "visualize_text(text_list, best_feature, model, setting=\"plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify $ feature is math related & anti-money\n",
    "# minimal_activating_example = \" for all $\" # f52 (GOOD)\n",
    "# minimal_activating_example = \". www.\" # f3 (???)\n",
    "# minimal_activating_example = ' \"' # f4 (GOOD)\n",
    "# minimal_activating_example = 'type' # f5 (BAD/ misleading)\n",
    "# minimal_activating_example = '-type' # f5 (BAD/ misleading)\n",
    "# minimal_activating_example = '*' # f6 (GOOD)\n",
    "# minimal_activating_example = 'n' # f6 (GOOD)\n",
    "minimal_activating_example = ' carl' # f6 (GOOD)\n",
    "\n",
    "def prepend_all_tokens_and_get_feature_activation(model, minimal_activating_example, feature, setting=\"prepend\"):\n",
    "    tokens = model.to_tokens(minimal_activating_example, prepend_bos=False)\n",
    "\n",
    "    # Run through every number up to vocab size\n",
    "    vocab_size = model.cfg.d_vocab\n",
    "    batch_size = 256*4  # Define your desired batch size\n",
    "\n",
    "    dollar_feature_activations = torch.zeros(vocab_size)\n",
    "    for start in range(0, vocab_size, batch_size):\n",
    "        end = min(start + batch_size, vocab_size)\n",
    "\n",
    "        token_prep = torch.arange(start, end).to(device)\n",
    "        token_prep = token_prep.unsqueeze(1)  # Add a dimension for concatenation\n",
    "\n",
    "        # 1. Prepend to the tokens\n",
    "        if setting == \"prepend\":\n",
    "            tokens_catted = torch.cat((token_prep, tokens.repeat(end - start, 1)), dim=1)\n",
    "        elif setting == \"append\":\n",
    "            tokens_catted = torch.cat((tokens.repeat(end - start, 1), token_prep), dim=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown setting: {setting}\")\n",
    "\n",
    "        # 2. Run through the model\n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(tokens_catted.to(device))\n",
    "            neuron_act_batch = cache[f\"blocks.{layer}.mlp.hook_post\"]\n",
    "            _, act = smaller_auto_encoder(neuron_act_batch)\n",
    "\n",
    "        # 3. Get the feature\n",
    "        dollar_feature_activations[start:end] = act[:, -1, feature].cpu().squeeze()\n",
    "\n",
    "    k = 20\n",
    "    k_increasing_val, k_increasing_ind = dollar_feature_activations.topk(k)\n",
    "    k_decreasing_val, k_decreasing_ind = dollar_feature_activations.topk(k, largest=False)\n",
    "    if(setting == \"prepend\"):\n",
    "        print(f\"[token]{minimal_activating_example}\")\n",
    "    elif(setting == \"append\"):\n",
    "        print(f\"{minimal_activating_example}[token]\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown setting: {setting}\")\n",
    "    # Print indices converted to tokens\n",
    "    print(f\"Top-{k} increasing: {model.to_str_tokens(k_increasing_ind)}\")\n",
    "    # Print values\n",
    "    print(f\"Top-{k} increasing: {[f'{val:.2f}' for val in k_increasing_val]}\")\n",
    "    print(f\"Top-{k} decreasing: {model.to_str_tokens(k_decreasing_ind)}\")\n",
    "    print(f\"Top-{k} decreasing: {[f'{val:.2f}' for val in k_decreasing_val]}\")\n",
    "\n",
    "# F6\n",
    "prepend_all_tokens_and_get_feature_activation(model, \"*\", best_feature, setting=\"append\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \"*\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \"n\", best_feature, setting=\"append\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \"n\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" Alice\", best_feature, setting=\"append\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" Alice\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \"*\", best_feature, setting=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_prep.unsqueeze(0).shape, tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cfg.d_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neurons that fire for this feature\n",
    "# Find corresponding neurons activations between pythia & autoencoder\n",
    "# Get the activations for the best dict features\n",
    "len_threshold = 11\n",
    "thresholds = [round(0.1*x,1) for x in range(len_threshold)]\n",
    "current_activated_neurons = np.zeros(len_threshold)\n",
    "for idx, threshold in enumerate(thresholds):\n",
    "    best_feature_activations = dictionary_activations[:, best_feature]\n",
    "    # Sort the features by activation, get the indices\n",
    "    nonzero_indices = torch.argsort(best_feature_activations, descending=True)\n",
    "    sorted_indices = nonzero_indices[:10]\n",
    "    t = (neuron_activations[sorted_indices, :] > threshold)\n",
    "    # And across the first dim)\n",
    "    t = t.all(dim=0)\n",
    "    neurons_activated = t.sum()\n",
    "    current_activated_neurons[idx] = neurons_activated\n",
    "    print(f\"Threshold: {threshold}, Neurons activated: {neurons_activated}\")\n",
    "# Plot boxplot w/ plotly\n",
    "plt.scatter(thresholds, current_activated_neurons)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Number of neurons activated\")\n",
    "plt.title(\"Features/Neurons activated\")\n",
    "plt.ylim(0, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logit lens\n",
    "# Multiply feature direction by W_out[layer]\n",
    "# Then by W_U\n",
    "for n in range(10):\n",
    "    best_feature = max_indices[n]\n",
    "    with torch.no_grad():\n",
    "        feature_direction = smaller_dict[best_feature].to(device)\n",
    "        residual_direction = torch.matmul(feature_direction, model.W_out[layer]) # Add bias\n",
    "        # residual_direction = model.ln_final(residual_direction)\n",
    "        logits = torch.matmul(residual_direction, model.W_U).cpu()\n",
    "    topk_values, topk_indices = torch.topk(logits, 10)\n",
    "    top_text = model.to_str_tokens(topk_indices)\n",
    "    print(f\"Feature {n}: {top_text}\")\n",
    "# print(topk_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import circuitsvis\n",
    "text = full_text\n",
    "features = best_feature\n",
    "\n",
    "if features==None:\n",
    "    features = torch.tensor([best_feature])\n",
    "if isinstance(features, int):\n",
    "    features = torch.tensor([features])\n",
    "if isinstance(features, list):\n",
    "    features = torch.tensor(features)\n",
    "if isinstance(text, str):\n",
    "    text = [text]\n",
    "text_list = []\n",
    "logit_list = []\n",
    "for t in text:\n",
    "    tokens = model.to_tokens(t, prepend_bos=False)\n",
    "    with torch.no_grad():\n",
    "        original_logits = model(tokens).log_softmax(-1).cpu()\n",
    "        ablated_logits = ablate_feature_direction(tokens, features, model, smaller_auto_encoder).log_softmax(-1).cpu()\n",
    "    # diff_logits = ablated_logits  - original_logits# ablated > original -> negative diff\n",
    "    diff_logits =   original_logits - ablated_logits# ablated > original -> negative diff\n",
    "    tokens = tokens.cpu()\n",
    "    split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "    gather_tokens = rearrange(tokens[:,1:], \"b s -> b s 1\") # TODO: verify this is correct\n",
    "    # Gather the logits for the true tokens\n",
    "    true_log_probs = rearrange(diff_logits[:, :-1].gather(-1,gather_tokens), \"b s n -> (b s n)\")\n",
    "    break\n",
    "# Add an extra dim for the batch\n",
    "diff_logits = diff_logits[0]\n",
    "tokens = tokens[0]\n",
    "print(diff_logits.shape, tokens.shape)\n",
    "# circuitsvis.logits.token_log_probs(token_indices=tokens, top_k=10, log_probs=original_logits, to_string=model.to_single_str_token)\n",
    "circuitsvis.logits.token_log_probs(token_indices=tokens, top_k=10, log_probs=diff_logits, to_string=model.to_single_str_token)\n",
    "# circuitsvis.logits.token_log_probs(token_indices=tokens, top_k=10, log_probs=ablated_logits, to_string=model.to_single_str_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuitsvis.logits.token_log_probs(token_indices=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_logit_diff(full_text, best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablate_text(text_list, best_feature, model, setting=\"plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_auto_encoder.decoder.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 2\n",
    "if isinstance(features, int):\n",
    "    features = torch.tensor([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff = original_logits.log_softmax(dim=-1) - ablated_logits.log_softmax(dim=-1)\n",
    "# Gather the logit difference for the true label\n",
    "predicted_logit_diff = logit_diff[:,:-1].gather(dim=-1, index=all_tokens[:,1:].unsqueeze(-1))\n",
    "predicted_logit_diff = predicted_logit_diff.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff[:, 1:].shape, all_tokens[:,:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the feature direction of the first feature\n",
    "dictionary_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#Plot a histogram\n",
    "import matplotlib.pyplot as plt\n",
    "for x in range(10):\n",
    "    max_elements = (dictionary_activations[:, max_indices[x]]>0.01)\n",
    "    plt.hist(dictionary_activations[max_elements, max_indices[x]], bins=20)\n",
    "    plt.title('Histogram of Activations for Dictionary Element ' + str(x))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#Plot a histogram\n",
    "import matplotlib.pyplot as plt\n",
    "for x in range(10):\n",
    "    print((dictionary_activations[:, max_indices[x]] > 0.0).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "dictionary_activations[:, max_indices[x]].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "import numpy as np \n",
    "from torch import nn\n",
    "import pickle\n",
    "\n",
    "# Define the autoencoder so pickle knows how to serialize it. \n",
    "# Later, we should actually save as a state_dict instead of a dumb pickle\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, activation_size, n_dict_components, t_type=torch.float32, l1_coef=0.0):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # Only defining the decoder layer, encoder will share its weights\n",
    "        self.decoder = nn.Linear(n_dict_components, activation_size, bias=True)\n",
    "        # Create a bias layer\n",
    "        self.encoder_bias= nn.Parameter(torch.zeros(n_dict_components))\n",
    "\n",
    "        \n",
    "        # Initialize the decoder weights orthogonally\n",
    "        nn.init.orthogonal_(self.decoder.weight)\n",
    "        self.decoder = self.decoder.to(t_type)\n",
    "\n",
    "        # Encoder is a Sequential with the ReLU activation\n",
    "        # No need to define a Linear layer for the encoder as its weights are tied with the decoder\n",
    "        self.encoder = nn.Sequential(nn.ReLU()).to(t_type)\n",
    "\n",
    "        self.l1_coef = l1_coef\n",
    "        self.activation_size = activation_size\n",
    "        self.n_dict_components = n_dict_components\n",
    "\n",
    "    def forward(self, x):\n",
    "        c = self.encoder(x @ self.decoder.weight + self.encoder_bias)\n",
    "        # Apply unit norm constraint to the decoder weights\n",
    "        self.decoder.weight.data = nn.functional.normalize(self.decoder.weight.data, dim=0)\n",
    "\n",
    "        # Decoding step as before\n",
    "        x_hat = self.decoder(c)\n",
    "        return x_hat, c\n",
    "\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m-deduped into HookedTransformer\n",
      "torch.Size([512, 512])\n",
      "torch.Size([1024, 512])\n",
      "torch.Size([2048, 512])\n",
      "torch.Size([4096, 512])\n",
      "len of autoencoders:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Change these settings to load the correct autoencoder\n",
    "layer = 2\n",
    "setting = \"residual\"\n",
    "model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "filename = \"/root/sparse_coding/autoencoders/pythia-70m-tied-autoencoder.pkl\"\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)\n",
    "\n",
    "if setting == \"residual\":\n",
    "    cache_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "    neurons = model.cfg.d_model\n",
    "elif setting == \"mlp\":\n",
    "    cache_name = f\"blocks.{layer}.mlp.hook_post\"\n",
    "    neurons = model.cfg.d_mlp\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "# Load the pickle file\n",
    "with open(filename, 'rb') as file:\n",
    "    autoencoders = pickle.load(file)\n",
    "\n",
    "# Index for l1 value, usually only 1 value is available\n",
    "l1_index = -1\n",
    "dictionaries = [autoencoder.decoder.weight.data.T for autoencoder in autoencoders[l1_index]]\n",
    "for d in dictionaries:\n",
    "    print(d.shape)\n",
    "print(\"len of autoencoders: \", len(autoencoders))\n",
    "dict_index = 2\n",
    "smaller_dict, larger_dict = dictionaries[dict_index], dictionaries[dict_index+1]\n",
    "smaller_auto_encoder, larger_auto_encoder = autoencoders[l1_index][dict_index], autoencoders[l1_index][dict_index+1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCS\n",
    "Max cosine similarity between one dictionary & another one. If they learned the same feature, then they'll have high cosine similarity. \n",
    "\n",
    "If two dictionaries learned it, it's probably a real feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# of features above 0.9:', 929)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.pyplot as plt\n",
    "#Dictionary Comparison\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "smaller_dict_features, _ = smaller_dict.shape\n",
    "larger_dict_features, _ = larger_dict.shape\n",
    "larger_dict = larger_dict.to(device)\n",
    "# Hungary algorithm\n",
    "# Calculate all cosine similarities and store in a 2D array\n",
    "cos_sims = np.zeros((smaller_dict_features, larger_dict_features))\n",
    "for idx, vector in enumerate(smaller_dict):\n",
    "    cos_sims[idx] = torch.nn.functional.cosine_similarity(vector.to(device), larger_dict, dim=1).cpu().numpy()\n",
    "# Convert to a minimization problem\n",
    "cos_sims = 1 - cos_sims\n",
    "# Use the Hungarian algorithm to solve the assignment problem\n",
    "row_ind, col_ind = linear_sum_assignment(cos_sims)\n",
    "# Retrieve the max cosine similarities and corresponding indices\n",
    "max_cosine_similarities = 1 - cos_sims[row_ind, col_ind]\n",
    "\n",
    "# Get the indices of the max cosine similarities in descending order\n",
    "max_indices = np.argsort(max_cosine_similarities)[::-1]\n",
    "max_cosine_similarities[max_indices][:20]\n",
    "print((\"# of features above 0.9:\", (max_cosine_similarities > .9).sum()))\n",
    "# Plot histogram of max_cosine_similarities\n",
    "plt.hist(max_cosine_similarities, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model activations & Dictionary Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4683061ef9492b9f5b897d6fbeb691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2606cebd017471899b2dc51d88005aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3a90d9c59f49fca3e2c717f5728c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9938 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Downnload dataset\n",
    "from datasets import Dataset, load_dataset\n",
    "dataset_name = \"NeelNanda/pile-10k\"\n",
    "token_amount=25\n",
    "dataset = load_dataset(dataset_name, split=\"train\").map(\n",
    "    lambda x: model.tokenizer(x['text']),\n",
    "    batched=True,\n",
    ").filter(\n",
    "    lambda x: len(x['input_ids']) > token_amount\n",
    ").map(\n",
    "    lambda x: {'input_ids': x['input_ids'][:token_amount]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdaa83fc1dfb4672a87f48eaaab0db55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we can use the model to get the activations\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "# neurons = model.W_in.shape[-1]\n",
    "neurons = model.cfg.d_model\n",
    "datapoints = dataset.num_rows\n",
    "batch_size = 64\n",
    "neuron_activations = torch.zeros((datapoints*token_amount, neurons))\n",
    "dictionary_activations = torch.zeros((datapoints*token_amount, smaller_dict_features))\n",
    "smaller_auto_encoder = smaller_auto_encoder.to(device)\n",
    "\n",
    "with torch.no_grad(), dataset.formatted_as(\"pt\"):\n",
    "    dl = DataLoader(dataset[\"input_ids\"], batch_size=batch_size)\n",
    "    for i, batch in enumerate(tqdm(dl)):\n",
    "        _, cache = model.run_with_cache(batch.to(device))\n",
    "        batched_neuron_activations = rearrange(cache[cache_name], \"b s n -> (b s) n\" )\n",
    "        neuron_activations[i*batch_size*token_amount:(i+1)*batch_size*token_amount,:] = batched_neuron_activations.cpu()\n",
    "        reconstruction, batched_dictionary_activations = smaller_auto_encoder(batched_neuron_activations)\n",
    "        dictionary_activations[i*batch_size*token_amount:(i+1)*batch_size*token_amount,:] = batched_dictionary_activations.cpu()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Activation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuitsvis.activations import text_neuron_activations\n",
    "# Get the activations for the best dict features\n",
    "def get_feature_datapoints(feature_index, dictionary_activations, dataset, k=10, setting=\"max\"):\n",
    "    best_feature_activations = dictionary_activations[:, feature_index]\n",
    "    # Sort the features by activation, get the indices\n",
    "    if setting==\"max\":\n",
    "        found_indices = torch.argsort(best_feature_activations, descending=True)[:k]\n",
    "    elif setting==\"uniform\":\n",
    "        min_value = torch.min(best_feature_activations)\n",
    "        max_value = torch.max(best_feature_activations)\n",
    "\n",
    "        # Define the number of bins\n",
    "        num_bins = k\n",
    "\n",
    "        # Calculate the bin boundaries as linear interpolation between min and max\n",
    "        bin_boundaries = torch.linspace(min_value, max_value, num_bins + 1)\n",
    "\n",
    "        # Assign each activation to its respective bin\n",
    "        bins = torch.bucketize(best_feature_activations, bin_boundaries)\n",
    "\n",
    "        # Initialize a list to store the sampled indices\n",
    "        sampled_indices = []\n",
    "\n",
    "        # Sample from each bin\n",
    "        for bin_idx in torch.unique(bins):\n",
    "            # Get the indices corresponding to the current bin\n",
    "            bin_indices = torch.nonzero(bins == bin_idx, as_tuple=False).squeeze(dim=1)\n",
    "            \n",
    "            # Randomly sample from the current bin\n",
    "            sampled_indices.extend(np.random.choice(bin_indices, size=1, replace=False))\n",
    "\n",
    "        # Convert the sampled indices to a PyTorch tensor & reverse order\n",
    "        found_indices = torch.tensor(sampled_indices).long().flip(dims=[0])\n",
    "    else: # random\n",
    "        # get nonzero indices\n",
    "        nonzero_indices = torch.nonzero(best_feature_activations)[:, 0]\n",
    "        # shuffle\n",
    "        shuffled_indices = nonzero_indices[torch.randperm(nonzero_indices.shape[0])]\n",
    "        found_indices = shuffled_indices[:k]\n",
    "    datapoint_indices =[np.unravel_index(i, (datapoints, token_amount)) for i in found_indices]\n",
    "    text_list = []\n",
    "    full_text = []\n",
    "    token_list = []\n",
    "    full_token_list = []\n",
    "    for md, s_ind in datapoint_indices:\n",
    "        md = int(md)\n",
    "        s_ind = int(s_ind)\n",
    "        full_tok = torch.tensor(dataset[md][\"input_ids\"])\n",
    "        full_text.append(model.tokenizer.decode(full_tok))\n",
    "        tok = dataset[md][\"input_ids\"][:s_ind+1]\n",
    "        text = model.tokenizer.decode(tok)\n",
    "        text_list.append(text)\n",
    "        token_list.append(tok)\n",
    "        full_token_list.append(full_tok)\n",
    "    return text_list, full_text, token_list, full_token_list\n",
    "\n",
    "def get_neuron_activation(token, feature, model, setting=\"dictionary_basis\"):\n",
    "    with torch.no_grad():\n",
    "        _, cache = model.run_with_cache(token.to(model.cfg.device))\n",
    "        neuron_act_batch = cache[cache_name]\n",
    "        if setting==\"dictionary_basis\":\n",
    "            _, act = smaller_auto_encoder(neuron_act_batch)\n",
    "            return act[0, :, feature].tolist()\n",
    "        else: # neuron/residual basis\n",
    "            return neuron_act_batch[0, :, feature].tolist()\n",
    "\n",
    "def ablate_text(text, feature, model, setting=\"plot\"):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    display_text_list = []\n",
    "    activation_list = []\n",
    "    for t in text:\n",
    "        # Convert text into tokens\n",
    "        if isinstance(t, str): # If the text is a list of tokens\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            tokens = model.to_tokens(t, prepend_bos=False)\n",
    "        else: # t equals tokens\n",
    "            tokens = t\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "        seq_size = tokens.shape[1]\n",
    "        if(seq_size == 1): # If the text is a single token, we can't ablate it\n",
    "            continue\n",
    "        original = get_neuron_activation(tokens, feature, model)[-1]\n",
    "        changed_activations = torch.zeros(seq_size, device=device).cpu()\n",
    "        for i in range(seq_size):\n",
    "            # Remove the i'th token from the input\n",
    "            ablated_tokens = torch.cat((tokens[:,:i], tokens[:,i+1:]), dim=1)\n",
    "            changed_activations[i] += get_neuron_activation(ablated_tokens, feature, model)[-1]\n",
    "        changed_activations -= original\n",
    "        display_text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "        activation_list += changed_activations.tolist() + [0.0]\n",
    "    activation_list = torch.tensor(activation_list).reshape(-1,1,1)\n",
    "    if setting == \"plot\":\n",
    "        return text_neuron_activations(tokens=display_text_list, activations=activation_list)\n",
    "    else:\n",
    "        return display_text_list, activation_list\n",
    "def visualize_text(text, feature, model, setting=\"dictionary_basis\", max_activation = None):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    if isinstance(feature, int):\n",
    "        feature = [feature]\n",
    "    display_text_list = []\n",
    "    act_list = []\n",
    "    for t in text:\n",
    "        if isinstance(t, str): # If the text is a list of tokens\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            token = model.to_tokens(t, prepend_bos=False)\n",
    "        else: # t are tokens\n",
    "            token = t\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "        for f in feature:\n",
    "            display_text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            act_list += get_neuron_activation(token, f, model, setting) + [0.0]\n",
    "    act_list = torch.tensor(act_list).reshape(-1,1,1)\n",
    "    if(max_activation is not None):\n",
    "        act_list = torch.clamp(act_list, max=max_activation)\n",
    "    return text_neuron_activations(tokens=display_text_list, activations=act_list)\n",
    "# Ablate the feature direction of the tokens\n",
    "# token_list is a list of tokens, convert to tensor of shape (batch_size, seq_len)\n",
    "from einops import rearrange\n",
    "def ablate_feature_direction(tokens, feature, model, autoencoder):\n",
    "    def mlp_ablation_hook(value, hook):\n",
    "        # Rearrange to fit autoencoder\n",
    "        int_val = rearrange(value, 'b s h -> (b s) h')\n",
    "\n",
    "        # Run through the autoencoder\n",
    "        _, act = autoencoder(int_val)\n",
    "        feature_to_ablate = feature # TODO: bring this out of the function\n",
    "\n",
    "        # Subtract value with feature direction*act_of_feature\n",
    "        feature_direction = torch.outer(act[:, feature_to_ablate].squeeze(), autoencoder.decoder.weight[:, feature_to_ablate].squeeze())\n",
    "        batch, seq_len, hidden_size = value.shape\n",
    "        feature_direction = rearrange(feature_direction, '(b s) h -> b s h', b=batch, s=seq_len)\n",
    "        value -= feature_direction\n",
    "        return value\n",
    "\n",
    "    return model.run_with_hooks(tokens, \n",
    "        fwd_hooks=[(\n",
    "            cache_name, \n",
    "            mlp_ablation_hook\n",
    "            )]\n",
    "        )\n",
    "def add_feature_direction(tokens, feature, model, autoencoder, scalar=1.0):\n",
    "    def residual_add_hook(value, hook):\n",
    "        feature_direction = autoencoder.decoder.weight[:, feature].squeeze()\n",
    "        value += scalar*feature_direction\n",
    "        return value\n",
    "\n",
    "    return model.run_with_hooks(tokens, \n",
    "        fwd_hooks=[(\n",
    "            cache_name,\n",
    "            residual_add_hook\n",
    "            )]\n",
    "        )\n",
    "def ablate_feature_direction_display(text, features=None, setting=\"true_tokens\", verbose=False):\n",
    "\n",
    "    if features==None:\n",
    "        features = torch.tensor([best_feature])\n",
    "    if isinstance(features, int):\n",
    "        features = torch.tensor([features])\n",
    "    if isinstance(features, list):\n",
    "        features = torch.tensor(features)\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    text_list = []\n",
    "    logit_list = []\n",
    "    for t in text:\n",
    "        tokens = model.to_tokens(t, prepend_bos=False)\n",
    "        with torch.no_grad():\n",
    "            original_logits = model(tokens).log_softmax(-1).cpu()\n",
    "            ablated_logits = ablate_feature_direction(tokens, features, model, smaller_auto_encoder).log_softmax(-1).cpu()\n",
    "        diff_logits = ablated_logits  - original_logits# ablated > original -> negative diff\n",
    "        tokens = tokens.cpu()\n",
    "        if setting == \"true_tokens\":\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            gather_tokens = rearrange(tokens[:,1:], \"b s -> b s 1\") # TODO: verify this is correct\n",
    "            # Gather the logits for the true tokens\n",
    "            diff = rearrange(diff_logits[:, :-1].gather(-1,gather_tokens), \"b s n -> (b s n)\")\n",
    "        elif setting == \"max\":\n",
    "            # Negate the diff_logits to see which tokens have the largest effect on the neuron\n",
    "            val, ind = (-1*diff_logits).max(-1)\n",
    "            diff = rearrange(val[:, :-1], \"b s -> (b s)\")\n",
    "            diff*= -1 # Negate the values gathered\n",
    "            split_text = model.to_str_tokens(ind, prepend_bos=False)\n",
    "            gather_tokens = rearrange(ind[:,1:], \"1 s -> 1 s 1\")\n",
    "        split_text = split_text[1:] # Remove the first token since we're not predicting it\n",
    "        if(verbose):\n",
    "            text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            orig = rearrange(original_logits[:, :-1].gather(-1, gather_tokens), \"b s n -> (b s n)\")\n",
    "            ablated = rearrange(ablated_logits[:, :-1].gather(-1, gather_tokens), \"b s n -> (b s n)\")\n",
    "            logit_list += orig.tolist() + [0.0]\n",
    "            logit_list += ablated.tolist() + [0.0]\n",
    "        text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "        logit_list += diff.tolist() + [0.0]\n",
    "    logit_list = torch.tensor(logit_list).reshape(-1,1,1)\n",
    "    if verbose:\n",
    "        print(f\"Max & Min logit-diff: {logit_list.max().item():.2f} & {logit_list.min().item():.2f}\")\n",
    "    return text_neuron_activations(tokens=text_list, activations=logit_list)\n",
    "def generate_text(input_text, num_tokens, model, autoencoder, feature, temperature=0.7, setting=\"add\", scalar=1.0):\n",
    "    # Convert input text to tokens\n",
    "    input_ids = model.tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "\n",
    "    for _ in range(num_tokens):\n",
    "        # Generate logits\n",
    "        with torch.no_grad():\n",
    "            if(setting==\"add\"):\n",
    "                logits = add_feature_direction(input_ids, feature, model, autoencoder, scalar=scalar)\n",
    "            else:\n",
    "                logits = model(input_ids)\n",
    "\n",
    "        # Apply temperature\n",
    "        logits = logits / temperature\n",
    "\n",
    "        # Sample from the distribution\n",
    "        probs = torch.nn.functional.softmax(logits[:, -1, :], dim=-1)\n",
    "        predicted_token = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        # Append predicted token to input_ids\n",
    "        input_ids = torch.cat((input_ids, predicted_token), dim=-1)\n",
    "\n",
    "    # Decode the tokens to text\n",
    "    output_text = model.tokenizer.decode(input_ids[0])\n",
    "\n",
    "    return output_text\n",
    "\n",
    "# Logit Lens\n",
    "def logit_lens(model, best_feature, smaller_dict, layer):\n",
    "    with torch.no_grad():\n",
    "        # There are never-used tokens, which have high norm. We want to ignore these.\n",
    "        bad_ind = (model.W_U.norm(dim=0) > 20)\n",
    "        feature_direction = smaller_dict[best_feature].to(device)\n",
    "        # feature_direction = torch.matmul(feature_direction, model.W_out[layer]) # if MLP\n",
    "        logits = torch.matmul(feature_direction, model.W_U).cpu()\n",
    "    # Don't include bad indices\n",
    "    logits[bad_ind] = -1000\n",
    "    topk_values, topk_indices = torch.topk(logits, 20)\n",
    "    top_text = model.to_str_tokens(topk_indices)\n",
    "    print(f\"{top_text}\")\n",
    "    print(topk_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text\n",
    "You can use the functions below to find interesting features to then add here to \"feature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:\n",
      " for a certain place.\n",
      "\n",
      "Lilmore\n",
      "\n",
      "The Lilmore is a three-mile\n",
      "Add:\n",
      " for,” LLP LLP LLP LLP LLP LLP Court,” LLPheets,” Court“ He LLP ruled His,”,’\n"
     ]
    }
   ],
   "source": [
    "sentence = \" for\"\n",
    "temp = 0.7\n",
    "tokens_to_generate = 20\n",
    "feature = 10 \n",
    "scalar = 100.0\n",
    "# Using the function:\n",
    "print(\"Normal:\\n\" + generate_text(sentence, tokens_to_generate, model, smaller_auto_encoder, feature=feature, temperature=temp, scalar=scalar, setting=\"normal\"))\n",
    "print(\"Add:\\n\" + generate_text(sentence, tokens_to_generate, model, smaller_auto_encoder, feature=feature, temperature=temp, scalar=scalar, setting=\"add\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Search\n",
    "Type in a sentence & see which features activate \n",
    "Note: Some features may be outliers, which will typically show up as high activations for the first word & first period or \\n (or high positive bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations: [1.69, 1.45, 1.39, 1.21, 0.91, 0.54, 0.49, 0.46, 0.37, 0.28]\n",
      "Feature_ids [1461, 1655, 389, 1309, 444, 82, 1300, 1206, 1901, 798]\n"
     ]
    }
   ],
   "source": [
    "t = \" I do like a\"\n",
    "split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "token = model.to_tokens(t, prepend_bos=False)\n",
    "_, cache = model.run_with_cache(token.to(model.cfg.device))\n",
    "neuron_act_batch = cache[cache_name]\n",
    "_, act = smaller_auto_encoder(neuron_act_batch)\n",
    "v, i = act[0, -1, :].topk(10)\n",
    "\n",
    "print(\"Activations:\",[round(val,2) for val in v.tolist()])\n",
    "print(\"Feature_ids\", i.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Interp\n",
    "Investigate the example sentences the activate this feature.\n",
    "\n",
    "Max: show max activating (tokens,contexts)\n",
    "\n",
    "Uniform: Show range of activations from each bin (e.g. sample an example from 1-2, 2-3, etc). \n",
    "[Note: if a feature is monosemantic, then the full range of activations should be that feature, not just max-activating ones]\n",
    "\n",
    "Full_text: shows the full text example\n",
    "\n",
    "Text_list: shows up to the most activating example (try w/ max activating on a couple of examples to see)\n",
    "\n",
    "ablate_text: remove the context one token at a time, and show the decrease/increase in activation of that feature\n",
    "\n",
    "ablate_feature_direction: removes feature direction from model's activation mid-inference, showing the logit diff in the output for every token.\n",
    "\n",
    "logit_lens: show the logit lens for that feature. If matches ablate_feature_direction, then the computation path is through the residual stream, else, it's through future layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias: -2.4709394\n",
      "Feature index: 1461\n",
      "MCS: 0.9889528751373291\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-fe58afb3-4d14\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-fe58afb3-4d14\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"my\", \" mum\", \" was\", \" unemployed\", \" for\", \" a\", \" while\", \" I\", \" never\", \" had\", \" a\", \" bab\", \"ys\", \"itter\", \" till\", \" I\", \" was\", \" ten\", \" anyway\", \".\", \" So\", \" my\", \" mum\", \" got\", \" a\", \"\\n\", \"A\", \"head\", \" of\", \" Mother\", \"\\u2019\", \"s\", \" Day\", \" next\", \" weekend\", \",\", \" Apple\", \"\\u2019\", \"s\", \" weekly\", \" Apple\", \" Pay\", \" promotions\", \" have\", \" made\", \" a\", \" return\", \".\", \" This\", \" time\", \",\", \"\\n\", \"In\", \" August\", \" 2012\", \",\", \" Mark\", \" Car\", \"ney\", \",\", \" then\", \" governor\", \" of\", \" the\", \" Bank\", \" of\", \" Canada\", \",\", \" made\", \" a\", \" speech\", \" to\", \" the\", \" Canadian\", \" Auto\", \" Workers\", \" about\", \"\\n\", \"A\", \" hum\", \"orous\", \" view\", \" of\", \" politics\", \",\", \" religion\", \",\", \" human\", \" behavior\", \",\", \" and\", \" insights\", \" toward\", \" everyday\", \" happen\", \"ings\", \" by\", \" a\", \" single\", \" guy\", \" living\", \" in\", \" downtown\", \"\\n\", \"Q\", \":\", \"\\\\newline\", \"\\\\newline\", \"R\", \"ails\", \" 4\", \".\", \"where\", \" nested\", \" model\", \" search\", \"\\\\newline\", \"\\\\newline\", \"Hi\", \",\", \"\\\\newline\", \"I\", \" have\", \" a\", \" Model\", \" of\", \" Users\", \" and\", \" a\", \"\\n\", \"M\", \"icrobial\", \" systems\", \" biology\", \":\", \" new\", \" front\", \"iers\", \" open\", \" to\", \" predictive\", \" microbi\", \"ology\", \".\", \"\\\\newline\", \"The\", \" field\", \" of\", \" Systems\", \" Biology\", \" is\", \" a\", \" rapidly\", \" evolving\", \" area\", \"\\n\", \"Forg\", \"otten\", \" password\", \"\\\\newline\", \"\\\\newline\", \"N\", \"iche\", \" Jobs\", \" Ltd\", \" Privacy\", \" Policy\", \"\\\\newline\", \"\\\\newline\", \"N\", \"urs\", \"es\", \".\", \"co\", \".\", \"uk\", \" is\", \" a\", \" job\", \" advertising\", \" website\", \"\\n\", \"This\", \" week\", \",\", \" a\", \" giant\", \" political\", \" volcano\", \" has\", \" been\", \" showing\", \" signs\", \" that\", \" it\", \" is\", \" about\", \" to\", \" erupt\", \",\", \" though\", \" most\", \" of\", \" the\", \" news\", \" media\", \",\", \"\\n\", \"Q\", \":\", \"\\\\newline\", \"\\\\newline\", \"How\", \" to\", \" determine\", \" the\", \" confidence\", \" of\", \" a\", \" neural\", \" network\", \" prediction\", \"?\", \"\\\\newline\", \"\\\\newline\", \"To\", \" illustrate\", \" my\", \" question\", \",\", \" suppose\", \" that\", \" I\", \"\\n\", \"This\", \" Teen\", \" Nearly\", \" D\", \"ied\", \" In\", \" A\", \" School\", \" Sh\", \"ooting\", \".\", \" Now\", \" She\", \"'s\", \" Just\", \" Trying\", \" To\", \" Live\", \"\\\\newline\", \"\\\\newline\", \"En\", \"large\", \" this\", \" image\", \" toggle\", \"\\n\", \"The\", \" reason\", \" that\", \" I\", \" was\", \" quite\", \" silent\", \" during\", \" the\", \" last\", \" days\", \" is\", \" called\", \" W\", \"ACK\", \".\", \" It\", \" is\", \" something\", \" that\", \" my\", \" colleague\", \" Man\", \"fred\", \" Weber\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.3379318714141846]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.1571781635284424]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[3.1857759952545166]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.5684597492218018]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.460825204849243]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.9642374515533447]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.8434703350067139]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.6497533321380615]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.2846143245697021]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.2079126834869385]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.8274567127227783]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.4456980228424072]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.047341108322143555]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fb6a42865f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N = 5\n",
    "# best_feature = int(max_indices[N])\n",
    "best_feature = 1461\n",
    "print(\"bias:\", smaller_auto_encoder.encoder_bias.detach().cpu().numpy()[best_feature])\n",
    "print(f\"Feature index: {best_feature}\")\n",
    "print(f\"MCS: {max_cosine_similarities[best_feature]}\")\n",
    "text_list, full_text, token_list, full_token_list = get_feature_datapoints(best_feature, dictionary_activations, dataset, setting=\"uniform\")\n",
    "# text_list, full_text, token_list, full_token_list = get_feature_datapoints(best_feature, dictionary_activations, dataset, setting=\"max\")\n",
    "visualize_text(full_text, best_feature, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-6e5c2972-af1c\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-6e5c2972-af1c\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"my\", \" mum\", \" was\", \" unemployed\", \" for\", \" a\", \" while\", \" I\", \" never\", \" had\", \" a\", \" bab\", \"ys\", \"itter\", \" till\", \" I\", \" was\", \" ten\", \" anyway\", \".\", \" So\", \" my\", \" mum\", \" got\", \" a\", \"\\n\", \"Jason\", \" Howard\", \" Green\", \"\\\\newline\", \"\\\\newline\", \"Wednesday\", \",\", \" October\", \" 7\", \",\", \" 2009\", \"\\\\newline\", \"\\\\newline\", \"Beat\", \" Down\", \" Over\", \" a\", \" Dress\", \" Code\", \"!!!\", \"\\\\newline\", \"\\\\newline\", \"Please\", \" take\", \" a\", \"\\n\", \"D\", \"way\", \"ne\", \" \\\"\", \"The\", \" Rock\", \"\\\"\", \" Johnson\", \" has\", \" hinted\", \" at\", \" a\", \"\\n\", \"Histor\", \"ical\", \" conceptual\", \"izations\", \" of\", \" depression\", \"\\\\newline\", \"================================\", \"===========\", \"\\\\newline\", \"\\\\newline\", \"There\", \" is\", \" a\", \"\\n\", \"After\", \" a\", \" decade\", \"-\", \"long\", \" pause\", \",\", \" the\", \" two\", \" Kore\", \"as\", \" are\", \" holding\", \" a\", \"\\n\", \"The\", \" South\", \" Korean\", \" Ministry\", \" of\", \" Trade\", \",\", \" Industry\", \" and\", \" Energy\", \" (\", \"M\", \"OT\", \"IE\", \")\", \" announced\", \" in\", \" a\", \" press\", \" release\", \" that\", \" a\", \"\\n\", \"Q\", \":\", \"\\\\newline\", \"\\\\newline\", \"What\", \" is\", \" the\", \" advantage\", \" of\", \" using\", \" a\", \"\\n\", \"Background\", \" {#\", \"Sec\", \"1\", \"}\", \"\\\\newline\", \"==========\", \"\\\\newline\", \"\\\\newline\", \"The\", \" development\", \" of\", \" resistance\", \" to\", \" cytotoxic\", \" agents\", \" represents\", \" a\", \"\\n\", \"Project\", \" Summary\", \" Post\", \"partum\", \" cardiomyopathy\", \" (\", \"PP\", \"CM\", \")\", \" is\", \" a\", \"\\n\", \"Q\", \":\", \"\\\\newline\", \"\\\\newline\", \"How\", \" do\", \" I\", \" make\", \" main\", \" a\", \"\\n\", \"#\", \"include\", \" <\", \"stdlib\", \".\", \"h\", \">\", \"\\\\newline\", \"#\", \"include\", \" <\", \"un\", \"ist\", \"\\n\"], \"activations\": [[[-0.011960029602050781]], [[0.16459941864013672]], [[0.023888587951660156]], [[0.013172149658203125]], [[0.023657798767089844]], [[0.0054836273193359375]], [[-0.02833843231201172]], [[0.005114555358886719]], [[0.012310504913330078]], [[0.019277095794677734]], [[0.04014015197753906]], [[-0.09752035140991211]], [[0.028885841369628906]], [[-0.0052947998046875]], [[0.011080265045166016]], [[-0.016115665435791016]], [[0.04094696044921875]], [[-0.032898902893066406]], [[-0.13679027557373047]], [[-0.252593994140625]], [[-0.04209756851196289]], [[-0.025403976440429688]], [[-0.09377050399780273]], [[-1.6262774467468262]], [[-3.1857759952545166]], [[0.0]], [[0.07260942459106445]], [[-0.006644725799560547]], [[-0.01939249038696289]], [[-0.04311418533325195]], [[-0.04311418533325195]], [[0.0024890899658203125]], [[-0.0433201789855957]], [[-0.02366924285888672]], [[-0.009114265441894531]], [[-0.06541681289672852]], [[-0.05444478988647461]], [[-0.10724258422851562]], [[-0.10724258422851562]], [[-0.028470993041992188]], [[0.023233413696289062]], [[-0.05157279968261719]], [[0.050536155700683594]], [[0.10521125793457031]], [[0.007874011993408203]], [[-0.07818174362182617]], [[-0.021441936492919922]], [[-0.021441936492919922]], [[-0.21470165252685547]], [[-1.070023536682129]], [[-2.621417284011841]], [[0.0]], [[-0.009573936462402344]], [[-0.033496856689453125]], [[-0.004873752593994141]], [[-0.3478708267211914]], [[0.10919809341430664]], [[-0.031003475189208984]], [[-0.05584239959716797]], [[-0.01750802993774414]], [[-0.09372234344482422]], [[-0.6605935096740723]], [[-0.20024919509887695]], [[-2.2883756160736084]], [[0.0]], [[0.025741100311279297]], [[0.04144573211669922]], [[0.0015568733215332031]], [[-0.0061244964599609375]], [[-0.15436172485351562]], [[0.037656307220458984]], [[0.12732505798339844]], [[-0.018589019775390625]], [[0.10189056396484375]], [[-0.038123130798339844]], [[-0.038123130798339844]], [[-0.9836773872375488]], [[-0.5126678943634033]], [[-1.9504492282867432]], [[0.0]], [[0.13428783416748047]], [[-0.11821508407592773]], [[-0.11467647552490234]], [[0.0016436576843261719]], [[-0.10137224197387695]], [[-0.10315942764282227]], [[0.07570219039916992]], [[-0.07286500930786133]], [[-0.004523754119873047]], [[-0.1208653450012207]], [[0.0003733634948730469]], [[-0.04294872283935547]], [[-0.8060722351074219]], [[-1.82517409324646]], [[0.0]], [[0.2259063720703125]], [[-0.12839221954345703]], [[-0.05381321907043457]], [[-0.03688454627990723]], [[0.056342363357543945]], [[-0.007757425308227539]], [[-0.02382206916809082]], [[-0.10958647727966309]], [[-0.06507492065429688]], [[-0.010530471801757812]], [[-0.027631044387817383]], [[-0.06357836723327637]], [[-0.00010752677917480469]], [[-0.04454374313354492]], [[-0.08558797836303711]], [[-0.1551344394683838]], [[-0.0609288215637207]], [[0.27847909927368164]], [[0.027655839920043945]], [[-0.0964195728302002]], [[0.03255939483642578]], [[-1.3106606006622314]], [[0.0]], [[0.3160395622253418]], [[0.2593812942504883]], [[0.02631521224975586]], [[0.02631521224975586]], [[0.03085470199584961]], [[-0.010838985443115234]], [[-0.03284955024719238]], [[-0.14224743843078613]], [[0.05969381332397461]], [[-0.38853001594543457]], [[-1.1367342472076416]], [[0.0]], [[0.06625676155090332]], [[0.04352068901062012]], [[0.002577543258666992]], [[1.4066696166992188e-05]], [[-0.0341794490814209]], [[0.08487200736999512]], [[0.22419524192810059]], [[-0.011767864227294922]], [[-0.011767864227294922]], [[0.008396625518798828]], [[-0.12949824333190918]], [[-0.13542485237121582]], [[0.14915156364440918]], [[-0.005538225173950195]], [[0.0319828987121582]], [[-0.03181314468383789]], [[-0.9157400131225586]], [[-0.9157400131225586]], [[0.0]], [[-0.21596932411193848]], [[0.10319280624389648]], [[-0.04177236557006836]], [[0.06670522689819336]], [[0.3601546287536621]], [[0.21279144287109375]], [[0.1184549331665039]], [[0.00018644332885742188]], [[0.08700728416442871]], [[-0.15780329704284668]], [[-0.6178028583526611]], [[0.0]], [[0.4562041759490967]], [[0.15083789825439453]], [[0.018642902374267578]], [[0.018642902374267578]], [[0.2788553237915039]], [[-0.03977227210998535]], [[0.07779860496520996]], [[-0.15712738037109375]], [[1.093226432800293]], [[-0.15712738037109375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fb6601f9b10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_text(text_list, best_feature, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-c4cc7204-0961\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-c4cc7204-0961\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\" mum\", \" was\", \" unemployed\", \" for\", \" a\", \" while\", \" I\", \" never\", \" had\", \" a\", \" bab\", \"ys\", \"itter\", \" till\", \" I\", \" was\", \" ten\", \" anyway\", \".\", \" So\", \" my\", \" mum\", \" got\", \" a\", \"\\n\", \" Howard\", \" Green\", \"\\\\newline\", \"\\\\newline\", \"Wednesday\", \",\", \" October\", \" 7\", \",\", \" 2009\", \"\\\\newline\", \"\\\\newline\", \"Beat\", \" Down\", \" Over\", \" a\", \" Dress\", \" Code\", \"!!!\", \"\\\\newline\", \"\\\\newline\", \"Please\", \" take\", \" a\", \"\\n\", \"way\", \"ne\", \" \\\"\", \"The\", \" Rock\", \"\\\"\", \" Johnson\", \" has\", \" hinted\", \" at\", \" a\", \" presidential\", \" run\", \" several\", \" times\", \",\", \" and\", \" now\", \" a\", \" campaign\", \" committee\", \" has\", \" formally\", \" filed\", \"\\n\", \"ical\", \" conceptual\", \"izations\", \" of\", \" depression\", \"\\\\newline\", \"================================\", \"===========\", \"\\\\newline\", \"\\\\newline\", \"There\", \" is\", \" a\", \" long\", \" tradition\", \" in\", \" phenomen\", \"olog\", \"l\", \"cal\", \" psych\", \"opathology\", \" that\", \" stresses\", \"\\n\", \" a\", \" decade\", \"-\", \"long\", \" pause\", \",\", \" the\", \" two\", \" Kore\", \"as\", \" are\", \" holding\", \" a\", \" top\", \"-\", \"level\", \" summit\", \" this\", \" week\", \".\", \" Seoul\", \" may\", \" score\", \" some\", \"\\n\", \" South\", \" Korean\", \" Ministry\", \" of\", \" Trade\", \",\", \" Industry\", \" and\", \" Energy\", \" (\", \"M\", \"OT\", \"IE\", \")\", \" announced\", \" in\", \" a\", \" press\", \" release\", \" that\", \" a\", \" 2\", \".\", \"1\", \"\\n\", \":\", \"\\\\newline\", \"\\\\newline\", \"What\", \" is\", \" the\", \" advantage\", \" of\", \" using\", \" a\", \" digital\", \" signature\", \" over\", \" simple\", \" asymmetric\", \" encryption\", \"?\", \"\\\\newline\", \"\\\\newline\", \"If\", \" you\", \"'re\", \" sending\", \" me\", \"\\n\", \" {#\", \"Sec\", \"1\", \"}\", \"\\\\newline\", \"==========\", \"\\\\newline\", \"\\\\newline\", \"The\", \" development\", \" of\", \" resistance\", \" to\", \" cytotoxic\", \" agents\", \" represents\", \" a\", \" major\", \" concern\", \" in\", \" cancer\", \" chemotherapy\", \".\", \" Multi\", \"\\n\", \" Summary\", \" Post\", \"partum\", \" cardiomyopathy\", \" (\", \"PP\", \"CM\", \")\", \" is\", \" a\", \" disease\", \" of\", \" unknown\", \" etiology\", \" that\", \" arises\", \" as\", \" a\", \" complication\", \" of\", \" pregnancy\", \" in\", \" women\", \" with\", \"\\n\", \":\", \"\\\\newline\", \"\\\\newline\", \"How\", \" do\", \" I\", \" make\", \" main\", \" a\", \" friend\", \" of\", \" my\", \" class\", \" from\", \" within\", \" a\", \" library\", \"?\", \"\\\\newline\", \"\\\\newline\", \"Please\", \" see\", \" my\", \" first\", \"\\n\", \"include\", \" <\", \"stdlib\", \".\", \"h\", \">\", \"\\\\newline\", \"#\", \"include\", \" <\", \"un\", \"ist\", \"d\", \".\", \"h\", \">\", \"\\\\newline\", \"#\", \"include\", \" <\", \"string\", \".\", \"h\", \">\", \"\\n\"], \"activations\": [[[0.0]], [[0.00018787384033203125]], [[0.00868988037109375]], [[-0.0003039836883544922]], [[-0.0019875764846801758]], [[-0.11146163940429688]], [[0.03933858871459961]], [[-0.04053544998168945]], [[-0.01779794692993164]], [[-0.0028079748153686523]], [[-0.25023555755615234]], [[0.03015468269586563]], [[-0.16646626591682434]], [[0.05059337615966797]], [[0.013318419456481934]], [[0.007692813873291016]], [[-0.03290557861328125]], [[-0.021697044372558594]], [[0.004423916339874268]], [[0.004390239715576172]], [[-0.008125543594360352]], [[0.022050857543945312]], [[4.6253204345703125e-05]], [[-0.0995016098022461]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.0017242431640625]], [[0.0]], [[-0.0010476112365722656]], [[2.6226043701171875e-06]], [[-1.2479722499847412e-06]], [[-3.6716461181640625e-05]], [[2.0712614059448242e-06]], [[1.7537735402584076e-05]], [[0.013325691223144531]], [[0.004034996032714844]], [[0.0060214996337890625]], [[0.00147247314453125]], [[0.21060943603515625]], [[0.015545845031738281]], [[0.06712150573730469]], [[0.002656280994415283]], [[-0.00022603943943977356]], [[0.0017080307006835938]], [[0.013840675354003906]], [[-0.005038857460021973]], [[0.0]], [[0.0]], [[-0.003909111022949219]], [[0.0]], [[-0.0008254051208496094]], [[0.006052970886230469]], [[-0.0005388259887695312]], [[0.016095638275146484]], [[0.0]], [[-0.004477500915527344]], [[-0.00037348270416259766]], [[0.0008071660995483398]], [[0.29546165466308594]], [[-0.3688392639160156]], [[-0.0028371810913085938]], [[0.056975483894348145]], [[0.021167278289794922]], [[0.018458127975463867]], [[0.01325225830078125]], [[-0.020459651947021484]], [[0.31237030029296875]], [[0.031088829040527344]], [[-0.16480612754821777]], [[0.030365943908691406]], [[0.02627420425415039]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.00016617774963378906]], [[-0.0036211013793945312]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.00010347366333007812]], [[-0.00035965442657470703]], [[3.719329833984375e-05]], [[-0.36670804023742676]], [[0.015156030654907227]], [[0.11186599731445312]], [[-0.08278846740722656]], [[-0.006539344787597656]], [[0.009267807006835938]], [[0.02550029754638672]], [[-0.011178016662597656]], [[-0.032308101654052734]], [[-0.13643789291381836]], [[-0.1065068244934082]], [[0.0]], [[0.0]], [[-0.9190230369567871]], [[-0.3404250144958496]], [[-0.01526767760515213]], [[-0.29100513458251953]], [[0.11064636707305908]], [[0.008180499076843262]], [[-0.0029196739196777344]], [[0.0034036636352539062]], [[-0.002888321876525879]], [[-0.004914760589599609]], [[-0.006618976593017578]], [[-0.001656651496887207]], [[0.25279951095581055]], [[-0.24052715301513672]], [[0.11705303192138672]], [[-0.0242311954498291]], [[-0.11472606658935547]], [[-0.058611392974853516]], [[0.05515575408935547]], [[-0.03870344161987305]], [[-0.018345355987548828]], [[0.014014244079589844]], [[-0.004049062728881836]], [[0.0]], [[0.0]], [[0.0]], [[0.0010333061218261719]], [[-6.566941738128662e-05]], [[-0.014262199401855469]], [[0.0]], [[0.0]], [[0.0]], [[0.005267620086669922]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-1.3828277587890625e-05]], [[0.000293731689453125]], [[0.3540189266204834]], [[0.023528605699539185]], [[0.19274377822875977]], [[-0.01114797592163086]], [[-0.12082862854003906]], [[0.007844924926757812]], [[-0.007970571517944336]], [[0.0]], [[0.0]], [[-3.1575560569763184e-05]], [[0.0]], [[0.0]], [[-9.918212890625e-05]], [[-0.00011488795280456543]], [[-0.0017647743225097656]], [[0.0]], [[-0.0005279779434204102]], [[-0.0003142356872558594]], [[-0.14099836349487305]], [[0.012690544128417969]], [[0.06807518005371094]], [[0.13751983642578125]], [[0.007294654846191406]], [[0.0009579658508300781]], [[1.621246337890625e-05]], [[-0.0005548596382141113]], [[-6.815418601036072e-05]], [[0.02033853530883789]], [[0.0057218074798583984]], [[0.006944894790649414]], [[-0.010867118835449219]], [[0.01495504379272461]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[5.602836608886719e-06]], [[0.0]], [[0.0]], [[-0.0007796287536621094]], [[0.0]], [[-0.0005507469177246094]], [[0.0]], [[0.001323699951171875]], [[5.811452865600586e-05]], [[0.05433154106140137]], [[-0.0008063316345214844]], [[-0.015087485313415527]], [[-0.007175922393798828]], [[-0.0031747817993164062]], [[-0.0006529092788696289]], [[0.0036373138427734375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-7.325410842895508e-05]], [[0.07286643981933594]], [[0.04429495334625244]], [[-0.04964637756347656]], [[0.00327908992767334]], [[-0.07367467880249023]], [[0.0028562545776367188]], [[0.0008611679077148438]], [[-0.0014589130878448486]], [[-0.12059974670410156]], [[0.0024379193782806396]], [[-0.009991645812988281]], [[0.010333061218261719]], [[-0.004906654357910156]], [[-0.0018897056579589844]], [[0.0]], [[0.0]], [[-1.1533498764038086e-05]], [[0.0]], [[0.0]], [[0.00010979175567626953]], [[-3.3527612686157227e-05]], [[0.0]], [[0.00022983551025390625]], [[0.00077056884765625]], [[-0.08823204040527344]], [[0.011754751205444336]], [[-0.002233743667602539]], [[-0.0008940696716308594]], [[-0.0039048194885253906]], [[0.00010156631469726562]], [[-0.0030711889266967773]], [[-0.0826263427734375]], [[0.024044692516326904]], [[0.0006695389747619629]], [[0.0004134178161621094]], [[-0.0016217231750488281]], [[-0.000194549560546875]], [[0.0007368326187133789]], [[-0.004774570465087891]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fb5d4ef5bd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_feature_direction_display(full_text, best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' lot', ' priori', ' dozen', 'usterity', ' few', ' handful', ' plethora', 'cknowled', ' wider', ' bit', ' variety', 'usp', ' hundred', ' full', ' similar', ' suitable', ' broader', 'erobic', ' thousand', ' multitude']\n",
      "tensor([2.3451, 2.2485, 2.2212, 2.0945, 2.0546, 2.0408, 2.0395, 1.9696, 1.9618,\n",
      "        1.9117, 1.8994, 1.8921, 1.8660, 1.8519, 1.8387, 1.8361, 1.8318, 1.8278,\n",
      "        1.8234, 1.8005])\n"
     ]
    }
   ],
   "source": [
    "logit_lens(model,best_feature, smaller_dict, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-6e3a4684-f36c\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-6e3a4684-f36c\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\" Your\", \" text\", \" here\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fb7482dac20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_text = [\n",
    "    \" Your text here\",\n",
    "]\n",
    "visualize_text(custom_text, best_feature, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Centric Viewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-b3f2704e-8a27\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-b3f2704e-8a27\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\"], \"activations\": [[[82.7564926147461]], [[0.41646838188171387]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[149.81748962402344]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[62.884986877441406]], [[0.0]], [[0.4040207862854004]], [[0.0]], [[0.0]], [[0.0]], [[99.5608139038086]], [[0.5513043403625488]], [[0.0]], [[1.0399408340454102]], [[1.425760269165039]], [[4.947237968444824]], [[1.7392220497131348]], [[0.0]], [[0.0]], [[4.0198774337768555]], [[0.17562437057495117]], [[0.0]], [[0.0]], [[0.0]], [[3.941493034362793]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[17.318439483642578]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.9275326728820801]], [[0.6468110084533691]], [[0.10458612442016602]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.11562681198120117]], [[1.100588321685791]], [[1.7711853981018066]], [[1.5439908504486084]], [[0.3038226366043091]], [[0.3253086805343628]], [[0.6628274917602539]], [[0.5560286045074463]], [[0.3502471446990967]], [[0.4706670045852661]], [[0.0]], [[0.8721731901168823]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.8246186971664429]], [[0.4927572011947632]], [[0.3002433776855469]], [[0.4912317991256714]], [[0.18886053562164307]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.7436568737030029]], [[1.5422230958938599]], [[1.4640122652053833]], [[1.782070279121399]], [[0.8627933263778687]], [[0.32637345790863037]], [[0.0]], [[0.30792057514190674]], [[0.15409982204437256]], [[0.10886752605438232]], [[0.06799399852752686]], [[0.40450000762939453]], [[0.0]], [[0.37047338485717773]], [[0.009954333305358887]], [[0.0]], [[0.0619814395904541]], [[0.20380747318267822]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.4360116720199585]], [[0.0]], [[0.557902455329895]], [[1.4583653211593628]], [[0.36010468006134033]], [[0.2150031328201294]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.47024083137512207]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.3076235055923462]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.3168461322784424]], [[0.1124265193939209]], [[3.23787784576416]], [[1.5314109325408936]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fb6601fad10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through datapoints & see if the features that activate on them make sense.\n",
    "d_point = 0\n",
    "# text = tokens_dataset[d_point]\n",
    "data_ind, sequence_pos = np.unravel_index(d_point, (datapoints, token_amount))\n",
    "feature_val, feature_ind = dictionary_activations[d_point].topk(10)\n",
    "data_ind = int(data_ind)\n",
    "sequence_pos = int(sequence_pos)\n",
    "full_tok = torch.tensor(dataset[data_ind][\"input_ids\"])\n",
    "full_text = []\n",
    "full_text.append(model.tokenizer.decode(full_tok))\n",
    "visualize_text(full_text, feature_ind, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the neuron/residual basis\n",
    "When we look at the weights of a feature, we are seeing the literal dimensions from the residual stream/neurons being read from the feature. \n",
    "\n",
    "Here I'm visualizing the weight values for the residual stream. If there are outliers, then it's mainly reading from that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check features non-zero weights in decoder\n",
    "# Plot a histogram of the weights\n",
    "max_activation = dictionary_activations[:, best_feature].max()\n",
    "weights = smaller_dict[best_feature]\n",
    "plt.hist(weights, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.topk(\n",
       " values=tensor([0.4587, 0.4407, 0.4183, 0.4015, 0.3814, 0.3496, 0.3330, 0.3156, 0.2968,\n",
       "         0.2948, 0.2846, 0.2781, 0.2736, 0.2714, 0.2680, 0.2593, 0.2587, 0.2563,\n",
       "         0.2554, 0.2505]),\n",
       " indices=tensor([478, 436,  98, 321,  87, 458, 230, 464, 129,  31, 137, 377, 263, 401,\n",
       "         291,  92, 132,  56, 109, 246])),\n",
       " tensor([-0.3796, -0.3700, -0.3456, -0.3286, -0.3197, -0.3164, -0.3107, -0.3015,\n",
       "         -0.3011, -0.3000, -0.2976, -0.2964, -0.2894, -0.2886, -0.2828, -0.2822,\n",
       "         -0.2763, -0.2675, -0.2606, -0.2588]),\n",
       " tensor(39))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weights*max_activation).topk(20), (weights*max_activation).topk(20, largest=False).values, (weights*max_activation > 0.2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepend/Append tokens\n",
    "We can iterate over all tokens to check which ones activate a feature a lot to more rigorously test a hypothesis on what a feature means.\n",
    "\n",
    "Note: I'm literately running the model through all 50k tokens prepended to the text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[token]\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n",
      "<|endoftext|>[token]\n",
      "Top-20 increasing: [' a', '#', '1', ')', '/', \"'\", '2', '<|padding|>', '$', '*', '+', '.', '&', '0', '\"', '(', ',', '<|endoftext|>', '!', '%']\n",
      "Top-20 increasing: ['0.11', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50303\n",
      "<|endoftext|> a[token]\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n"
     ]
    }
   ],
   "source": [
    "def prepend_all_tokens_and_get_feature_activation(model, minimal_activating_example, feature, setting=\"prepend\"):\n",
    "    tokens = model.to_tokens(minimal_activating_example, prepend_bos=False)\n",
    "\n",
    "    # Run through every number up to vocab size\n",
    "    vocab_size = model.cfg.d_vocab\n",
    "    batch_size = 256*2 # Define your desired batch size\n",
    "\n",
    "    dollar_feature_activations = torch.zeros(vocab_size)\n",
    "    for start in range(0, vocab_size, batch_size):\n",
    "        end = min(start + batch_size, vocab_size)\n",
    "\n",
    "        token_prep = torch.arange(start, end).to(device)\n",
    "        token_prep = token_prep.unsqueeze(1)  # Add a dimension for concatenation\n",
    "\n",
    "        # 1. Prepend to the tokens\n",
    "        if setting == \"prepend\":\n",
    "            tokens_catted = torch.cat((token_prep, tokens.repeat(end - start, 1)), dim=1).long()\n",
    "        elif setting == \"append\":\n",
    "            tokens_catted = torch.cat((tokens.repeat(end - start, 1), token_prep), dim=1).long()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown setting: {setting}\")\n",
    "\n",
    "        # 2. Run through the model\n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(tokens_catted.to(device))\n",
    "            neuron_act_batch = cache[cache_name]\n",
    "            _, act = smaller_auto_encoder(neuron_act_batch)\n",
    "\n",
    "        # 3. Get the feature\n",
    "        dollar_feature_activations[start:end] = act[:, -1, feature].cpu().squeeze()\n",
    "\n",
    "    k = 20\n",
    "    k_increasing_val, k_increasing_ind = dollar_feature_activations.topk(k)\n",
    "    k_decreasing_val, k_decreasing_ind = dollar_feature_activations.topk(k, largest=False)\n",
    "    if(setting == \"prepend\"):\n",
    "        print(f\"[token]{minimal_activating_example}\")\n",
    "    elif(setting == \"append\"):\n",
    "        print(f\"{minimal_activating_example}[token]\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown setting: {setting}\")\n",
    "    # Print indices converted to tokens\n",
    "    print(f\"Top-{k} increasing: {model.to_str_tokens(k_increasing_ind)}\")\n",
    "    # Print values\n",
    "    print(f\"Top-{k} increasing: {[f'{val:.2f}' for val in k_increasing_val]}\")\n",
    "    print(f\"Top-{k} decreasing: {model.to_str_tokens(k_decreasing_ind)}\")\n",
    "    print(f\"Top-{k} decreasing: {[f'{val:.2f}' for val in k_decreasing_val]}\")\n",
    "    print(f\"Number of 0 activations: {torch.sum(dollar_feature_activations == 0)}\")\n",
    "    if(setting == \"prepend\"):\n",
    "        best_text = \"\".join(model.to_str_tokens(dollar_feature_activations.argmax()) + [minimal_activating_example])\n",
    "    else:\n",
    "        best_text = \"\".join([minimal_activating_example] + model.to_str_tokens(dollar_feature_activations.argmax()))\n",
    "    return best_text\n",
    "\n",
    "best_text = \"\"\n",
    "for x in range(3):\n",
    "    # best_text = prepend_all_tokens_and_get_feature_activation(model, best_text, best_feature, setting=\"prepend\")\n",
    "    best_text = prepend_all_tokens_and_get_feature_activation(model, best_text, best_feature, setting=\"append\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" for all $\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" tree\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" tree\", best_feature, setting=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[token]\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n",
      "[token]<|endoftext|>\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n",
      "[token]<|endoftext|><|endoftext|>\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n"
     ]
    }
   ],
   "source": [
    "best_text = \"\"\n",
    "for x in range(3):\n",
    "    best_text = prepend_all_tokens_and_get_feature_activation(model, best_text, best_feature, setting=\"prepend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[token] for all $\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|endoftext|> for all $'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepend_all_tokens_and_get_feature_activation(model, \" for all $\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \"The\", best_feature, setting=\"append\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" tree\", best_feature, setting=\"append\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

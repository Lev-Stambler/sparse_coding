{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchorse/miniconda3/envs/logan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "import numpy as np \n",
    "from torch import nn\n",
    "import pickle\n",
    "\n",
    "# Define the autoencoder so pickle knows how to serialize it. \n",
    "# Later, we should actually save as a state_dict instead of a dumb pickle\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, activation_size, n_dict_components, t_type=torch.float32, l1_coef=0.0):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # Only defining the decoder layer, encoder will share its weights\n",
    "        self.decoder = nn.Linear(n_dict_components, activation_size, bias=True)\n",
    "        # Create a bias layer\n",
    "        self.encoder_bias= nn.Parameter(torch.zeros(n_dict_components))\n",
    "\n",
    "        \n",
    "        # Initialize the decoder weights orthogonally\n",
    "        nn.init.orthogonal_(self.decoder.weight)\n",
    "        self.decoder = self.decoder.to(t_type)\n",
    "\n",
    "        # Encoder is a Sequential with the ReLU activation\n",
    "        # No need to define a Linear layer for the encoder as its weights are tied with the decoder\n",
    "        self.encoder = nn.Sequential(nn.ReLU()).to(t_type)\n",
    "\n",
    "        self.l1_coef = l1_coef\n",
    "        self.activation_size = activation_size\n",
    "        self.n_dict_components = n_dict_components\n",
    "\n",
    "    def forward(self, x):\n",
    "        c = self.encoder(x @ self.decoder.weight + self.encoder_bias)\n",
    "        # Apply unit norm constraint to the decoder weights\n",
    "        self.decoder.weight.data = nn.functional.normalize(self.decoder.weight.data, dim=0)\n",
    "\n",
    "        # Decoding step as before\n",
    "        x_hat = self.decoder(c)\n",
    "        return x_hat, c\n",
    "\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m-deduped into HookedTransformer\n",
      "torch.Size([512, 512])\n",
      "torch.Size([1024, 512])\n",
      "torch.Size([2048, 512])\n",
      "torch.Size([4096, 512])\n",
      "len of autoencoders:  1\n"
     ]
    }
   ],
   "source": [
    "#Change these settings to load the correct autoencoder\n",
    "filename = \"/home/mchorse/logan_sparse_coding/sparse_coding/layer-2-autoencoder.pkl\"\n",
    "layer = 2\n",
    "setting = \"residual\"\n",
    "model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)\n",
    "\n",
    "if setting == \"residual\":\n",
    "    cache_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "    neurons = model.cfg.d_model\n",
    "elif setting == \"mlp\":\n",
    "    cache_name = f\"blocks.{layer}.mlp.hook_post\"\n",
    "    neurons = model.cfg.d_mlp\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "# Load the pickle file\n",
    "with open(filename, 'rb') as file:\n",
    "    autoencoders = pickle.load(file)\n",
    "\n",
    "# Index for l1 value, usually only 1 value is available\n",
    "l1_index = -1\n",
    "dictionaries = [autoencoder.decoder.weight.data.T for autoencoder in autoencoders[l1_index]]\n",
    "for d in dictionaries:\n",
    "    print(d.shape)\n",
    "print(\"len of autoencoders: \", len(autoencoders))\n",
    "dict_index = 2\n",
    "smaller_dict, larger_dict = dictionaries[dict_index], dictionaries[dict_index+1]\n",
    "smaller_auto_encoder, larger_auto_encoder = autoencoders[l1_index][dict_index], autoencoders[l1_index][dict_index+1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCS\n",
    "Max cosine similarity between one dictionary & another one. If they learned the same feature, then they'll have high cosine similarity. \n",
    "\n",
    "If two dictionaries learned it, it's probably a real feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# of features above 0.9:', 929)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.pyplot as plt\n",
    "#Dictionary Comparison\n",
    "smaller_dict_features, _ = smaller_dict.shape\n",
    "larger_dict_features, _ = larger_dict.shape\n",
    "larger_dict = larger_dict.to(device)\n",
    "# Hungary algorithm\n",
    "# Calculate all cosine similarities and store in a 2D array\n",
    "cos_sims = np.zeros((smaller_dict_features, larger_dict_features))\n",
    "for idx, vector in enumerate(smaller_dict):\n",
    "    cos_sims[idx] = torch.nn.functional.cosine_similarity(vector.to(device), larger_dict, dim=1).cpu().numpy()\n",
    "# Convert to a minimization problem\n",
    "cos_sims = 1 - cos_sims\n",
    "# Use the Hungarian algorithm to solve the assignment problem\n",
    "row_ind, col_ind = linear_sum_assignment(cos_sims)\n",
    "# Retrieve the max cosine similarities and corresponding indices\n",
    "max_cosine_similarities = 1 - cos_sims[row_ind, col_ind]\n",
    "\n",
    "# Get the indices of the max cosine similarities in descending order\n",
    "max_indices = np.argsort(max_cosine_similarities)[::-1].copy()\n",
    "max_cosine_similarities[max_indices][:20]\n",
    "print((\"# of features above 0.9:\", (max_cosine_similarities > .9).sum()))\n",
    "# Plot histogram of max_cosine_similarities\n",
    "plt.hist(max_cosine_similarities, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# William\n",
    "The dictionary for the autointerp is the 2k one, defined as 'smaller_dict'\n",
    "\n",
    "You can also use max_indices to sort by max_MCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first two top-MCS features\n",
    "smaller_dict[max_indices][:20].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model activations & Dictionary Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "                                                                      \r"
     ]
    }
   ],
   "source": [
    "# Downnload dataset\n",
    "from datasets import Dataset, load_dataset\n",
    "dataset_name = \"NeelNanda/pile-10k\"\n",
    "token_amount= 40\n",
    "dataset = load_dataset(dataset_name, split=\"train\").map(\n",
    "    lambda x: model.tokenizer(x['text']),\n",
    "    batched=True,\n",
    ").filter(\n",
    "    lambda x: len(x['input_ids']) > token_amount\n",
    ").map(\n",
    "    lambda x: {'input_ids': x['input_ids'][:token_amount]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [00:03<00:00, 39.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the model to get the activations\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "# neurons = model.W_in.shape[-1]\n",
    "neurons = model.cfg.d_model\n",
    "datapoints = dataset.num_rows\n",
    "batch_size = 64\n",
    "neuron_activations = torch.zeros((datapoints*token_amount, neurons))\n",
    "dictionary_activations = torch.zeros((datapoints*token_amount, smaller_dict_features))\n",
    "smaller_auto_encoder = smaller_auto_encoder.to(device)\n",
    "\n",
    "with torch.no_grad(), dataset.formatted_as(\"pt\"):\n",
    "    dl = DataLoader(dataset[\"input_ids\"], batch_size=batch_size)\n",
    "    for i, batch in enumerate(tqdm(dl)):\n",
    "        _, cache = model.run_with_cache(batch.to(device))\n",
    "        batched_neuron_activations = rearrange(cache[cache_name], \"b s n -> (b s) n\" )\n",
    "        neuron_activations[i*batch_size*token_amount:(i+1)*batch_size*token_amount,:] = batched_neuron_activations.cpu()\n",
    "        reconstruction, batched_dictionary_activations = smaller_auto_encoder(batched_neuron_activations)\n",
    "        dictionary_activations[i*batch_size*token_amount:(i+1)*batch_size*token_amount,:] = batched_dictionary_activations.cpu()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Activation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuitsvis.activations import text_neuron_activations\n",
    "# Get the activations for the best dict features\n",
    "def get_feature_datapoints(feature_index, dictionary_activations, dataset, k=10, setting=\"max\"):\n",
    "    best_feature_activations = dictionary_activations[:, feature_index]\n",
    "    # Sort the features by activation, get the indices\n",
    "    if setting==\"max\":\n",
    "        found_indices = torch.argsort(best_feature_activations, descending=True)[:k]\n",
    "    elif setting==\"uniform\":\n",
    "        min_value = torch.min(best_feature_activations)\n",
    "        max_value = torch.max(best_feature_activations)\n",
    "\n",
    "        # Define the number of bins\n",
    "        num_bins = k\n",
    "\n",
    "        # Calculate the bin boundaries as linear interpolation between min and max\n",
    "        bin_boundaries = torch.linspace(min_value, max_value, num_bins + 1)\n",
    "\n",
    "        # Assign each activation to its respective bin\n",
    "        bins = torch.bucketize(best_feature_activations, bin_boundaries)\n",
    "\n",
    "        # Initialize a list to store the sampled indices\n",
    "        sampled_indices = []\n",
    "\n",
    "        # Sample from each bin\n",
    "        for bin_idx in torch.unique(bins):\n",
    "            # Get the indices corresponding to the current bin\n",
    "            bin_indices = torch.nonzero(bins == bin_idx, as_tuple=False).squeeze(dim=1)\n",
    "            \n",
    "            # Randomly sample from the current bin\n",
    "            sampled_indices.extend(np.random.choice(bin_indices, size=1, replace=False))\n",
    "\n",
    "        # Convert the sampled indices to a PyTorch tensor & reverse order\n",
    "        found_indices = torch.tensor(sampled_indices).long().flip(dims=[0])\n",
    "    else: # random\n",
    "        # get nonzero indices\n",
    "        nonzero_indices = torch.nonzero(best_feature_activations)[:, 0]\n",
    "        # shuffle\n",
    "        shuffled_indices = nonzero_indices[torch.randperm(nonzero_indices.shape[0])]\n",
    "        found_indices = shuffled_indices[:k]\n",
    "    datapoint_indices =[np.unravel_index(i, (datapoints, token_amount)) for i in found_indices]\n",
    "    text_list = []\n",
    "    full_text = []\n",
    "    token_list = []\n",
    "    full_token_list = []\n",
    "    for md, s_ind in datapoint_indices:\n",
    "        md = int(md)\n",
    "        s_ind = int(s_ind)\n",
    "        full_tok = torch.tensor(dataset[md][\"input_ids\"])\n",
    "        full_text.append(model.tokenizer.decode(full_tok))\n",
    "        tok = dataset[md][\"input_ids\"][:s_ind+1]\n",
    "        text = model.tokenizer.decode(tok)\n",
    "        text_list.append(text)\n",
    "        token_list.append(tok)\n",
    "        full_token_list.append(full_tok)\n",
    "    return text_list, full_text, token_list, full_token_list\n",
    "\n",
    "def get_neuron_activation(token, feature, model, setting=\"dictionary_basis\"):\n",
    "    with torch.no_grad():\n",
    "        _, cache = model.run_with_cache(token.to(model.cfg.device))\n",
    "        neuron_act_batch = cache[cache_name]\n",
    "        if setting==\"dictionary_basis\":\n",
    "            _, act = smaller_auto_encoder(neuron_act_batch)\n",
    "            return act[0, :, feature].tolist()\n",
    "        else: # neuron/residual basis\n",
    "            return neuron_act_batch[0, :, feature].tolist()\n",
    "\n",
    "def ablate_text(text, feature, model, setting=\"plot\"):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    display_text_list = []\n",
    "    activation_list = []\n",
    "    for t in text:\n",
    "        # Convert text into tokens\n",
    "        if isinstance(t, str): # If the text is a list of tokens\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            tokens = model.to_tokens(t, prepend_bos=False)\n",
    "        else: # t equals tokens\n",
    "            tokens = t\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "        seq_size = tokens.shape[1]\n",
    "        if(seq_size == 1): # If the text is a single token, we can't ablate it\n",
    "            continue\n",
    "        original = get_neuron_activation(tokens, feature, model)[-1]\n",
    "        changed_activations = torch.zeros(seq_size, device=device).cpu()\n",
    "        for i in range(seq_size):\n",
    "            # Remove the i'th token from the input\n",
    "            ablated_tokens = torch.cat((tokens[:,:i], tokens[:,i+1:]), dim=1)\n",
    "            changed_activations[i] += get_neuron_activation(ablated_tokens, feature, model)[-1]\n",
    "        changed_activations -= original\n",
    "        display_text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "        activation_list += changed_activations.tolist() + [0.0]\n",
    "    activation_list = torch.tensor(activation_list).reshape(-1,1,1)\n",
    "    if setting == \"plot\":\n",
    "        return text_neuron_activations(tokens=display_text_list, activations=activation_list)\n",
    "    else:\n",
    "        return display_text_list, activation_list\n",
    "def visualize_text(text, feature, model, setting=\"dictionary_basis\", max_activation = None):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    if isinstance(feature, int):\n",
    "        feature = [feature]\n",
    "    display_text_list = []\n",
    "    act_list = []\n",
    "    for t in text:\n",
    "        if isinstance(t, str): # If the text is a list of tokens\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            token = model.to_tokens(t, prepend_bos=False)\n",
    "        else: # t are tokens\n",
    "            token = t\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "        for f in feature:\n",
    "            display_text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            act_list += get_neuron_activation(token, f, model, setting) + [0.0]\n",
    "    act_list = torch.tensor(act_list).reshape(-1,1,1)\n",
    "    if(max_activation is not None):\n",
    "        act_list = torch.clamp(act_list, max=max_activation)\n",
    "    return text_neuron_activations(tokens=display_text_list, activations=act_list)\n",
    "# Ablate the feature direction of the tokens\n",
    "# token_list is a list of tokens, convert to tensor of shape (batch_size, seq_len)\n",
    "from einops import rearrange\n",
    "def ablate_feature_direction(tokens, feature, model, autoencoder):\n",
    "    def mlp_ablation_hook(value, hook):\n",
    "        # Rearrange to fit autoencoder\n",
    "        int_val = rearrange(value, 'b s h -> (b s) h')\n",
    "\n",
    "        # Run through the autoencoder\n",
    "        _, act = autoencoder(int_val)\n",
    "        feature_to_ablate = feature # TODO: bring this out of the function\n",
    "\n",
    "        # Subtract value with feature direction*act_of_feature\n",
    "        feature_direction = torch.outer(act[:, feature_to_ablate].squeeze(), autoencoder.decoder.weight[:, feature_to_ablate].squeeze())\n",
    "        batch, seq_len, hidden_size = value.shape\n",
    "        feature_direction = rearrange(feature_direction, '(b s) h -> b s h', b=batch, s=seq_len)\n",
    "        value -= feature_direction\n",
    "        return value\n",
    "\n",
    "    return model.run_with_hooks(tokens, \n",
    "        fwd_hooks=[(\n",
    "            cache_name, \n",
    "            mlp_ablation_hook\n",
    "            )]\n",
    "        )\n",
    "def add_feature_direction(tokens, feature, model, autoencoder, scalar=1.0):\n",
    "    def residual_add_hook(value, hook):\n",
    "        feature_direction = autoencoder.decoder.weight[:, feature].squeeze()\n",
    "        value += scalar*feature_direction\n",
    "        return value\n",
    "\n",
    "    return model.run_with_hooks(tokens, \n",
    "        fwd_hooks=[(\n",
    "            cache_name,\n",
    "            residual_add_hook\n",
    "            )]\n",
    "        )\n",
    "def ablate_feature_direction_display(text, features=None, setting=\"true_tokens\", verbose=False):\n",
    "\n",
    "    if features==None:\n",
    "        features = torch.tensor([best_feature])\n",
    "    if isinstance(features, int):\n",
    "        features = torch.tensor([features])\n",
    "    if isinstance(features, list):\n",
    "        features = torch.tensor(features)\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    text_list = []\n",
    "    logit_list = []\n",
    "    for t in text:\n",
    "        tokens = model.to_tokens(t, prepend_bos=False)\n",
    "        with torch.no_grad():\n",
    "            original_logits = model(tokens).log_softmax(-1).cpu()\n",
    "            ablated_logits = ablate_feature_direction(tokens, features, model, smaller_auto_encoder).log_softmax(-1).cpu()\n",
    "        diff_logits = ablated_logits  - original_logits# ablated > original -> negative diff\n",
    "        tokens = tokens.cpu()\n",
    "        if setting == \"true_tokens\":\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            gather_tokens = rearrange(tokens[:,1:], \"b s -> b s 1\") # TODO: verify this is correct\n",
    "            # Gather the logits for the true tokens\n",
    "            diff = rearrange(diff_logits[:, :-1].gather(-1,gather_tokens), \"b s n -> (b s n)\")\n",
    "        elif setting == \"max\":\n",
    "            # Negate the diff_logits to see which tokens have the largest effect on the neuron\n",
    "            val, ind = (-1*diff_logits).max(-1)\n",
    "            diff = rearrange(val[:, :-1], \"b s -> (b s)\")\n",
    "            diff*= -1 # Negate the values gathered\n",
    "            split_text = model.to_str_tokens(ind, prepend_bos=False)\n",
    "            gather_tokens = rearrange(ind[:,1:], \"1 s -> 1 s 1\")\n",
    "        split_text = split_text[1:] # Remove the first token since we're not predicting it\n",
    "        if(verbose):\n",
    "            text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            orig = rearrange(original_logits[:, :-1].gather(-1, gather_tokens), \"b s n -> (b s n)\")\n",
    "            ablated = rearrange(ablated_logits[:, :-1].gather(-1, gather_tokens), \"b s n -> (b s n)\")\n",
    "            logit_list += orig.tolist() + [0.0]\n",
    "            logit_list += ablated.tolist() + [0.0]\n",
    "        text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "        logit_list += diff.tolist() + [0.0]\n",
    "    logit_list = torch.tensor(logit_list).reshape(-1,1,1)\n",
    "    if verbose:\n",
    "        print(f\"Max & Min logit-diff: {logit_list.max().item():.2f} & {logit_list.min().item():.2f}\")\n",
    "    return text_neuron_activations(tokens=text_list, activations=logit_list)\n",
    "def generate_text(input_text, num_tokens, model, autoencoder, feature, temperature=0.7, setting=\"add\", scalar=1.0):\n",
    "    # Convert input text to tokens\n",
    "    input_ids = model.tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "\n",
    "    for _ in range(num_tokens):\n",
    "        # Generate logits\n",
    "        with torch.no_grad():\n",
    "            if(setting==\"add\"):\n",
    "                logits = add_feature_direction(input_ids, feature, model, autoencoder, scalar=scalar)\n",
    "            else:\n",
    "                logits = model(input_ids)\n",
    "\n",
    "        # Apply temperature\n",
    "        logits = logits / temperature\n",
    "\n",
    "        # Sample from the distribution\n",
    "        probs = torch.nn.functional.softmax(logits[:, -1, :], dim=-1)\n",
    "        predicted_token = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        # Append predicted token to input_ids\n",
    "        input_ids = torch.cat((input_ids, predicted_token), dim=-1)\n",
    "\n",
    "    # Decode the tokens to text\n",
    "    output_text = model.tokenizer.decode(input_ids[0])\n",
    "\n",
    "    return output_text\n",
    "\n",
    "# Logit Lens\n",
    "def logit_lens(model, best_feature, smaller_dict, layer):\n",
    "    with torch.no_grad():\n",
    "        # There are never-used tokens, which have high norm. We want to ignore these.\n",
    "        bad_ind = (model.W_U.norm(dim=0) > 20)\n",
    "        feature_direction = smaller_dict[best_feature].to(device)\n",
    "        # feature_direction = torch.matmul(feature_direction, model.W_out[layer]) # if MLP\n",
    "        logits = torch.matmul(feature_direction, model.W_U).cpu()\n",
    "    # Don't include bad indices\n",
    "    logits[bad_ind] = -1000\n",
    "    topk_values, topk_indices = torch.topk(logits, 20)\n",
    "    top_text = model.to_str_tokens(topk_indices)\n",
    "    print(f\"{top_text}\")\n",
    "    print(topk_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text\n",
    "You can use the functions below to find interesting features to then add here to \"feature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:\n",
      " for a certain place.\n",
      "\n",
      "Lilmore\n",
      "\n",
      "The Lilmore is a three-mile\n",
      "Add:\n",
      " for,” LLP LLP LLP LLP LLP LLP Court,” LLPheets,” Court“ He LLP ruled His,”,’\n"
     ]
    }
   ],
   "source": [
    "sentence = \" for\"\n",
    "temp = 0.7\n",
    "tokens_to_generate = 20\n",
    "feature = 10 \n",
    "scalar = 100.0\n",
    "# Using the function:\n",
    "print(\"Normal:\\n\" + generate_text(sentence, tokens_to_generate, model, smaller_auto_encoder, feature=feature, temperature=temp, scalar=scalar, setting=\"normal\"))\n",
    "print(\"Add:\\n\" + generate_text(sentence, tokens_to_generate, model, smaller_auto_encoder, feature=feature, temperature=temp, scalar=scalar, setting=\"add\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Search\n",
    "Type in a sentence & see which features activate \n",
    "Note: Some features may be outliers, which will typically show up as high activations for the first word & first period or \\n (or high positive bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations: [1.69, 1.45, 1.39, 1.21, 0.91, 0.54, 0.49, 0.46, 0.37, 0.28]\n",
      "Feature_ids [1461, 1655, 389, 1309, 444, 82, 1300, 1206, 1901, 798]\n"
     ]
    }
   ],
   "source": [
    "t = \" I do like a\"\n",
    "split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "token = model.to_tokens(t, prepend_bos=False)\n",
    "_, cache = model.run_with_cache(token.to(model.cfg.device))\n",
    "neuron_act_batch = cache[cache_name]\n",
    "_, act = smaller_auto_encoder(neuron_act_batch)\n",
    "v, i = act[0, -1, :].topk(10)\n",
    "\n",
    "print(\"Activations:\",[round(val,2) for val in v.tolist()])\n",
    "print(\"Feature_ids\", i.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Interp\n",
    "Investigate the example sentences the activate this feature.\n",
    "\n",
    "Max: show max activating (tokens,contexts)\n",
    "\n",
    "Uniform: Show range of activations from each bin (e.g. sample an example from 1-2, 2-3, etc). \n",
    "[Note: if a feature is monosemantic, then the full range of activations should be that feature, not just max-activating ones]\n",
    "\n",
    "Full_text: shows the full text example\n",
    "\n",
    "Text_list: shows up to the most activating example (try w/ max activating on a couple of examples to see)\n",
    "\n",
    "ablate_text: remove the context one token at a time, and show the decrease/increase in activation of that feature\n",
    "\n",
    "ablate_feature_direction: removes feature direction from model's activation mid-inference, showing the logit diff in the output for every token.\n",
    "\n",
    "logit_lens: show the logit lens for that feature. If matches ablate_feature_direction, then the computation path is through the residual stream, else, it's through future layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias: -1.4668521\n",
      "Feature index: 1703\n",
      "MCS: 0.9344644546508789\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-b459dbaf-12ae\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-b459dbaf-12ae\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"Can\", \" Photo\", \"Model\", \"er\", \" model\", \" long\", \" road\", \" scenes\", \"?\", \"\\\\newline\", \"\\\\newline\", \"Yes\", \",\", \" Photo\", \"Model\", \"er\", \" can\", \" measure\", \" and\", \" model\", \" long\", \" road\", \" scenes\", \".\", \" Photo\", \"Model\", \"er\", \" was\", \" the\", \" first\", \" phot\", \"ogram\", \"metric\", \" product\", \" to\", \" offer\", \" Project\", \" Mer\", \"ge\", \" \\u2013\", \"\\n\", \"There\", \" are\", \" errors\", \" in\", \" the\", \" Funding\", \" section\", \".\", \" The\", \" correct\", \" funding\", \" information\", \" is\", \" as\", \" follows\", \":\", \" This\", \" study\", \" was\", \" supported\", \" by\", \" the\", \" National\", \" Cancer\", \" Institute\", \" of\", \" the\", \" National\", \" Institutes\", \" of\", \" Health\", \" under\", \" award\", \" number\", \" K\", \"08\", \"CA\", \"15\", \"50\", \"35\", \"\\n\", \"Wire\", \"less\", \" communication\", \" was\", \" traditionally\", \" based\", \" on\", \" the\", \" idea\", \" of\", \" enabling\", \" voice\", \" communication\", \" to\", \" and\", \" from\", \" a\", \" mobile\", \" terminal\", \" residing\", \" in\", \" the\", \" coverage\", \" of\", \" a\", \" mobile\", \" communication\", \" network\", \".\", \" The\", \" communication\", \" channel\", \" was\", \" established\", \" over\", \" circuit\", \"-\", \"sw\", \"itched\", \" technology\", \"\\n\", \"(\", \"Sports\", \"Network\", \".\", \"com\", \")\", \" -\", \" Bruce\", \" Ari\", \"ans\", \" was\", \" a\", \" candidate\", \" for\", \" the\", \" vacant\", \" Philadelphia\", \"\\\\newline\", \"E\", \"agles\", \" job\", \",\", \" but\", \" the\", \" powers\", \" that\", \" be\", \" decided\", \" Chip\", \" Kelly\", \",\", \" with\", \" no\", \" professional\", \"\\\\newline\", \"experience\", \",\", \" was\", \" better\", \" equipped\", \"\\n\", \"World\", \"s\", \" Apart\", \" (\", \"Black\", \"jack\", \" album\", \")\", \"\\\\newline\", \"\\\\newline\", \"World\", \"s\", \" Apart\", \" is\", \" the\", \" second\", \" and\", \" final\", \" album\", \" of\", \" the\", \" American\", \" rock\", \" band\", \" Black\", \"jack\", \".\", \" The\", \" album\", \" was\", \" met\", \" with\", \" nearly\", \" total\", \" indifference\", \",\", \" sold\", \" poorly\", \" and\", \" Black\", \"\\n\", \"Get\", \" Ready\", \" (\", \"Tom\", \"omi\", \" It\", \"ano\", \" album\", \")\", \"\\\\newline\", \"\\\\newline\", \"Get\", \" Ready\", \" (\", \"st\", \"yl\", \"ized\", \" as\", \" Get\", \" Ready\", \"\\ufffd\", \"\\ufffd\", \")\", \" is\", \" the\", \" second\", \" studio\", \" album\", \" released\", \" by\", \" Tom\", \"omi\", \" It\", \"ano\", \".\", \" It\", \" was\", \" released\", \" in\", \" Japan\", \"\\n\", \"2013\", \" Santa\", \" Rosa\", \" local\", \" elections\", \"\\\\newline\", \"\\\\newline\", \"Local\", \" elections\", \" was\", \" held\", \" in\", \"  \", \"Santa\", \" Rosa\", \" City\", \" on\", \" May\", \" 13\", \",\", \" 2013\", \" within\", \" the\", \" Philippine\", \" general\", \" election\", \".\", \" The\", \" voters\", \" elected\", \" for\", \" the\", \" elective\", \" local\", \" posts\", \" in\", \" the\", \" city\", \":\", \" the\", \"\\n\", \"Introduction\", \"\\\\newline\", \"\\\\newline\", \"These\", \" qu\", \"es\", \"\\u00ad\", \"t\", \"ions\", \" are\", \" designed\", \" to\", \" probe\", \" var\", \"\\u00ad\", \"i\", \"\\u00ad\", \"ous\", \" aspects\", \" of\", \" the\", \" L\", \"DS\", \" Church\", \"\\u2019\", \"s\", \" his\", \"\\u00ad\", \"to\", \"\\u00ad\", \"ry\", \" and\", \" truth\", \"-\", \"claims\", \".\", \" The\", \" list\", \" was\", \" made\", \"\\n\", \"An\", \"ime\", \" dating\", \" simulation\", \" games\", \" online\", \"\\\\newline\", \"\\\\newline\", \"Pol\", \"je\", \" Email\", \" je\", \" ob\", \"avez\", \"no\", \"!\", \" Results\", \" exclude\", \" some\", \" products\", \" based\", \" on\", \" your\", \" preferences\", \".\", \" Sadly\", \",\", \" this\", \" is\", \" also\", \" a\", \" series\", \" which\", \" was\", \" often\", \" passed\", \" up\", \" for\", \" English\", \" localization\", \"\\n\", \"\\ufeff\", \"//----------------------------------------------------------------\", \"--------------\", \"\\\\newline\", \"//\", \" <\", \"auto\", \"-\", \"generated\", \">\", \"\\\\newline\", \"//\", \"     \", \"This\", \" code\", \" was\", \" generated\", \" by\", \" Async\", \"Generator\", \".\", \"\\\\newline\", \"//\", \"\\\\newline\", \"//\", \"     \", \"Changes\", \" to\", \" this\", \" file\", \" may\", \" cause\", \" incorrect\", \" behavior\", \" and\", \" will\", \" be\", \" lost\", \" if\", \"\\\\newline\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[3.0834789276123047]], [[0.04943835735321045]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.2567843198776245]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[3.0381879806518555]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[3.006296157836914]], [[0.7677520513534546]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.2898454666137695]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[3.000138282775879]], [[0.4627199172973633]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.9928885698318481]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.972611427307129]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.9620447158813477]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.943819999694824]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.9028663635253906]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.07277452945709229]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.8928823471069336]], [[1.0252681970596313]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.885756015777588]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f1cfb3b3fa0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N = 5\n",
    "# best_feature = int(max_indices[N])\n",
    "best_feature = 1703\n",
    "print(\"bias:\", smaller_auto_encoder.encoder_bias.detach().cpu().numpy()[best_feature])\n",
    "print(f\"Feature index: {best_feature}\")\n",
    "print(f\"MCS: {max_cosine_similarities[best_feature]}\")\n",
    "# text_list, full_text, token_list, full_token_list = get_feature_datapoints(best_feature, dictionary_activations, dataset, setting=\"uniform\")\n",
    "text_list, full_text, token_list, full_token_list = get_feature_datapoints(best_feature, dictionary_activations, dataset, setting=\"max\")\n",
    "visualize_text(full_text, best_feature, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-c35da435-8c59\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-c35da435-8c59\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"Can\", \" Photo\", \"Model\", \"er\", \" model\", \" long\", \" road\", \" scenes\", \"?\", \"\\\\newline\", \"\\\\newline\", \"Yes\", \",\", \" Photo\", \"Model\", \"er\", \" can\", \" measure\", \" and\", \" model\", \" long\", \" road\", \" scenes\", \".\", \" Photo\", \"Model\", \"er\", \" was\", \"\\n\", \"There\", \" are\", \" errors\", \" in\", \" the\", \" Funding\", \" section\", \".\", \" The\", \" correct\", \" funding\", \" information\", \" is\", \" as\", \" follows\", \":\", \" This\", \" study\", \" was\", \"\\n\", \"Wire\", \"less\", \" communication\", \" was\", \"\\n\", \"(\", \"Sports\", \"Network\", \".\", \"com\", \")\", \" -\", \" Bruce\", \" Ari\", \"ans\", \" was\", \"\\n\", \"World\", \"s\", \" Apart\", \" (\", \"Black\", \"jack\", \" album\", \")\", \"\\\\newline\", \"\\\\newline\", \"World\", \"s\", \" Apart\", \" is\", \" the\", \" second\", \" and\", \" final\", \" album\", \" of\", \" the\", \" American\", \" rock\", \" band\", \" Black\", \"jack\", \".\", \" The\", \" album\", \" was\", \"\\n\", \"Get\", \" Ready\", \" (\", \"Tom\", \"omi\", \" It\", \"ano\", \" album\", \")\", \"\\\\newline\", \"\\\\newline\", \"Get\", \" Ready\", \" (\", \"st\", \"yl\", \"ized\", \" as\", \" Get\", \" Ready\", \"\\ufffd\", \"\\ufffd\", \")\", \" is\", \" the\", \" second\", \" studio\", \" album\", \" released\", \" by\", \" Tom\", \"omi\", \" It\", \"ano\", \".\", \" It\", \" was\", \"\\n\", \"2013\", \" Santa\", \" Rosa\", \" local\", \" elections\", \"\\\\newline\", \"\\\\newline\", \"Local\", \" elections\", \" was\", \"\\n\", \"Introduction\", \"\\\\newline\", \"\\\\newline\", \"These\", \" qu\", \"es\", \"\\u00ad\", \"t\", \"ions\", \" are\", \" designed\", \" to\", \" probe\", \" var\", \"\\u00ad\", \"i\", \"\\u00ad\", \"ous\", \" aspects\", \" of\", \" the\", \" L\", \"DS\", \" Church\", \"\\u2019\", \"s\", \" his\", \"\\u00ad\", \"to\", \"\\u00ad\", \"ry\", \" and\", \" truth\", \"-\", \"claims\", \".\", \" The\", \" list\", \" was\", \"\\n\", \"An\", \"ime\", \" dating\", \" simulation\", \" games\", \" online\", \"\\\\newline\", \"\\\\newline\", \"Pol\", \"je\", \" Email\", \" je\", \" ob\", \"avez\", \"no\", \"!\", \" Results\", \" exclude\", \" some\", \" products\", \" based\", \" on\", \" your\", \" preferences\", \".\", \" Sadly\", \",\", \" this\", \" is\", \" also\", \" a\", \" series\", \" which\", \" was\", \"\\n\", \"\\ufeff\", \"//----------------------------------------------------------------\", \"--------------\", \"\\\\newline\", \"//\", \" <\", \"auto\", \"-\", \"generated\", \">\", \"\\\\newline\", \"//\", \"     \", \"This\", \" code\", \" was\", \"\\n\"], \"activations\": [[[-0.03627729415893555]], [[0.03226041793823242]], [[0.013096332550048828]], [[0.014713287353515625]], [[-0.0022115707397460938]], [[0.05479907989501953]], [[0.0113372802734375]], [[0.0066661834716796875]], [[0.05164146423339844]], [[-0.021917343139648438]], [[-0.021917343139648438]], [[0.024934768676757812]], [[-0.0193634033203125]], [[-0.03679084777832031]], [[-0.019545555114746094]], [[-0.009810924530029297]], [[-0.14644193649291992]], [[0.013576030731201172]], [[-0.069580078125]], [[9.679794311523438e-05]], [[-0.011707305908203125]], [[0.004748821258544922]], [[-0.026165008544921875]], [[-0.40893983840942383]], [[-0.15589237213134766]], [[-0.09147214889526367]], [[0.11829090118408203]], [[-3.0834779739379883]], [[0.0]], [[0.0012807846069335938]], [[-0.09238624572753906]], [[-0.009600162506103516]], [[-0.02201700210571289]], [[-0.006222724914550781]], [[0.04075479507446289]], [[-0.012076377868652344]], [[-0.06170511245727539]], [[0.13570737838745117]], [[-0.06620645523071289]], [[0.01073598861694336]], [[-0.025430679321289062]], [[-0.22279024124145508]], [[-0.02314138412475586]], [[-0.1652989387512207]], [[-0.18772315979003906]], [[-0.29286670684814453]], [[-0.25450658798217773]], [[-3.0381879806518555]], [[0.0]], [[-0.4743046760559082]], [[-0.08962583541870117]], [[-0.0906972885131836]], [[-3.006296157836914]], [[0.0]], [[-0.15138578414916992]], [[-0.054067134857177734]], [[-0.016434192657470703]], [[-0.04284524917602539]], [[-0.009083747863769531]], [[-0.03757667541503906]], [[0.07779073715209961]], [[0.010569095611572266]], [[-0.1544933319091797]], [[-0.21502399444580078]], [[-3.000138282775879]], [[0.0]], [[-0.012656211853027344]], [[-0.007678508758544922]], [[-0.02002859115600586]], [[0.023920536041259766]], [[-0.0004868507385253906]], [[0.004231929779052734]], [[0.015622138977050781]], [[-0.04652690887451172]], [[0.0031142234802246094]], [[0.0031142234802246094]], [[-0.013826847076416016]], [[-0.014009475708007812]], [[-0.0433955192565918]], [[-0.1658782958984375]], [[0.03426074981689453]], [[-0.019039630889892578]], [[-0.0031585693359375]], [[-0.0062618255615234375]], [[-0.02347850799560547]], [[0.009503364562988281]], [[0.014627933502197266]], [[0.008203506469726562]], [[0.0010724067687988281]], [[0.0063991546630859375]], [[-0.02210092544555664]], [[-0.015796184539794922]], [[-0.18477582931518555]], [[-0.20133161544799805]], [[-0.9784902334213257]], [[-2.972611904144287]], [[0.0]], [[-0.0021924972534179688]], [[0.02834033966064453]], [[0.021318435668945312]], [[0.01285409927368164]], [[-0.00041675567626953125]], [[-0.00988912582397461]], [[0.007730960845947266]], [[0.03103160858154297]], [[0.0007724761962890625]], [[0.013157844543457031]], [[0.013157844543457031]], [[-0.03964519500732422]], [[0.008085250854492188]], [[-0.014490127563476562]], [[0.0038924217224121094]], [[-0.00829935073852539]], [[0.010547161102294922]], [[-0.010575294494628906]], [[-0.06564044952392578]], [[0.011022567749023438]], [[-0.013162612915039062]], [[0.010838508605957031]], [[0.008167743682861328]], [[-0.1555776596069336]], [[0.040637969970703125]], [[0.02783346176147461]], [[-0.025705337524414062]], [[-0.07692956924438477]], [[-0.06528091430664062]], [[-0.047055721282958984]], [[0.047591209411621094]], [[0.02579355239868164]], [[0.0305023193359375]], [[0.01624774932861328]], [[-0.12702131271362305]], [[-0.285555362701416]], [[-2.9620447158813477]], [[0.0]], [[-0.0384669303894043]], [[-0.015253067016601562]], [[-0.03760480880737305]], [[-0.02493572235107422]], [[0.03298521041870117]], [[0.05378913879394531]], [[0.05378913879394531]], [[-0.11239337921142578]], [[-0.4596877098083496]], [[-2.9438204765319824]], [[0.0]], [[-0.054396629333496094]], [[0.005812168121337891]], [[0.005812168121337891]], [[-0.034444332122802734]], [[0.010266780853271484]], [[0.010754585266113281]], [[0.011797904968261719]], [[0.0062541961669921875]], [[0.01792430877685547]], [[-0.027309894561767578]], [[0.02160930633544922]], [[-0.012780189514160156]], [[0.0072784423828125]], [[-0.00948190689086914]], [[0.010693073272705078]], [[0.0011577606201171875]], [[0.008244037628173828]], [[0.014144420623779297]], [[-0.023893356323242188]], [[0.00797271728515625]], [[0.009159564971923828]], [[0.016431808471679688]], [[0.008616447448730469]], [[0.026686668395996094]], [[-0.006625175476074219]], [[-0.0027937889099121094]], [[0.031865596771240234]], [[0.0180816650390625]], [[0.01665639877319336]], [[0.015303611755371094]], [[0.009518623352050781]], [[-0.0167236328125]], [[-0.017958641052246094]], [[0.01842021942138672]], [[0.013562202453613281]], [[-0.04927682876586914]], [[0.00032520294189453125]], [[-1.2131761312484741]], [[-2.9028663635253906]], [[0.0]], [[-0.007153987884521484]], [[0.006249427795410156]], [[-0.010065078735351562]], [[0.028514385223388672]], [[-0.002312183380126953]], [[-0.015509605407714844]], [[-0.012680530548095703]], [[-0.012680530548095703]], [[-0.007586479187011719]], [[0.0035157203674316406]], [[-0.0004343986511230469]], [[-0.0011119842529296875]], [[-0.001956939697265625]], [[0.002129077911376953]], [[-0.008016586303710938]], [[0.021358489990234375]], [[0.021923065185546875]], [[-0.036212921142578125]], [[0.005302906036376953]], [[0.011148452758789062]], [[0.03656339645385742]], [[-0.008695602416992188]], [[-0.08606719970703125]], [[-0.03986692428588867]], [[-0.009398460388183594]], [[-0.005324363708496094]], [[0.01157379150390625]], [[-0.04701042175292969]], [[-0.2041025161743164]], [[0.02195882797241211]], [[-0.05971717834472656]], [[-0.0773935317993164]], [[0.07212495803833008]], [[-2.8928823471069336]], [[0.0]], [[0.009096622467041016]], [[-0.055821895599365234]], [[0.12165069580078125]], [[-0.042156219482421875]], [[-0.03710174560546875]], [[-0.05043506622314453]], [[-0.030084609985351562]], [[0.014741897583007812]], [[0.2743186950683594]], [[-0.09827232360839844]], [[-0.03388214111328125]], [[-0.08879232406616211]], [[-0.0633249282836914]], [[-0.49829959869384766]], [[-0.7950530052185059]], [[-2.8857545852661133]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f1cfb3b3250>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_text(text_list, best_feature, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-9fb900d9-c91f\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-9fb900d9-c91f\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\" Photo\", \"Model\", \"er\", \" model\", \" long\", \" road\", \" scenes\", \"?\", \"\\\\newline\", \"\\\\newline\", \"Yes\", \",\", \" Photo\", \"Model\", \"er\", \" can\", \" measure\", \" and\", \" model\", \" long\", \" road\", \" scenes\", \".\", \" Photo\", \"Model\", \"er\", \" was\", \" the\", \" first\", \" phot\", \"ogram\", \"metric\", \" product\", \" to\", \" offer\", \" Project\", \" Mer\", \"ge\", \" \\u2013\", \"\\n\", \" are\", \" errors\", \" in\", \" the\", \" Funding\", \" section\", \".\", \" The\", \" correct\", \" funding\", \" information\", \" is\", \" as\", \" follows\", \":\", \" This\", \" study\", \" was\", \" supported\", \" by\", \" the\", \" National\", \" Cancer\", \" Institute\", \" of\", \" the\", \" National\", \" Institutes\", \" of\", \" Health\", \" under\", \" award\", \" number\", \" K\", \"08\", \"CA\", \"15\", \"50\", \"35\", \"\\n\", \"less\", \" communication\", \" was\", \" traditionally\", \" based\", \" on\", \" the\", \" idea\", \" of\", \" enabling\", \" voice\", \" communication\", \" to\", \" and\", \" from\", \" a\", \" mobile\", \" terminal\", \" residing\", \" in\", \" the\", \" coverage\", \" of\", \" a\", \" mobile\", \" communication\", \" network\", \".\", \" The\", \" communication\", \" channel\", \" was\", \" established\", \" over\", \" circuit\", \"-\", \"sw\", \"itched\", \" technology\", \"\\n\", \"Sports\", \"Network\", \".\", \"com\", \")\", \" -\", \" Bruce\", \" Ari\", \"ans\", \" was\", \" a\", \" candidate\", \" for\", \" the\", \" vacant\", \" Philadelphia\", \"\\\\newline\", \"E\", \"agles\", \" job\", \",\", \" but\", \" the\", \" powers\", \" that\", \" be\", \" decided\", \" Chip\", \" Kelly\", \",\", \" with\", \" no\", \" professional\", \"\\\\newline\", \"experience\", \",\", \" was\", \" better\", \" equipped\", \"\\n\", \"s\", \" Apart\", \" (\", \"Black\", \"jack\", \" album\", \")\", \"\\\\newline\", \"\\\\newline\", \"World\", \"s\", \" Apart\", \" is\", \" the\", \" second\", \" and\", \" final\", \" album\", \" of\", \" the\", \" American\", \" rock\", \" band\", \" Black\", \"jack\", \".\", \" The\", \" album\", \" was\", \" met\", \" with\", \" nearly\", \" total\", \" indifference\", \",\", \" sold\", \" poorly\", \" and\", \" Black\", \"\\n\", \" Ready\", \" (\", \"Tom\", \"omi\", \" It\", \"ano\", \" album\", \")\", \"\\\\newline\", \"\\\\newline\", \"Get\", \" Ready\", \" (\", \"st\", \"yl\", \"ized\", \" as\", \" Get\", \" Ready\", \"\\ufffd\", \"\\ufffd\", \")\", \" is\", \" the\", \" second\", \" studio\", \" album\", \" released\", \" by\", \" Tom\", \"omi\", \" It\", \"ano\", \".\", \" It\", \" was\", \" released\", \" in\", \" Japan\", \"\\n\", \" Santa\", \" Rosa\", \" local\", \" elections\", \"\\\\newline\", \"\\\\newline\", \"Local\", \" elections\", \" was\", \" held\", \" in\", \"  \", \"Santa\", \" Rosa\", \" City\", \" on\", \" May\", \" 13\", \",\", \" 2013\", \" within\", \" the\", \" Philippine\", \" general\", \" election\", \".\", \" The\", \" voters\", \" elected\", \" for\", \" the\", \" elective\", \" local\", \" posts\", \" in\", \" the\", \" city\", \":\", \" the\", \"\\n\", \"\\\\newline\", \"\\\\newline\", \"These\", \" qu\", \"es\", \"\\u00ad\", \"t\", \"ions\", \" are\", \" designed\", \" to\", \" probe\", \" var\", \"\\u00ad\", \"i\", \"\\u00ad\", \"ous\", \" aspects\", \" of\", \" the\", \" L\", \"DS\", \" Church\", \"\\u2019\", \"s\", \" his\", \"\\u00ad\", \"to\", \"\\u00ad\", \"ry\", \" and\", \" truth\", \"-\", \"claims\", \".\", \" The\", \" list\", \" was\", \" made\", \"\\n\", \"ime\", \" dating\", \" simulation\", \" games\", \" online\", \"\\\\newline\", \"\\\\newline\", \"Pol\", \"je\", \" Email\", \" je\", \" ob\", \"avez\", \"no\", \"!\", \" Results\", \" exclude\", \" some\", \" products\", \" based\", \" on\", \" your\", \" preferences\", \".\", \" Sadly\", \",\", \" this\", \" is\", \" also\", \" a\", \" series\", \" which\", \" was\", \" often\", \" passed\", \" up\", \" for\", \" English\", \" localization\", \"\\n\", \"//----------------------------------------------------------------\", \"--------------\", \"\\\\newline\", \"//\", \" <\", \"auto\", \"-\", \"generated\", \">\", \"\\\\newline\", \"//\", \"     \", \"This\", \" code\", \" was\", \" generated\", \" by\", \" Async\", \"Generator\", \".\", \"\\\\newline\", \"//\", \"\\\\newline\", \"//\", \"     \", \"Changes\", \" to\", \" this\", \" file\", \" may\", \" cause\", \" incorrect\", \" behavior\", \" and\", \" will\", \" be\", \" lost\", \" if\", \"\\\\newline\", \"\\n\"], \"activations\": [[[0.0]], [[0.006737709045410156]], [[0.0006241798400878906]], [[0.008192062377929688]], [[0.0033826828002929688]], [[0.0034151077270507812]], [[0.0033512115478515625]], [[4.100799560546875e-05]], [[-0.0001570582389831543]], [[0.00011786818504333496]], [[0.0007076263427734375]], [[0.00013881921768188477]], [[0.011946678161621094]], [[-1.2814998626708984e-06]], [[-4.297355189919472e-05]], [[-0.00020194053649902344]], [[-0.0021648406982421875]], [[-0.00020599365234375]], [[0.01100921630859375]], [[0.0037784576416015625]], [[0.0]], [[-8.940696716308594e-08]], [[0.0002340078353881836]], [[0.011777877807617188]], [[-2.384185791015625e-07]], [[-3.5510631278157234e-05]], [[0.00010824203491210938]], [[1.0838031768798828]], [[-1.0331602096557617]], [[0.1436481475830078]], [[0.11634159088134766]], [[0.023562192916870117]], [[0.022546768188476562]], [[-0.027967453002929688]], [[-0.014098644256591797]], [[-0.010433197021484375]], [[-0.028743743896484375]], [[0.025565147399902344]], [[-0.04664468765258789]], [[0.0]], [[0.0]], [[-0.0020017623901367188]], [[0.0003364086151123047]], [[0.0007021427154541016]], [[0.0]], [[-0.0015392303466796875]], [[-0.0002980232238769531]], [[-2.0503997802734375e-05]], [[-0.0007219314575195312]], [[0.0007178783416748047]], [[-0.0018911361694335938]], [[-0.00010120868682861328]], [[0.0630192756652832]], [[-0.0033144503831863403]], [[0.0014597773551940918]], [[-0.002899169921875]], [[-0.004334926605224609]], [[-0.0019873380661010742]], [[0.011582136154174805]], [[0.0054105594754219055]], [[0.01884359121322632]], [[0.050218939781188965]], [[0.05973339080810547]], [[0.0018797814846038818]], [[0.023558616638183594]], [[0.009376943111419678]], [[0.019203543663024902]], [[0.0054070353507995605]], [[-0.0011042840778827667]], [[-4.6572647988796234e-05]], [[-0.06808829307556152]], [[0.006805419921875]], [[-0.009637057781219482]], [[0.006996870040893555]], [[0.00677180290222168]], [[0.01287841796875]], [[0.028000354766845703]], [[-0.012629985809326172]], [[-0.008347511291503906]], [[0.0]], [[0.0]], [[0.0031347274780273438]], [[0.0]], [[-0.09199142456054688]], [[-0.10052299499511719]], [[-0.0014228522777557373]], [[-0.004733085632324219]], [[-0.0798959732055664]], [[0.009181171655654907]], [[-0.23914575576782227]], [[-0.009472370147705078]], [[0.015228271484375]], [[-0.043657541275024414]], [[0.05771207809448242]], [[0.0008261203765869141]], [[0.04110980033874512]], [[0.006697893142700195]], [[-0.0058917999267578125]], [[0.009612083435058594]], [[0.017002105712890625]], [[0.012284994125366211]], [[-0.005024909973144531]], [[-0.08096027374267578]], [[0.037076711654663086]], [[0.006024718284606934]], [[0.04096364974975586]], [[0.0028225183486938477]], [[0.004206359386444092]], [[-0.01431584358215332]], [[0.05446481704711914]], [[-0.058743953704833984]], [[-1.828031063079834]], [[-1.676088809967041]], [[-0.045024871826171875]], [[-0.0069332122802734375]], [[0.046053409576416016]], [[-0.01433420181274414]], [[-0.0039339736104011536]], [[-0.043290138244628906]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.00020313262939453125]], [[0.006011009216308594]], [[0.002421855926513672]], [[0.0]], [[-0.0007610321044921875]], [[0.4116361141204834]], [[-0.3044929504394531]], [[-0.05997025966644287]], [[-0.03202521800994873]], [[0.015665531158447266]], [[-0.02284526824951172]], [[0.06999969482421875]], [[0.002372264862060547]], [[-0.03370952606201172]], [[-0.050920963287353516]], [[0.03383684158325195]], [[-0.16625499725341797]], [[0.024979591369628906]], [[0.02792072296142578]], [[0.06994271278381348]], [[0.016815289855003357]], [[-0.1475820541381836]], [[0.020226478576660156]], [[-0.03484654426574707]], [[-0.009399890899658203]], [[0.022724628448486328]], [[0.012475967407226562]], [[-0.008837699890136719]], [[0.024198532104492188]], [[0.011111021041870117]], [[-0.002842426300048828]], [[-0.1768665313720703]], [[0.41437768936157227]], [[0.06672811508178711]], [[0.0]], [[0.0]], [[0.00035190582275390625]], [[0.0]], [[0.0007801055908203125]], [[0.0]], [[0.0]], [[-3.129243850708008e-05]], [[6.198883056640625e-05]], [[0.0]], [[-6.580352783203125e-05]], [[-0.000528872013092041]], [[-0.001270294189453125]], [[5.245208740234375e-06]], [[-0.0003883838653564453]], [[-2.1696090698242188e-05]], [[-2.86102294921875e-06]], [[0.0]], [[8.58306884765625e-06]], [[-0.00039958953857421875]], [[0.00045359134674072266]], [[2.384185791015625e-06]], [[0.0]], [[0.0]], [[0.0014379024505615234]], [[0.0]], [[0.0]], [[0.004295468330383301]], [[0.0035816431045532227]], [[4.7087669372558594e-05]], [[-0.08283042907714844]], [[0.07798373699188232]], [[-0.04649782180786133]], [[0.08099985122680664]], [[0.03838300704956055]], [[0.04897499084472656]], [[-0.019115447998046875]], [[-0.03000020980834961]], [[0.0005613565444946289]], [[0.038863182067871094]], [[0.0]], [[0.0]], [[-0.0002307891845703125]], [[0.0012769699096679688]], [[0.00015354156494140625]], [[-0.0003185272216796875]], [[-5.14984130859375e-05]], [[0.0007429122924804688]], [[-0.00013059377670288086]], [[5.924701690673828e-05]], [[-1.0728836059570312e-05]], [[-0.0018310546875]], [[-0.00017189979553222656]], [[-7.748603820800781e-07]], [[0.0]], [[-1.6689300537109375e-06]], [[0.0020380020141601562]], [[-0.0010514259338378906]], [[0.0018992424011230469]], [[8.642673492431641e-07]], [[0.0]], [[0.0]], [[-1.9073486328125e-06]], [[0.0007839202880859375]], [[-0.0001811981201171875]], [[-6.628036499023438e-05]], [[9.5367431640625e-07]], [[0.0]], [[0.015524744987487793]], [[2.384185791015625e-07]], [[0.004807949066162109]], [[0.0]], [[1.1324882507324219e-06]], [[0.0]], [[0.0]], [[-0.00015294551849365234]], [[0.0]], [[-0.6196557283401489]], [[0.029375314712524414]], [[0.20331454277038574]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.00018668174743652344]], [[0.0]], [[0.0006885528564453125]], [[0.0]], [[-0.000263214111328125]], [[-0.6907644867897034]], [[0.020035147666931152]], [[0.02239370346069336]], [[0.011840343475341797]], [[0.0009495913982391357]], [[0.025096416473388672]], [[-0.16202259063720703]], [[-0.0065686702728271484]], [[-0.003869295120239258]], [[-0.014122247695922852]], [[0.07718944549560547]], [[0.011944770812988281]], [[0.005798041820526123]], [[0.0289306640625]], [[0.0006074905395507812]], [[0.004568904638290405]], [[0.0038208961486816406]], [[-0.05090141296386719]], [[-0.005060672760009766]], [[-0.06441354751586914]], [[0.0032863616943359375]], [[0.0019736289978027344]], [[-0.0010194778442382812]], [[-0.025936126708984375]], [[-0.02911853790283203]], [[-0.008214712142944336]], [[-0.004377245903015137]], [[-0.0012347698211669922]], [[-0.12438440322875977]], [[-0.0013263225555419922]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-4.553794860839844e-05]], [[0.0005087852478027344]], [[0.00010260939598083496]], [[-0.0014677047729492188]], [[-0.0002994537353515625]], [[0.0]], [[0.0]], [[-2.2724270820617676e-07]], [[0.0]], [[0.0]], [[4.015862941741943e-06]], [[0.001055002212524414]], [[0.0]], [[0.0]], [[0.005761146545410156]], [[9.906291961669922e-05]], [[8.714292198419571e-05]], [[0.0]], [[0.0014215707778930664]], [[0.0]], [[-7.748603820800781e-07]], [[0.0]], [[0.0]], [[-0.0037527084350585938]], [[-2.384185791015625e-06]], [[0.0]], [[4.76837158203125e-07]], [[0.015113353729248047]], [[-0.0039997100830078125]], [[0.0023040771484375]], [[-0.24378514289855957]], [[0.0]], [[0.0]], [[0.0029392242431640625]], [[0.0011339187622070312]], [[-0.0004911422729492188]], [[0.00043201446533203125]], [[0.0]], [[0.0]], [[0.00044155120849609375]], [[0.0]], [[0.0019445419311523438]], [[0.004108428955078125]], [[-0.0009875297546386719]], [[0.0]], [[0.0]], [[0.0]], [[-0.0054798126220703125]], [[-0.002750396728515625]], [[-0.0039348602294921875]], [[-0.0038084983825683594]], [[-0.009333610534667969]], [[4.4133514165878296e-05]], [[-0.0010602474212646484]], [[-0.0018777847290039062]], [[0.0002894401550292969]], [[-0.0014667510986328125]], [[0.0029546916484832764]], [[0.00442957878112793]], [[-0.0013475418090820312]], [[-0.0015592575073242188]], [[0.002011895179748535]], [[-0.007798194885253906]], [[-0.009962081909179688]], [[-0.019138574600219727]], [[1.1963119506835938]], [[-0.2841300964355469]], [[-0.14041876792907715]], [[-0.13373303413391113]], [[-0.0064983367919921875]], [[0.04357337951660156]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.046737611293792725]], [[-0.0028292974457144737]], [[-0.10820341110229492]], [[-0.00431060791015625]], [[-0.005625247955322266]], [[-0.00047336146235466003]], [[1.2002885341644287e-05]], [[-0.015305280685424805]], [[-7.529766298830509e-05]], [[0.004064023494720459]], [[0.07601344585418701]], [[0.00033939629793167114]], [[0.004620492458343506]], [[0.0005437489598989487]], [[3.1404197216033936e-05]], [[1.6594305634498596e-05]], [[-6.996840238571167e-05]], [[-0.0005618184804916382]], [[3.218650817871094e-05]], [[1.5490222722291946e-06]], [[1.369323581457138e-05]], [[-2.9051676392555237e-05]], [[-1.7467886209487915e-05]], [[0.0005556493997573853]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f1cfb3b3010>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_feature_direction_display(full_text, best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hers', ' unsuccessful', ' originally', ' initially', 'oop', ' unsuccess', ' kindly', 'hes', 'raid', ' born', ' vain', ' discontinued', 'swer', 'her', ' negligent', ' previously', 'ayette', 'lla', ' exception', 'orf']\n",
      "tensor([2.1063, 2.0073, 1.9762, 1.9271, 1.8129, 1.8127, 1.7595, 1.7240, 1.6969,\n",
      "        1.6202, 1.5482, 1.5389, 1.5265, 1.5208, 1.4840, 1.4795, 1.4768, 1.4720,\n",
      "        1.4651, 1.4623])\n"
     ]
    }
   ],
   "source": [
    "logit_lens(model,best_feature, smaller_dict, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-6e3a4684-f36c\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-6e3a4684-f36c\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\" Your\", \" text\", \" here\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fb7482dac20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_text = [\n",
    "    \" Your text here\",\n",
    "]\n",
    "visualize_text(custom_text, best_feature, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Centric Viewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-b3f2704e-8a27\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-b3f2704e-8a27\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\"], \"activations\": [[[82.7564926147461]], [[0.41646838188171387]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[149.81748962402344]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[62.884986877441406]], [[0.0]], [[0.4040207862854004]], [[0.0]], [[0.0]], [[0.0]], [[99.5608139038086]], [[0.5513043403625488]], [[0.0]], [[1.0399408340454102]], [[1.425760269165039]], [[4.947237968444824]], [[1.7392220497131348]], [[0.0]], [[0.0]], [[4.0198774337768555]], [[0.17562437057495117]], [[0.0]], [[0.0]], [[0.0]], [[3.941493034362793]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[17.318439483642578]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.9275326728820801]], [[0.6468110084533691]], [[0.10458612442016602]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.11562681198120117]], [[1.100588321685791]], [[1.7711853981018066]], [[1.5439908504486084]], [[0.3038226366043091]], [[0.3253086805343628]], [[0.6628274917602539]], [[0.5560286045074463]], [[0.3502471446990967]], [[0.4706670045852661]], [[0.0]], [[0.8721731901168823]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.8246186971664429]], [[0.4927572011947632]], [[0.3002433776855469]], [[0.4912317991256714]], [[0.18886053562164307]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.7436568737030029]], [[1.5422230958938599]], [[1.4640122652053833]], [[1.782070279121399]], [[0.8627933263778687]], [[0.32637345790863037]], [[0.0]], [[0.30792057514190674]], [[0.15409982204437256]], [[0.10886752605438232]], [[0.06799399852752686]], [[0.40450000762939453]], [[0.0]], [[0.37047338485717773]], [[0.009954333305358887]], [[0.0]], [[0.0619814395904541]], [[0.20380747318267822]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.4360116720199585]], [[0.0]], [[0.557902455329895]], [[1.4583653211593628]], [[0.36010468006134033]], [[0.2150031328201294]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.47024083137512207]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.3076235055923462]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.3168461322784424]], [[0.1124265193939209]], [[3.23787784576416]], [[1.5314109325408936]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fb6601fad10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through datapoints & see if the features that activate on them make sense.\n",
    "d_point = 0\n",
    "# text = tokens_dataset[d_point]\n",
    "data_ind, sequence_pos = np.unravel_index(d_point, (datapoints, token_amount))\n",
    "feature_val, feature_ind = dictionary_activations[d_point].topk(10)\n",
    "data_ind = int(data_ind)\n",
    "sequence_pos = int(sequence_pos)\n",
    "full_tok = torch.tensor(dataset[data_ind][\"input_ids\"])\n",
    "full_text = []\n",
    "full_text.append(model.tokenizer.decode(full_tok))\n",
    "visualize_text(full_text, feature_ind, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the neuron/residual basis\n",
    "When we look at the weights of a feature, we are seeing the literal dimensions from the residual stream/neurons being read from the feature. \n",
    "\n",
    "Here I'm visualizing the weight values for the residual stream. If there are outliers, then it's mainly reading from that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check features non-zero weights in decoder\n",
    "# Plot a histogram of the weights\n",
    "max_activation = dictionary_activations[:, best_feature].max()\n",
    "weights = smaller_dict[best_feature]\n",
    "plt.hist(weights, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.topk(\n",
       " values=tensor([0.4587, 0.4407, 0.4183, 0.4015, 0.3814, 0.3496, 0.3330, 0.3156, 0.2968,\n",
       "         0.2948, 0.2846, 0.2781, 0.2736, 0.2714, 0.2680, 0.2593, 0.2587, 0.2563,\n",
       "         0.2554, 0.2505]),\n",
       " indices=tensor([478, 436,  98, 321,  87, 458, 230, 464, 129,  31, 137, 377, 263, 401,\n",
       "         291,  92, 132,  56, 109, 246])),\n",
       " tensor([-0.3796, -0.3700, -0.3456, -0.3286, -0.3197, -0.3164, -0.3107, -0.3015,\n",
       "         -0.3011, -0.3000, -0.2976, -0.2964, -0.2894, -0.2886, -0.2828, -0.2822,\n",
       "         -0.2763, -0.2675, -0.2606, -0.2588]),\n",
       " tensor(39))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weights*max_activation).topk(20), (weights*max_activation).topk(20, largest=False).values, (weights*max_activation > 0.2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepend/Append tokens\n",
    "We can iterate over all tokens to check which ones activate a feature a lot to more rigorously test a hypothesis on what a feature means.\n",
    "\n",
    "Note: I'm literately running the model through all 50k tokens prepended to the text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[token]\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n",
      "<|endoftext|>[token]\n",
      "Top-20 increasing: [' a', '#', '1', ')', '/', \"'\", '2', '<|padding|>', '$', '*', '+', '.', '&', '0', '\"', '(', ',', '<|endoftext|>', '!', '%']\n",
      "Top-20 increasing: ['0.11', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50303\n",
      "<|endoftext|> a[token]\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n"
     ]
    }
   ],
   "source": [
    "def prepend_all_tokens_and_get_feature_activation(model, minimal_activating_example, feature, setting=\"prepend\"):\n",
    "    tokens = model.to_tokens(minimal_activating_example, prepend_bos=False)\n",
    "\n",
    "    # Run through every number up to vocab size\n",
    "    vocab_size = model.cfg.d_vocab\n",
    "    batch_size = 256*2 # Define your desired batch size\n",
    "\n",
    "    dollar_feature_activations = torch.zeros(vocab_size)\n",
    "    for start in range(0, vocab_size, batch_size):\n",
    "        end = min(start + batch_size, vocab_size)\n",
    "\n",
    "        token_prep = torch.arange(start, end).to(device)\n",
    "        token_prep = token_prep.unsqueeze(1)  # Add a dimension for concatenation\n",
    "\n",
    "        # 1. Prepend to the tokens\n",
    "        if setting == \"prepend\":\n",
    "            tokens_catted = torch.cat((token_prep, tokens.repeat(end - start, 1)), dim=1).long()\n",
    "        elif setting == \"append\":\n",
    "            tokens_catted = torch.cat((tokens.repeat(end - start, 1), token_prep), dim=1).long()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown setting: {setting}\")\n",
    "\n",
    "        # 2. Run through the model\n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(tokens_catted.to(device))\n",
    "            neuron_act_batch = cache[cache_name]\n",
    "            _, act = smaller_auto_encoder(neuron_act_batch)\n",
    "\n",
    "        # 3. Get the feature\n",
    "        dollar_feature_activations[start:end] = act[:, -1, feature].cpu().squeeze()\n",
    "\n",
    "    k = 20\n",
    "    k_increasing_val, k_increasing_ind = dollar_feature_activations.topk(k)\n",
    "    k_decreasing_val, k_decreasing_ind = dollar_feature_activations.topk(k, largest=False)\n",
    "    if(setting == \"prepend\"):\n",
    "        print(f\"[token]{minimal_activating_example}\")\n",
    "    elif(setting == \"append\"):\n",
    "        print(f\"{minimal_activating_example}[token]\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown setting: {setting}\")\n",
    "    # Print indices converted to tokens\n",
    "    print(f\"Top-{k} increasing: {model.to_str_tokens(k_increasing_ind)}\")\n",
    "    # Print values\n",
    "    print(f\"Top-{k} increasing: {[f'{val:.2f}' for val in k_increasing_val]}\")\n",
    "    print(f\"Top-{k} decreasing: {model.to_str_tokens(k_decreasing_ind)}\")\n",
    "    print(f\"Top-{k} decreasing: {[f'{val:.2f}' for val in k_decreasing_val]}\")\n",
    "    print(f\"Number of 0 activations: {torch.sum(dollar_feature_activations == 0)}\")\n",
    "    if(setting == \"prepend\"):\n",
    "        best_text = \"\".join(model.to_str_tokens(dollar_feature_activations.argmax()) + [minimal_activating_example])\n",
    "    else:\n",
    "        best_text = \"\".join([minimal_activating_example] + model.to_str_tokens(dollar_feature_activations.argmax()))\n",
    "    return best_text\n",
    "\n",
    "best_text = \"\"\n",
    "for x in range(3):\n",
    "    # best_text = prepend_all_tokens_and_get_feature_activation(model, best_text, best_feature, setting=\"prepend\")\n",
    "    best_text = prepend_all_tokens_and_get_feature_activation(model, best_text, best_feature, setting=\"append\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" for all $\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" tree\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" tree\", best_feature, setting=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[token]\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n",
      "[token]<|endoftext|>\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n",
      "[token]<|endoftext|><|endoftext|>\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n"
     ]
    }
   ],
   "source": [
    "best_text = \"\"\n",
    "for x in range(3):\n",
    "    best_text = prepend_all_tokens_and_get_feature_activation(model, best_text, best_feature, setting=\"prepend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[token] for all $\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|endoftext|> for all $'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepend_all_tokens_and_get_feature_activation(model, \" for all $\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \"The\", best_feature, setting=\"append\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" tree\", best_feature, setting=\"append\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
